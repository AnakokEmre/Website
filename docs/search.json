[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Qui suis-je ?",
    "section": "",
    "text": "Depuis septembre 2025, je suis enseignant-chercheur en statistiques appliqu√©es.\n\nTravaux de recherche actuels\nMots Cl√©s: Graphes d‚Äôadmixture, Invasion biologique, G√©n√©tique des populations.\nCollaborateurs: Arnaud Estoup, Mathieu Gautier (INRAE, CBGP, Montpellier), Paul Bastide (CNRS, Univ. Paris Cit√©, Paris), C√©cile An√© (Univ. of Wisconsin-Madison, USA), Jean-Michel Marin (IMAG, Univ. Montpellier, Montpellier)\nJ‚Äô√©tais en recherche post-doctoral de mars 2025 √† septembre 2025 au Centre Biologique de Gestion des Populations de Montpellier en tant que charg√© de recherche. Cette collaboration continue actuellement. Je travaille sur des d√©veloppements m√©thodologiques pour inf√©rer des graphes de m√©lange (ou d‚Äôadmixture, abr√©g√© en GM) en g√©n√©tique des populations d‚Äôesp√®ces envahissantes. Les GM repr√©sentent sch√©matiquement l‚Äôhistoire √©volutive de populations via des fusions et des s√©parations de populations. Ils sont inf√©r√©s √† l‚Äôaide de m√©thodes statistiques appliqu√©es aux corr√©lations des fr√©quences all√©liques. Les objectifs de ce travail sont multiples. Il s‚Äôagit d‚Äôabord de comparer les m√©thodes d‚Äôinf√©rence existantes sur des donn√©es simul√©es et r√©elles, en analysant notamment des approches bay√©siennes et des m√©thodes bas√©es sur la vraisemblance. De plus, la grande taille de l‚Äôespace des GM complique ces m√©thodologies et pose des d√©fis d‚Äôidentifiabilit√©, que nous souhaitons √©tudier en s‚Äôinspirant de la litt√©rature d√©j√† existante pour les arbres phylog√©n√©tiques. Un autre d√©fi sera d‚Äôint√©grer l‚Äôincertitude dans l‚Äôestimation de la covariance des fr√©quences all√©liques des populations et d‚Äôadapter ces estimations √† des donn√©es plus complexes, telles que les donn√©es Pool-Seq. Il est aussi envisag√© de d√©velopper des m√©thodologies innovantes pour l‚Äôestimation des GM, en m‚Äôinspirant des mod√®les g√©n√©ratifs de graphes, notamment avec des Graphs Neural Networks. Les m√©thodologies d√©velopp√©es seront appliqu√©es √† des jeux de donn√©es g√©nomiques disponibles pour de nombreuses populations natives et envahissantes de deux esp√®ces d‚Äôinsectes envahissants, la coccinelle Harmonia axyridis et la drosophile Drosophila suzukii.\n\n\n√âtudes\n\n\n\n2021 - 2024\nüè¢ MIA Paris-Saclay, Palaiseau\nEncadrant: Pierre Barbillon (MIA Paris-Saclay), Colin Fontaine (MNHM), Elisa Thebault (iEES).\n\n\n\n\n\nTh√®se : Prise en compte des effets d‚Äô√©chantillonnage pour la d√©tection de structure des r√©seaux √©cologiques\nTh√®se soutenue au campus Agro Paris-Saclay le 16 d√©cembre 2024.\nLien vers la th√®se\nMots-cl√©s: Statistiques appliqu√©es √† l‚Äô√©cologie, Th√©orie des graphes, r√©seaux plantes-pollinisateurs, mod√®le √† blocs stochastiques, algorithme EM, √©chantillonnage, r√©seaux de neurones convolutifs.\n\n\n\n\n\n\n\n2020 - 2021\nüè¢ Sorbonne Universit√©, Paris\n\n\n\n\n\nMaster 2 de Math√©matiques et Application, parcours Statistiques.\nMots-cl√©s: Mod√®les lin√©aires en grande dimension, apprentissage statistique, apprentissage automatique, optimisation stochastique, analyse statistique de graphe, acquisition compress√©e.\n\n\n\n\n\n\n\n2019 - 2020\nüè¢ Sorbonne Universit√©, Paris\n\n\n\n\n\nMaster 1 de Math√©matiques et Application.\nMots-cl√©s: Statistiques avanc√©es, statistiques computationnelles, g√©om√©trie diff√©rentielle\n\n\n\n\n\n\n\n2018 - 2019\nüè¢ Sorbonne Universit√©, Paris\n\n\n\n\n\nLicence 3 de Math√©matiques\nMots-cl√©s: Statistiques num√©riques, approximation num√©rique de fonction, th√©orie de la mesure.\n\n\n\n\n\n\n\n2016 - 2018\nüè¢ Lyc√©e F√©nelon, Paris\n\n\n\n\n\nClasse Pr√©paratoire aux Grandes √âcoles Math-Physique\n\n\n\n\n\n\nExp√©riences\n\n\n\nDepuis 2025\nüè¢ Centre Biologique de Gestion des Populations, Montpellier\n\n\n\n\n\nPost-Doctorat : D√©veloppement de m√©thodes statistiques pour la reconstruction de routes d‚Äôinvasion biologique, inf√©rence de sc√©narios √©volutionnaires complexes √† partir de donn√©es g√©nomiques en utilisant des graphes admixtures.\nMots-cl√©s: G√©n√©tique des populations, Graphes admixtures\n\nExploration de l‚Äôespace des graphes admixtures et probl√®mes d‚Äôidentifiabilit√©s.\nUtilisation de mod√®les g√©n√©ratifs de graphes.\nApplications √† des donn√©es g√©n√©tiques d‚Äôesp√®ces invasives.\n\n\n\n\n\n\n\n\nMai-Sep 2021\nüè¢ CEA, Saclay\nEncadrants : Valerio Calvelli (CEA)\n\n\n\n\n\nStage de M2 : Participation √† la conception du design magn√©tique d‚Äôune machine IRM √† 14 T en utilisant diff√©rentes techniques d‚Äôintelligence artificielle.\nMots-cl√©s: Opera-2d 2020, algorithme g√©n√©tique, optimisation sous contrainte, magn√©tisme\n\nMettre en place un code Python capable d‚Äôinteragir avec le logiciel Opera-2d 2020.\nTrouver une configuration optimale respectant des contraintes √† l‚Äôaide d‚Äôun algorithme g√©n√©tique.\n\n\n\n\n\n\n\n\nMai-Sep 2021\nüè¢ Laboratoire de Probabilit√©, Statistiques et Mod√©lisation, Paris\nEncadrants : Anna Bonnet (LPSM), Sylvain Le Corff (LPSM), Harry Sokol (AP-HP)\n\n\n\n\n\nStage de M1 : Apprentissage statistique pour tester l‚Äôinfluence du microbiote intestinal sur la r√©ponse au traitement de la maladie de Crohn.\nMots-cl√©s: Machine learning, for√™ts al√©atoires, s√©lection de variables en grande dimension, MCMC\n\nS√©lectionner des variables pertinentes √† l‚Äôaide de for√™ts al√©atoires et comparer les r√©sultats avec d‚Äôautres √©tudes.\nImpl√©menter un algorithme MCMC de s√©lection de variables dans un mod√®le de r√©gression logistique.\nLe stage a abouti √† l‚Äô√©criture d‚Äôun article publi√© : Impact of the Ileal Microbiota on Surgical Site Infections in Crohn‚Äôs Disease : A Nationwide Prospective Cohort, Journal of Crohn‚Äôs and Colitis, Volume 16, Issue 8, August 2022, Pages 1211‚Äì1221, https://doi.org/10.1093/ecco-jcc/jjac026"
  },
  {
    "objectID": "bibliographie.html",
    "href": "bibliographie.html",
    "title": "Publications",
    "section": "",
    "text": "Interpretability of Graph Neural Networks to Assess Effects of Global Change Drivers on Ecological Networks\n\n\n\nCitizen Science\n\nEcological network\n\nGraph Neural Network\n\nHilbert-Schmidt Independence Criterion\n\nSampling Effect\n\nFeature Importance\n\n\n\nWe explore existing methods for interpreting GNNs in order to highlight the effects of various environmental covariates on pollination network connectivity.\n\n\n\n\n\nJan 13, 2026\n\n\nEmre Anakok, Pierre Barbillon, Colin Fontaine, Elisa Thebault\n\n\n\n\n\n\n\n\n\n\n\n\nDisentangling the structure of ecological bipartite networks from observation processes\n\n\n\nLatent Block Model\n\nSampling Effect\n\nStochastic Expectation Maximization\n\nNestedness\n\nModularity\n\n\n\nA new model for network analysis.\n\n\n\n\n\nMar 17, 2025\n\n\nEmre Anakok, Pierre Barbillon, Colin Fontaine, Elisa Thebault\n\n\n\n\n\n\n\n\n\n\n\n\nBipartite Graph Variational Auto-Encoder with Fair Latent Representation to Account for Sampling Bias in Ecological Networks\n\n\n\nCitizen Science\n\nEcological network\n\nGraph Neural Network\n\nHilbert-Schmidt Independence Criterion\n\nSampling Effect\n\n\n\nTranslating the fairness framework commonly considered in sociology in order to address sampling bias in ecology using graph embeddings.\n\n\n\n\n\nJul 15, 2024\n\n\nEmre Anakok, Pierre Barbillon, Colin Fontaine, Elisa Thebault\n\n\n\n\n\n\n\n\n\n\n\n\nImpact of the Ileal Microbiota on Surgical Site Infections in Crohn‚Äôs Disease: A Nationwide Prospective Cohort\n\n\n\nRandom forest\n\nGut microbiota\n\nCrohn‚Äôs disease\n\nPrediction\n\n\n\nThe objective of this study was to assess the impact of the gut microbiota on surgical site infection in Crohn‚Äôs disease.\n\n\n\n\n\nFeb 26, 2022\n\n\nEmre Anakok, Cl√©ment Julien\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Emre Anakok",
    "section": "",
    "text": "Je suis actuellement enseignant chercheur √† l‚ÄôIUT de Paris - Rives de Seine, Universit√© Paris Cit√©, et au laboratoire du MAP5 (UMR 8145)."
  },
  {
    "objectID": "latex/Back_propagation.html",
    "href": "latex/Back_propagation.html",
    "title": "Back propagation",
    "section": "",
    "text": "\\documentclass[border=3pt,tikz]{standalone}\n\\usepackage{amsmath} % for aligned\n\\usepackage{listofitems} % for \\readlist to create arrays\n\\usetikzlibrary{arrows.meta} % for arrow size\n\\usepackage[outline]{contour} % glow around text\n\\contourlength{1.4pt}\n\n% COLORS\n\n\\usepackage{contour} % glow around text\n\\contourlength{1.4pt}\n\n\\usepackage[dvipsnames]{xcolor}\n\\usepackage{pgfplots}\n\\definecolor{taupegray}{rgb}{0.55, 0.52, 0.54}\n\\usepackage{neuralnetwork}\n\n\\usepackage{tikz-network}\n\\usepackage{xcolor}\n\\colorlet{myred}{red!80!black}\n\\colorlet{myblue}{blue!80!black}\n\\colorlet{mygreen}{green!60!black}\n\\colorlet{myyellow}{yellow!60!white}\n\\colorlet{myorange}{orange!70!red!60!black}\n\\colorlet{mydarkred}{red!30!black}\n\\colorlet{mydarkblue}{blue!40!black}\n\\colorlet{mydarkgreen}{green!30!black}\n\\colorlet{mydarkyellow}{yellow!30!black}\n\n\\tikzset{\n  &gt;=latex, % for default LaTeX arrow head\n  node/.style={thick,circle,draw=myblue,minimum size=22,inner sep=0.5,outer sep=0.6},\n  node in/.style={node,green!20!black,draw=mygreen!30!black,fill=mygreen!25},\n  node hidden/.style={node,blue!20!black,draw=myblue!30!black,fill=myblue!20},\n  node convol/.style={node,orange!20!black,draw=myorange!30!black,fill=myorange!20},\n  node out/.style={node,red!20!black,draw=myred!30!black,fill=myred!20},\n  connect/.style={thick,mydarkblue}, %,line cap=round\n  connect arrow/.style={-{Latex[length=4,width=3.5]},thick,mydarkblue,shorten &lt;=0.5,shorten &gt;=1},\n  node 1/.style={node in}, % node styles, numbered for easy mapping with \\nstyle\n  node 2/.style={node hidden},\n  node 3/.style={node out}\n}\n\\def\\nstyle{int(\\lay&lt;\\Nnodlen?min(2,\\lay):3)} % map layer number onto 1, 2, or 3\n\n\\begin{document}\n\n\n\\contourlength{2pt}\n\\begin{tikzpicture}[x=2.2cm,y=1.4cm]\n  \\message{^^JNeural network, shifted}\n  \\readlist\\Nnod{4,5,5,5,3} % array of number of nodes per layer\n  \\readlist\\Nstr{n,m_1,m_2,m_3,m} % array of string number of nodes per layer\n  \\readlist\\Cstr{\\strut x^{(0)},x^{(\\prev)},x^{(\\prev)},x^{(\\prev)},y} % array of coefficient symbol per layer\n  \\def\\yshift{0.5} % shift last node for dots\n  \n  \\message{^^J  Layer}\n  \\foreachitem \\N \\in \\Nnod{ % loop over layers\n    \\def\\lay{\\Ncnt} % alias of index of current layer\n    \\pgfmathsetmacro\\prev{int(\\Ncnt-1)} % number of previous layer\n    \\message{\\lay,}\n    \\foreach \\i [evaluate={\\c=int(\\i==\\N); \\y=\\N/2-\\i-\\c*\\yshift;\n                 \\index=(\\i&lt;\\N?int(\\i):\"\\Nstr[\\lay]\");\n                 \\x=1\\lay; \\n=\\nstyle;}] in {1,...,\\N}{ % loop over nodes\n      % NODES\n      %\\ifnum \\lay&gt;1\n      \\node[node \\n] (N\\lay-\\i) at (1.2*\\x,\\y) {$\\frac{\\partial \\varepsilon}{\\partial \\Cstr[\\lay]_{\\index}}$};\n      %\\else\n       % \\node[node \\n] (N\\lay-\\i) at (1.2*\\x,\\y) {$\\Cstr[\\lay]_{\\index}$};\n    %\\fi\n      \n      % CONNECTIONS\n      \\ifnum\\lay&gt;1 % connect to previous layer\n        \\foreach \\j in {1,...,\\Nnod[\\prev]}{ % loop over nodes in previous layer\n          \\draw[connect arrow,white,line width=1.2] (N\\prev-\\j) -- (N\\lay-\\i);\n          \\draw[connect arrow,myblue!20] (N\\lay-\\i)--(N\\prev-\\j);\n          %\\draw[connect] (N\\prev-\\j.0) -- (N\\lay-\\i.180); % connect to left\n        }\n      \\fi % else: nothing to connect first layer\n      \n    }\n    \\path (N\\lay-\\N) --++ (0,1+\\yshift) node[midway,scale=1.5] {$\\vdots$};\n  }\n\n  \\node[thick,circle,draw=mydarkyellow,fill=myyellow,minimum size=22,inner sep=0.5,outer sep=0.6](epsilon) at ($(N5-2) + (1,0)$) {$\\varepsilon$};\n    \\foreach \\j in {1,2,3}{ % loop over nodes in previous layer\n          %\\draw[connect arrow,white,line width=1.2] (N5-\\j) -- (epsilon);\n          \n          }\n    \n    \\foreach \\j [evaluate={\\index=(\\j&lt;3?int(\\j):\"k\");}] in {1,...,3}{ % loop over nodes in previous layer\n         %\\draw[connect arrow,white,line width=1.2] (NI-\\j) -- (NO);\n         \\draw[connect arrow]   (epsilon)-- (N5-\\j)\n           node[pos=0.50] {};\n           %node[pos=0.50] {\\colorbox{white}{\\makebox[2em]{{$\\frac{\\partial\\varepsilon}{\\partial y_\\index}$}}};\n      }\n\n    \\draw[connect arrow] (N5-1) --(N4-3)\n     node[pos=0.50] {\\contour[60]{white}{$\\frac{\\partial \\varepsilon}{\\partial w^{(3)}_{1,3}}$}};\n    \\draw[connect arrow] (N5-2) --(N4-3)\n    node[pos=0.50] {\\contour[60]{white}{$\\frac{\\partial  \\varepsilon}{\\partial w^{(3)}_{2,3}}$}};\n    \\draw[connect arrow] (N5-3) --(N4-3)\n    node[pos=0.50] {\\contour[60]{white}{$\\frac{\\partial  \\varepsilon}{\\partial w^{(3)}_{3,3}}$}};\n    \\draw[connect arrow] (N4-3) --(N3-3)\n    node[pos=0.50] {\\contour[60]{white}{$\\frac{\\partial\\varepsilon}{\\partial w^{(2)}_{3,3}}$}};\n    \n      \n  % LABELS\n  \\node[above=0,align=center,mygreen!60!black] at (N1-1.90) {Couche\\\\[-0.2em]d'entr√©e};\n  \\node[above=0,align=center,myblue!60!black] at (N3-1.90) {Couche(s) cach√©e(s)};\n  \\node[above=0,align=center,myred!60!black] at (N\\Nnodlen-1.90) {Couche\\\\[-0.2em]de sortie};\n   \\node[above=0,align=center,mydarkyellow!60!black] at (epsilon) {Fonction\\\\[-0.2em]de co√ªt\\\\[-0.2em]};\n\n   \\node[below=1,align=center ] at ($(N3-5) + (0,0.5)$) {$\\begin{aligned}\n     & \\color{myblue} \\frac{\\partial \\varepsilon }{\\partial x_j^{(l)}} \\color{black} = \n  \\sum_{i=1} ^{m_{l+1}} w_{i,j}^{(l)} \\sigma ' (z_i^{(l)})  \\color{myblue} \\frac{\\partial \\varepsilon }{\\partial x_i^{(l+1)}}\\\\\n  & \\frac{\\partial \\varepsilon}{\\partial w_{j,k}^{(l)}} = x_k^{(l)} \\sigma '(z_j^{(l)}) \\color{myblue} \\frac{\\partial \\varepsilon }{\\partial x_j^{(l+1)}} \n  \\end{aligned}$};\n  \n\\end{tikzpicture}\n\n\\end{document}"
  },
  {
    "objectID": "latex/Message_passing.html",
    "href": "latex/Message_passing.html",
    "title": "Message Passing",
    "section": "",
    "text": "\\documentclass[border=3pt,tikz]{standalone}\n\\usepackage[dvipsnames]{xcolor}\n\\usepackage{pgfplots}\n\\definecolor{taupegray}{rgb}{0.55, 0.52, 0.54}\n\\def\\general_height{0.2}\n\n\\usepackage{tikz-network}\n\n\\begin{document}\n\\begin{tikzpicture}\n\n\\Text[x=-0.18,y=3cm]{\\Large Couche $l$}\n\\Text[x=14cm,y=3cm]{\\Large Couche $l+1$}\n\n\\begin{scope}[scale=2]\n\\Vertex[x=0.88,y=0.48,label=A,color=red]{A}\n\\Vertex[x=-0.18,y=0.98,label=B,color=green]{B}\n\\Vertex[x=-1,y=0.12,label=C,color=pink]{C}\n\\Vertex[x=-0.42,y=-0.9,label=D,color=yellow,style={line width=1mm}]{D}\n\\Vertex[x=0.72,y=-0.69,label=E,color=cyan]{E}\n\\Edge[color=gray](A)(B)\n\\Edge[color=gray](A)(C)\n\\Edge[lw=3](A)(D)\n\\Edge[color=gray](A)(E)\n\\Edge[color=gray](B)(C)\n\\Edge[lw=3](B)(D)\n\\Edge[color=gray](B)(E)\n\\end{scope}\n\n\\begin{scope}[xshift=3cm]\n\\Vertex[x=0,y=0,Pseudo]{K}\n\\begin{axis}[ybar stacked,\nheight=\\general_height\\textwidth,\n bar width=13pt,ymin=0,\n x=17pt,\n ytick=\\empty,\n xtick=\\empty,\n hide axis]\n    \\addplot[fill=red,opacity=0.5] coordinates\n        {(0,0.1) (1,0.1) (2,0.15) (3,0.2) (4,0.15)};\n    \\end{axis}\n\n\\Vertex[x=0,y=1,Pseudo]{L}\n\\begin{axis}[ybar stacked, \nyshift = 1cm,\nheight=\\general_height\\textwidth,\n bar width=13pt,ymin=0,\n x=17pt,\n ytick=\\empty,\n xtick=\\empty,\n hide axis]\n    \\addplot[fill=green,opacity=0.5] coordinates\n        {(0,0.2) (1,0.05) (2,0.1) (3,0.15) (4,0.05)};\n    \\end{axis}\n\n\\Vertex[x=0,y=-1,Pseudo]{M}\n\\begin{axis}[ybar stacked, \nyshift = -1cm,\nheight=\\general_height\\textwidth,\n bar width=13pt,ymin=0,\n x=17pt,\n ytick=\\empty,\n xtick=\\empty,\n hide axis]\n    \\addplot[fill=yellow,opacity=0.5] coordinates\n        {(0,0.1) (1,0.2) (2,0) (3,0.1) (4,0.1)};\n    \\end{axis}\n\n\\draw (0,-1.5cm) -- (3,-1.5cm);\n \\Text[x=3.5,y=-1.5cm]{\\Huge $\\mathbf{+}$}\n\n\\begin{axis}[ybar stacked,\nheight=0.27\\textwidth,\nyshift = -3.5cm,\n bar width=13pt,ymin=0,\n x=17pt,\n ytick=\\empty,\n xtick=\\empty,\n hide axis]\n \\addplot[fill=yellow,opacity=0.5] coordinates\n        {(0,0.1) (1,0.2) (2,0) (3,0.1) (4,0.1)};\n  \\addplot[fill=red,opacity=0.5] coordinates\n        {(0,0.1) (1,0.1) (2,0.15) (3,0.2) (4,0.15)};\n \\addplot[fill=green,opacity=0.5] coordinates\n        {(0,0.2) (1,0.05) (2,0.1) (3,0.15) (4,0.05)};   \n \\end{axis}\n \\Vertex[x=3,y=-3.5,Pseudo]{N}  \n\\end{scope}\n\\node[align=center,text width=5cm] at (1,-4.5) {\\large Agr√©gation des donn√©es des noeuds voisins};\n\n\\Edge[bend=35,style={dashed},Direct](A)(K)\n\\Edge[bend=35,style={dashed},Direct](B)(L)\n\\Edge[bend=-35,style={dashed},Direct](D)(M)\n\n\\begin{scope}[xshift=10cm,yshift=-3.5cm]\n    \\begin{axis}[ybar stacked, \nheight=\\general_height\\textwidth,\n bar width=13pt,ymin=0,\n x=17pt,\n ytick=\\empty,\n xtick=\\empty,\n hide axis]\n    \\addplot[fill=purple] coordinates\n        {(0,0.2) (1,0.15) (2,0.1) (3,0.1) };\n    \\end{axis}\n \\Vertex[x=0,y=0,Pseudo]{N'}    \n\\Vertex[x=2,y=0,Pseudo]{N''}    \n\n\n\\end{scope}\n\n\\Edge[style={dashed},Direct,label={\\Huge $f$}](N)(N')\n\\node[align=center,text width=3.5cm] at (8cm,-4.5) {\\large Transformation de la donn√©e agr√©g√©e};\n\n\n\\begin{scope}[xshift=14cm,scale=2]\n    \\Vertex[x=0.88,y=0.48,label=A,color=purple,opacity=0.5]{A2}\n\\Vertex[x=-0.18,y=0.98,label=B,color=purple,opacity=0.7]{B2}\n\\Vertex[x=-1,y=0.12,label=C,color=purple,opacity=0.4]{C2}\n\\Vertex[x=-0.42,y=-0.9,label=D,color=purple]{D2}\n\\Vertex[x=0.72,y=-0.69,label=E,color=purple,opacity=0.2]{E2}\n\\Edge[color=gray](A2)(B2)\n\\Edge[color=gray](A2)(C2)\n\\Edge[color=gray](A2)(D2)\n\\Edge[color=gray](A2)(E2)\n\\Edge[color=gray](B2)(C2)\n\\Edge[color=gray](B2)(D2)\n\\Edge[color=gray](B2)(E2)\n\\end{scope}\n\\node[align=center,text width=5.5cm] at (13cm,-4.5) {\\large Mise √† jour du graphe avec la nouvelle information};\n\n\\Edge[bend=-35,style={dashed},Direct](N'')(D2)\n\n\n\\end{tikzpicture}\n\\end{document}"
  },
  {
    "objectID": "latex.html",
    "href": "latex.html",
    "title": "Latex plots",
    "section": "",
    "text": "Vous trouverez ici des fichiers LaTeX autonomes mis √† disposition pour g√©n√©rer des sch√©mas au format PDF.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArtificial neuron\n\n\nBasic unit of neural networks\n\n\n\n\n\nMar 18, 2025\n\n\nEmre Anakok\n\n\n\n\n\n\n\n\n\n\n\n\nAuto encoder\n\n\nScheme of auto encoder\n\n\n\n\n\nMar 18, 2025\n\n\nEmre Anakok\n\n\n\n\n\n\n\n\n\n\n\n\nBack propagation\n\n\nNeural network with back propagation equation\n\n\n\n\n\nOct 24, 2024\n\n\nEmre Anakok\n\n\n\n\n\n\n\n\n\n\n\n\nEtymology of the word ‚Äú√©chantillonnage‚Äù\n\n\nOrigin of the word \"√©chantillonnage\", which means \"sampling\" in French\n\n\n\n\n\nMar 18, 2025\n\n\nEmre Anakok\n\n\n\n\n\n\n\n\n\n\n\n\nLatent block model\n\n\nProbabilistic model for bipartite networks, credits to Louis Lacoste\n\n\n\n\n\nMar 18, 2025\n\n\nEmre Anakok\n\n\n\n\n\n\n\n\n\n\n\n\nLink prediction\n\n\nLink prediction task for networks\n\n\n\n\n\nMar 18, 2025\n\n\nEmre Anakok\n\n\n\n\n\n\n\n\n\n\n\n\nMatrix formulation of neural networks\n\n\nA layer of a neural network\n\n\n\n\n\nMar 18, 2025\n\n\nEmre Anakok\n\n\n\n\n\n\n\n\n\n\n\n\nMessage Passing\n\n\nScheme of message passing\n\n\n\n\n\nOct 24, 2024\n\n\nEmre Anakok\n\n\n\n\n\n\n\n\n\n\n\n\nMissing data VS incomplete data\n\n\nDifference between missing data (left) and incomplete data (right) in the context of networks.\n\n\n\n\n\nMar 18, 2025\n\n\nEmre Anakok\n\n\n\n\n\n\n\n\n\n\n\n\nNeural network\n\n\nClassical neural network.\n\n\n\n\n\nMar 18, 2025\n\n\nEmre Anakok\n\n\n\n\n\n\n\n\n\n\n\n\nNode classification\n\n\nSupervised node classification task for networks\n\n\n\n\n\nMar 18, 2025\n\n\nEmre Anakok\n\n\n\n\n\n\n\n\n\n\n\n\nNode clustering\n\n\nUnsupervised node clustering task for networks\n\n\n\n\n\nMar 18, 2025\n\n\nEmre Anakok\n\n\n\n\n\n\n\n\n\n\n\n\nPooling edges\n\n\nEdge pooling operation, also known as edge feature aggregation.\n\n\n\n\n\nMar 18, 2025\n\n\nEmre Anakok\n\n\n\n\n\n\n\n\n\n\n\n\nPooling from edges to nodes\n\n\nEach node gather data from adjacent edges.\n\n\n\n\n\nMar 18, 2025\n\n\nEmre Anakok\n\n\n\n\n\n\n\n\n\n\n\n\nPooling from nodes to edges\n\n\nPooling operation from nodes to edges\n\n\n\n\n\nMar 18, 2025\n\n\nEmre Anakok\n\n\n\n\n\n\n\n\n\n\n\n\nPooling nodes\n\n\nNode pooling operation, also known as node feature aggregation.\n\n\n\n\n\nOct 24, 2024\n\n\nEmre Anakok\n\n\n\n\n\n\n\n\n\n\n\n\nSpipoll auto encoder\n\n\nScheme of Bipartite auto encoder for Spipoll data set\n\n\n\n\n\nMar 18, 2025\n\n\nEmre Anakok\n\n\n\n\n\n\n\n\n\n\n\n\nSpipoll full encoder\n\n\nScheme of Bipartite auto encoder for the Spipoll data set\n\n\n\n\n\nMar 18, 2025\n\n\nEmre Anakok\n\n\n\n\n\n\n\n\n\n\n\n\nStochastic block model\n\n\nProbabilistic model of network, credits to Sophie Donnet and Pierre Barbillon\n\n\n\n\n\nMar 18, 2025\n\n\nEmre Anakok\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/BFVGAE.html",
    "href": "posts/BFVGAE.html",
    "title": "Bipartite Graph Variational Auto-Encoder with Fair Latent Representation to Account for Sampling Bias in Ecological Networks",
    "section": "",
    "text": "We propose a method to represent bipartite networks using graph embeddings tailored to tackle the challenges of studying ecological networks, such as the ones linking plants and pollinators, where many covariates need to be accounted for, in particular to control for sampling bias. We adapt the variational graph auto-encoder approach to the bipartite case, which enables us to generate embeddings in a latent space where the two sets of nodes are positioned based on their probability of connection. We translate the fairness framework commonly considered in sociology in order to address sampling bias in ecology. By incorporating the Hilbert-Schmidt independence criterion (HSIC) as an additional penalty term in the loss we optimize, we ensure that the structure of the latent space is independent of continuous variables, which are related to the sampling process. Finally, we show how our approach can change our understanding of ecological networks when applied to the Spipoll data set, a citizen science monitoring program of plant-pollinator interactions to which many observers contribute, making it prone to sampling bias.\nLink to preprint\nGitHub Repository"
  },
  {
    "objectID": "posts/CoOPLBM.html",
    "href": "posts/CoOPLBM.html",
    "title": "Disentangling the structure of ecological bipartite networks from observation processes",
    "section": "",
    "text": "The structure of a bipartite interaction network can be described by providing a clustering for each of the two types of nodes. Such clusterings are outputted by fitting a Latent Block Model (LBM) on an observed network that comes from a sampling of species interactions in the field. However, the sampling is limited and possibly uneven. This may jeopardize the fit of the LBM and then the description of the structure of the network by detecting structures which result from the sampling and not from actual underlying ecological phenomena. If the observed interaction network consists of a weighted bipartite network where the number of observed interactions between two species is available, the sampling efforts for all species can be estimated and used to correct the LBM fit. We propose to combine an observation model that accounts for sampling and an LBM for describing the structure of underlying possible ecological interactions. We develop an original inference procedure for this model, the efficiency of which is demonstrated on simulation studies. The pratical interest in ecology of our model is highlighted on a large dataset of plant-pollinator network.\nLink to paper\nGitHub repository"
  },
  {
    "objectID": "posts/CoOPLBM.html#abstract",
    "href": "posts/CoOPLBM.html#abstract",
    "title": "Disentangling the structure of ecological bipartite networks from observation processes",
    "section": "",
    "text": "The structure of a bipartite interaction network can be described by providing a clustering for each of the two types of nodes. Such clusterings are outputted by fitting a Latent Block Model (LBM) on an observed network that comes from a sampling of species interactions in the field. However, the sampling is limited and possibly uneven. This may jeopardize the fit of the LBM and then the description of the structure of the network by detecting structures which result from the sampling and not from actual underlying ecological phenomena. If the observed interaction network consists of a weighted bipartite network where the number of observed interactions between two species is available, the sampling efforts for all species can be estimated and used to correct the LBM fit. We propose to combine an observation model that accounts for sampling and an LBM for describing the structure of underlying possible ecological interactions. We develop an original inference procedure for this model, the efficiency of which is demonstrated on simulation studies. The pratical interest in ecology of our model is highlighted on a large dataset of plant-pollinator network.\nLink to paper\nGitHub repository"
  },
  {
    "objectID": "posts/ImpactMicrobiota.html",
    "href": "posts/ImpactMicrobiota.html",
    "title": "Impact of the Ileal Microbiota on Surgical Site Infections in Crohn‚Äôs Disease: A Nationwide Prospective Cohort",
    "section": "",
    "text": "Background and aims: Surgery is performed in 50-70% of Crohn‚Äôs disease [CD] patients, and its main risk is surgical site infection [SSI]. The microbiota has been extensively assessed in CD but not as a potential risk factor for septic morbidity. The objective of this study was to assess the impact of the gut microbiota on SSI in CD.\nMethods: We used the multicentric REMIND prospective cohort to identify all patients who experienced SSI after ileocolonic resection for CD, defined as any postoperative local septic complication within 90 days after surgery: wound abscess, intra-abdominal collection, anastomotic leakage or enterocutaneous fistula. The mucosa-associated microbiota of the ileal resection specimen was analysed by 16S gene sequencing in 149 patients. The variable selection and prediction were performed with random forests [R package VSURF] on clinical and microbiotal data. The criterion of performance that we considered was the area under the Receiver Operating Characteristic [ROC] curve [AUC].\nResults: SSI occurred in 24 patients [16.1%], including 15 patients [10.1%] with major morbidity. There were no significant differences between patients with or without SSI regarding alpha and beta diversity. The top selected variables for the prediction of SSI were all microbiota-related. The maximum AUC [0.796] was obtained with a model including 14 genera, but an AUC of 0.78 had already been obtained with a model including only six genera [Hungatella, Epulopiscium, Fusobacterium, Ruminococcaceae_ucg_009, Actinomyces and Ralstonia].\nConclusion: The gut microbiota has the potential to predict SSI after ileocolonic resection for CD. It might play a role in this frequent postoperative complication.\nLink to paper"
  },
  {
    "objectID": "posts/BFVGAE.html#abstract",
    "href": "posts/BFVGAE.html#abstract",
    "title": "Bipartite Graph Variational Auto-Encoder with Fair Latent Representation to Account for Sampling Bias in Ecological Networks",
    "section": "",
    "text": "We propose a method to represent bipartite networks using graph embeddings tailored to tackle the challenges of studying ecological networks, such as the ones linking plants and pollinators, where many covariates need to be accounted for, in particular to control for sampling bias. We adapt the variational graph auto-encoder approach to the bipartite case, which enables us to generate embeddings in a latent space where the two sets of nodes are positioned based on their probability of connection. We translate the fairness framework commonly considered in sociology in order to address sampling bias in ecology. By incorporating the Hilbert-Schmidt independence criterion (HSIC) as an additional penalty term in the loss we optimize, we ensure that the structure of the latent space is independent of continuous variables, which are related to the sampling process. Finally, we show how our approach can change our understanding of ecological networks when applied to the Spipoll data set, a citizen science monitoring program of plant-pollinator interactions to which many observers contribute, making it prone to sampling bias.\nLink to preprint\nGitHub Repository"
  },
  {
    "objectID": "posts/ImpactMicrobiota.html#abstract",
    "href": "posts/ImpactMicrobiota.html#abstract",
    "title": "Impact of the Ileal Microbiota on Surgical Site Infections in Crohn‚Äôs Disease: A Nationwide Prospective Cohort",
    "section": "",
    "text": "Background and aims: Surgery is performed in 50-70% of Crohn‚Äôs disease [CD] patients, and its main risk is surgical site infection [SSI]. The microbiota has been extensively assessed in CD but not as a potential risk factor for septic morbidity. The objective of this study was to assess the impact of the gut microbiota on SSI in CD.\nMethods: We used the multicentric REMIND prospective cohort to identify all patients who experienced SSI after ileocolonic resection for CD, defined as any postoperative local septic complication within 90 days after surgery: wound abscess, intra-abdominal collection, anastomotic leakage or enterocutaneous fistula. The mucosa-associated microbiota of the ileal resection specimen was analysed by 16S gene sequencing in 149 patients. The variable selection and prediction were performed with random forests [R package VSURF] on clinical and microbiotal data. The criterion of performance that we considered was the area under the Receiver Operating Characteristic [ROC] curve [AUC].\nResults: SSI occurred in 24 patients [16.1%], including 15 patients [10.1%] with major morbidity. There were no significant differences between patients with or without SSI regarding alpha and beta diversity. The top selected variables for the prediction of SSI were all microbiota-related. The maximum AUC [0.796] was obtained with a model including 14 genera, but an AUC of 0.78 had already been obtained with a model including only six genera [Hungatella, Epulopiscium, Fusobacterium, Ruminococcaceae_ucg_009, Actinomyces and Ralstonia].\nConclusion: The gut microbiota has the potential to predict SSI after ileocolonic resection for CD. It might play a role in this frequent postoperative complication.\nLink to paper"
  },
  {
    "objectID": "about.html#exp√©rience",
    "href": "about.html#exp√©rience",
    "title": "Qui suis-je ?",
    "section": "Exp√©rience",
    "text": "Exp√©rience\n\n\nTimeline\n\n\n\n\nDinosaurs Roamed the Earth\n\n\nRAWWWWWWRRR üê¢ü¶Ç\n\n\n\n\nCreative Component Launched\n\n\n‚ÄúWe can be all things to all people!‚Äù üì£\n\n\n\n\nSquareflair was Born\n\n\n\n\n‚ÄúWe can be all things to Squarespace users!‚Äù üì£\n\n\n\n\nSquareflair Today\n\n\n‚ÄúWe design and build from scratch!‚Äù üì£\n\n\nWhen we say 100% custom we mean it‚Äî and we build all sites on the Squarespace Developer platform.\n\n\nDid you know that all of our pixels are hand-forged from the rarest of subpixels grown and harvested in the Nerd Forest? ü§úüí•ü§õ\n\n  &lt;p&gt;&lt;strong&gt;Our success can be measured by lives and brands enhanced by 9+ years of 100% Squarespace-focused service!&lt;/strong&gt;&lt;/p&gt;\n  \n\nsquareflair.com\n\n&lt;/li&gt;"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Qui suis-je ?",
    "section": "Experience",
    "text": "Experience\n\n\n  \n    \n    \n      Postdoctoral Position\n      LPSM / IMT\n      Oct 2019 ‚Äì Present ¬∑ Paris / Toulouse\n      \n        Courses at PolyTech for master students\n        Theoretical research on post hoc bounds\n        Collaboration on CNV dataset\n        Astrophysics research\n      \n    \n  \n\n  \n    \n    \n      PhD Student\n      AgroParisTech\n      Oct 2016 ‚Äì Sep 2019 ¬∑ Paris / Grignon\n      \n        Courses for first and second-year students\n        Theoretical research on multivariate models\n        Collaboration with immunologists"
  },
  {
    "objectID": "about.html#exp√©riences",
    "href": "about.html#exp√©riences",
    "title": "Qui suis-je ?",
    "section": "Exp√©riences",
    "text": "Exp√©riences"
  },
  {
    "objectID": "about.html#present",
    "href": "about.html#present",
    "title": "Qui suis-je ?",
    "section": "2024 - Present",
    "text": "2024 - Present\nSoftware Engineer at XYZ Corp\n- Developing web applications using React and Node.js\n- Leading a team of 5 developers"
  },
  {
    "objectID": "about.html#section",
    "href": "about.html#section",
    "title": "Qui suis-je ?",
    "section": "2021 - 2024",
    "text": "2021 - 2024\nüè¢ MIA Paris-Saclay, Palaiseau\nEncadrant: Pierre Barbillon (MIA Paris-Saclay), Colin Fontaine (MNHM), Elisa Thebault (iEES)."
  },
  {
    "objectID": "about.html#section-1",
    "href": "about.html#section-1",
    "title": "Qui suis-je ?",
    "section": "2020 - 2021",
    "text": "2020 - 2021\nüè¢ Sorbonne Universit√©, Paris"
  },
  {
    "objectID": "about.html#section-2",
    "href": "about.html#section-2",
    "title": "Qui suis-je ?",
    "section": "2019 - 2020",
    "text": "2019 - 2020\nüè¢ Sorbonne Universit√©, Paris"
  },
  {
    "objectID": "about.html#section-3",
    "href": "about.html#section-3",
    "title": "Qui suis-je ?",
    "section": "2018 - 2019",
    "text": "2018 - 2019\nüè¢ Sorbonne Universit√©, Paris"
  },
  {
    "objectID": "about.html#section-4",
    "href": "about.html#section-4",
    "title": "Qui suis-je ?",
    "section": "2016 - 2018",
    "text": "2016 - 2018\nüè¢ Lyc√©e F√©nelon, Paris"
  },
  {
    "objectID": "about.html#depuis-2025",
    "href": "about.html#depuis-2025",
    "title": "Qui suis-je ?",
    "section": "Depuis 2025",
    "text": "Depuis 2025\nüè¢ Centre Biologique de Gestion des Populations, Montpellier"
  },
  {
    "objectID": "about.html#mai-sep-2021",
    "href": "about.html#mai-sep-2021",
    "title": "Qui suis-je ?",
    "section": "Mai-Sep 2021",
    "text": "Mai-Sep 2021\nüè¢ CEA, Saclay\nEncadrants : Valerio Calvelli (CEA)"
  },
  {
    "objectID": "about.html#jul-sep-2020",
    "href": "about.html#jul-sep-2020",
    "title": "Qui suis-je ?",
    "section": "Jul-Sep 2020",
    "text": "Jul-Sep 2020\nStage de M1 : Apprentissage statistique pour tester l‚Äôinfluence du microbiote intestinal sur la r√©ponse au traitement de la maladie de Crohn\nüè¢ Laboratoire de Probabilit√©, Statistiques et Mod√©lisation, Paris\nMots-cl√©s: Machine learning, for√™ts al√©atoires, s√©lection de variables en grande dimension, MCMC\nEncadrants : Anna Bonnet (LPSM), Sylvain Le Corff (LPSM), Harry Sokol (AP-HP)\n\nS√©lectionner des variables pertinentes √† l‚Äôaide de for√™ts al√©atoires et comparer les r√©sultats avec d‚Äôautres √©tudes.\nImpl√©menter un algorithme MCMC de s√©lection de variables dans un mod√®le de r√©gression logistique.\nLe stage a abouti √† l‚Äô√©criture d‚Äôun article publi√© : Impact of the Ileal Microbiota on Surgical Site Infections in Crohn‚Äôs Disease : A Nationwide Prospective Cohort, Journal of Crohn‚Äôs and Colitis, Volume 16, Issue 8, August 2022, Pages 1211‚Äì1221, https://doi.org/10.1093/ecco-jcc/jjac026"
  },
  {
    "objectID": "about.html#th√®se-prise-en-compte-des-effets-d√©chantillonnage-pour-la-d√©tection-de-structure-des-r√©seaux-√©cologiques",
    "href": "about.html#th√®se-prise-en-compte-des-effets-d√©chantillonnage-pour-la-d√©tection-de-structure-des-r√©seaux-√©cologiques",
    "title": "Qui suis-je ?",
    "section": "Th√®se : Prise en compte des effets d‚Äô√©chantillonnage pour la d√©tection de structure des r√©seaux √©cologiques",
    "text": "Th√®se : Prise en compte des effets d‚Äô√©chantillonnage pour la d√©tection de structure des r√©seaux √©cologiques\nTh√®se soutenue au campus Agro Paris-Saclay le 16 d√©cembre 2024.\nLien vers la th√®se\nMots-cl√©s: Statistiques appliqu√©es √† l‚Äô√©cologie, Th√©orie des graphes, r√©seaux plantes-pollinisateurs, mod√®le √† blocs stochastiques, algorithme EM, √©chantillonnage, r√©seaux de neurones convolutifs."
  },
  {
    "objectID": "about.html#section-5",
    "href": "about.html#section-5",
    "title": "Qui suis-je ?",
    "section": "2016 - 2018",
    "text": "2016 - 2018\nClasse Pr√©paratoire aux Grandes √âcoles Math-Physique\nüè¢ Lyc√©e F√©nelon, Paris"
  },
  {
    "objectID": "about.html#master-2-de-math√©matiques-et-application-parcours-statistiques.",
    "href": "about.html#master-2-de-math√©matiques-et-application-parcours-statistiques.",
    "title": "Qui suis-je ?",
    "section": "Master 2 de Math√©matiques et Application, parcours Statistiques.",
    "text": "Master 2 de Math√©matiques et Application, parcours Statistiques.\nMots-cl√©s: Mod√®les lin√©aires en grande dimension, apprentissage statistique, apprentissage automatique, optimisation stochastique, analyse statistique de graphe, acquisition compress√©e."
  },
  {
    "objectID": "about.html#master-2-de-math√©matiques-et-application-parcours-statistiques.-1",
    "href": "about.html#master-2-de-math√©matiques-et-application-parcours-statistiques.-1",
    "title": "Qui suis-je ?",
    "section": "Master 2 de Math√©matiques et Application, parcours Statistiques.",
    "text": "Master 2 de Math√©matiques et Application, parcours Statistiques.\nMots-cl√©s: Mod√®les lin√©aires en grande dimension, apprentissage statistique, apprentissage automatique, optimisation stochastique, analyse statistique de graphe, acquisition compress√©e."
  },
  {
    "objectID": "about.html#master-1-de-math√©matiques-et-application.",
    "href": "about.html#master-1-de-math√©matiques-et-application.",
    "title": "Qui suis-je ?",
    "section": "Master 1 de Math√©matiques et Application.",
    "text": "Master 1 de Math√©matiques et Application.\nMots-cl√©s: Statistiques avanc√©es, statistiques computationnelles, g√©om√©trie diff√©rentielle"
  },
  {
    "objectID": "about.html#licence-3-de-math√©matiques",
    "href": "about.html#licence-3-de-math√©matiques",
    "title": "Qui suis-je ?",
    "section": "Licence 3 de Math√©matiques",
    "text": "Licence 3 de Math√©matiques\nMots-cl√©s: Statistiques num√©riques, approximation num√©rique de fonction, th√©orie de la mesure."
  },
  {
    "objectID": "about.html#classe-pr√©paratoire-aux-grandes-√©coles-math-physique",
    "href": "about.html#classe-pr√©paratoire-aux-grandes-√©coles-math-physique",
    "title": "Qui suis-je ?",
    "section": "Classe Pr√©paratoire aux Grandes √âcoles Math-Physique",
    "text": "Classe Pr√©paratoire aux Grandes √âcoles Math-Physique"
  },
  {
    "objectID": "about.html#post-doctorat-d√©veloppement-de-m√©thodes-statistiques-pour-la-reconstruction-de-routes-dinvasion-biologique-inf√©rence-de-sc√©narios-√©volutionnaires-complexes-√†-partir-de-donn√©es-g√©nomiques-en-utilisant-des-graphes-admixtures.",
    "href": "about.html#post-doctorat-d√©veloppement-de-m√©thodes-statistiques-pour-la-reconstruction-de-routes-dinvasion-biologique-inf√©rence-de-sc√©narios-√©volutionnaires-complexes-√†-partir-de-donn√©es-g√©nomiques-en-utilisant-des-graphes-admixtures.",
    "title": "Qui suis-je ?",
    "section": "Post-Doctorat : D√©veloppement de m√©thodes statistiques pour la reconstruction de routes d‚Äôinvasion biologique, inf√©rence de sc√©narios √©volutionnaires complexes √† partir de donn√©es g√©nomiques en utilisant des graphes admixtures.",
    "text": "Post-Doctorat : D√©veloppement de m√©thodes statistiques pour la reconstruction de routes d‚Äôinvasion biologique, inf√©rence de sc√©narios √©volutionnaires complexes √† partir de donn√©es g√©nomiques en utilisant des graphes admixtures.\nMots-cl√©s: G√©n√©tique des populations, Graphes admixtures\n\nExploration de l‚Äôespace des graphes admixtures et probl√®mes d‚Äôidentifiabilit√©s.\nUtilisation de mod√®les g√©n√©ratifs de graphes.\nApplications √† des donn√©es g√©n√©tiques d‚Äôesp√®ces invasives."
  },
  {
    "objectID": "about.html#depuis-2025-1",
    "href": "about.html#depuis-2025-1",
    "title": "Qui suis-je ?",
    "section": "Depuis 2025",
    "text": "Depuis 2025\nPost-Doctorat : D√©veloppement de m√©thodes statistiques pour la reconstruction de routes d‚Äôinvasion biologique, inf√©rence de sc√©narios √©volutionnaires complexes √† partir de donn√©es g√©nomiques en utilisant des graphes admixtures.\nüè¢ Centre Biologique de Gestion des Populations, Montpellier\nMots-cl√©s: G√©n√©tique des populations, Graphes admixtures\n\nExploration de l‚Äôespace des graphes admixtures et probl√®mes d‚Äôidentifiabilit√©s.\nUtilisation de mod√®les g√©n√©ratifs de graphes.\nApplications √† des donn√©es g√©n√©tiques d‚Äôesp√®ces invasives."
  },
  {
    "objectID": "about.html#stage-de-m2-participation-√†-la-conception-du-design-magn√©tique-dune-machine-irm-√†-14-t-en-utilisant-diff√©rentes-techniques-dintelligence-artificielle.",
    "href": "about.html#stage-de-m2-participation-√†-la-conception-du-design-magn√©tique-dune-machine-irm-√†-14-t-en-utilisant-diff√©rentes-techniques-dintelligence-artificielle.",
    "title": "Qui suis-je ?",
    "section": "Stage de M2 : Participation √† la conception du design magn√©tique d‚Äôune machine IRM √† 14 T en utilisant diff√©rentes techniques d‚Äôintelligence artificielle.",
    "text": "Stage de M2 : Participation √† la conception du design magn√©tique d‚Äôune machine IRM √† 14 T en utilisant diff√©rentes techniques d‚Äôintelligence artificielle.\nMots-cl√©s: Opera-2d 2020, algorithme g√©n√©tique, optimisation sous contrainte, magn√©tisme\n\nMettre en place un code Python capable d‚Äôinteragir avec le logiciel Opera-2d 2020.\nTrouver une configuration optimale respectant des contraintes √† l‚Äôaide d‚Äôun algorithme g√©n√©tique."
  },
  {
    "objectID": "about.html#mai-sep-2021-1",
    "href": "about.html#mai-sep-2021-1",
    "title": "Qui suis-je ?",
    "section": "Mai-Sep 2021",
    "text": "Mai-Sep 2021\nüè¢ Laboratoire de Probabilit√©, Statistiques et Mod√©lisation, Paris\nEncadrants : Anna Bonnet (LPSM), Sylvain Le Corff (LPSM), Harry Sokol (AP-HP)"
  },
  {
    "objectID": "about.html#stage-de-m2-participation-√†-la-conception-du-design-magn√©tique-dune-machine-irm-√†-14-t-en-utilisant-diff√©rentes-techniques-dintelligence-artificielle.-1",
    "href": "about.html#stage-de-m2-participation-√†-la-conception-du-design-magn√©tique-dune-machine-irm-√†-14-t-en-utilisant-diff√©rentes-techniques-dintelligence-artificielle.-1",
    "title": "Qui suis-je ?",
    "section": "Stage de M2 : Participation √† la conception du design magn√©tique d‚Äôune machine IRM √† 14 T en utilisant diff√©rentes techniques d‚Äôintelligence artificielle.",
    "text": "Stage de M2 : Participation √† la conception du design magn√©tique d‚Äôune machine IRM √† 14 T en utilisant diff√©rentes techniques d‚Äôintelligence artificielle.\nMots-cl√©s: Opera-2d 2020, algorithme g√©n√©tique, optimisation sous contrainte, magn√©tisme\n\nMettre en place un code Python capable d‚Äôinteragir avec le logiciel Opera-2d 2020.\nTrouver une configuration optimale respectant des contraintes √† l‚Äôaide d‚Äôun algorithme g√©n√©tique."
  },
  {
    "objectID": "about.html#stage-de-m1-apprentissage-statistique-pour-tester-linfluence-du-microbiote-intestinal-sur-la-r√©ponse-au-traitement-de-la-maladie-de-crohn.",
    "href": "about.html#stage-de-m1-apprentissage-statistique-pour-tester-linfluence-du-microbiote-intestinal-sur-la-r√©ponse-au-traitement-de-la-maladie-de-crohn.",
    "title": "Qui suis-je ?",
    "section": "Stage de M1 : Apprentissage statistique pour tester l‚Äôinfluence du microbiote intestinal sur la r√©ponse au traitement de la maladie de Crohn.",
    "text": "Stage de M1 : Apprentissage statistique pour tester l‚Äôinfluence du microbiote intestinal sur la r√©ponse au traitement de la maladie de Crohn.\nMots-cl√©s: Machine learning, for√™ts al√©atoires, s√©lection de variables en grande dimension, MCMC\n\nS√©lectionner des variables pertinentes √† l‚Äôaide de for√™ts al√©atoires et comparer les r√©sultats avec d‚Äôautres √©tudes.\nImpl√©menter un algorithme MCMC de s√©lection de variables dans un mod√®le de r√©gression logistique.\nLe stage a abouti √† l‚Äô√©criture d‚Äôun article publi√© : Impact of the Ileal Microbiota on Surgical Site Infections in Crohn‚Äôs Disease : A Nationwide Prospective Cohort, Journal of Crohn‚Äôs and Colitis, Volume 16, Issue 8, August 2022, Pages 1211‚Äì1221, https://doi.org/10.1093/ecco-jcc/jjac026"
  },
  {
    "objectID": "latex/spipoll_full_encoder.html",
    "href": "latex/spipoll_full_encoder.html",
    "title": "Spipoll full encoder",
    "section": "",
    "text": "\\documentclass[border=0pt,tikz]{standalone}\n\\usepackage{amsmath}\n\\usepackage[dvipsnames]{xcolor}\n\\usepackage{pgfplots}\n\\usepackage{tikz-cd}\n\n\\begin{document}\n\\begin{tikzcd}\n    B,X_1,X_2 \\arrow[r,\"q\"] \\arrow[d, \"\\mathbf{1}( P^{\\top}B&gt;0)\"] & Z_1, Z_2 \\arrow[r,\"p\"] \\arrow[dd,\"\\Tilde{q}\"] & \\widehat{B} \\arrow[d,\"\\Tilde{P}^T \\widehat{B} \",dashed] & \\text{AUC}(\\widehat{B}) \\\\\n    B' &  & \\widehat{B'} & \\text{AUC}(\\widehat{B'}) \\\\[-25pt]\n    & Z'_1,Z_2  \\arrow[r,\"p\"]& \\Tilde{B'}& \\text{AUC}(\\Tilde{B'})  \n    \\end{tikzcd}\n\\end{document}"
  },
  {
    "objectID": "latex/spipoll_encoder.html",
    "href": "latex/spipoll_encoder.html",
    "title": "Spipoll auto encoder",
    "section": "",
    "text": "\\documentclass[border=0pt,tikz]{standalone}\n\\usepackage{amsmath}\n\\usepackage[dvipsnames]{xcolor}\n\\usepackage{pgfplots}\n\\usepackage{tikz-cd}\n\n\\begin{document}\n\\begin{tikzcd}\nB,X_1,X_2 \\arrow[r,\"q\"] \\arrow[d, \"\\mathbf{1}( P^{\\top}B&gt;0)\"] & Z_1, Z_2 \\arrow[r,\"p\"] & \\widehat{B} \\arrow[d,\"\\Tilde{P}^T \\widehat{B} \"]  \\\\\nB' &  & \\widehat{B'} \\\\\n\\end{tikzcd}\n\\end{document}"
  },
  {
    "objectID": "latex/SBM.html",
    "href": "latex/SBM.html",
    "title": "Stochastic block model",
    "section": "",
    "text": "\\documentclass[varwidth,border=3pt,tikz]{standalone}\n\\usepackage{multicol}\n\\usepackage{tikz}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{enumitem}\n%\\usetikzlibrary{calc,shapes,backgrounds,arrows,automata,shadows,positioning}\n\\usetikzlibrary{arrows,shapes,positioning,shadows,trees,calc,backgrounds,automata,positioning}\n\n\\tikzset{\n  basic/.style  = {draw, text width=3cm, font=\\sffamily, rectangle},\n  root/.style   = {basic, rounded corners=2pt, thin, align=center,\n                   fill=green!30},\n  level 2/.style = {basic, rounded corners=6pt, thin,align=center, fill=green!60,\n                   text width=8em},\n  level 3/.style = {basic, thin, align=left, fill=pink!60, text width=3.5cm}\n}\n\n% pour tickz multilevel\n\\definecolor{redorg}{RGB}{215,48,39}\n\\definecolor{orangeorg}{RGB}{253,174,97}\n\\definecolor{blueind}{RGB}{69,117,233}\n\\definecolor{cyanind}{RGB}{116,173,209}\n\\definecolor{greenind}{RGB}{112,130,56}\n\\definecolor{dgreen2}{RGB}{48,56,215}\n\n\\begin{document}\n\n\n        \\begin{tikzpicture}\n          %% UN GRAPH\n      \\tikzstyle{every edge}=[-,&gt;=stealth',shorten &gt;=1pt,auto,thin,draw]\n      \\tikzstyle{every state}=[draw=none,text=white,scale=0.65, font=\\scriptsize, transform shape]\n      \\tikzstyle{every node}=[fill=yellow!40!orange]\n      % premier cluster\n      \\node[state] (A1) at (0,0.5) {A1};\n      \\node[state] (A2) at (1,0.5) {A2};\n      \\node[state] (A3) at (.5,1.5) {A3};\n\n      \\path (A2) edge [bend left] node[fill=white,below=.1cm]\n      {$\\pi_{\\textcolor{yellow!40!orange}{\\bullet}\\textcolor{yellow!40!orange}{\\bullet}}$}\n      (A1)\n      (A1) edge [bend left] (A3)\n      (A3) edge [bend left] (A2);\n\n      \\tikzstyle{every node}=[fill=dgreen2!80!black]\n      \\foreach \\angle/\\text in {234/B1, 162/B2, 90/B3, 18/B4, -54/B5} {\n        \\node[fill=dgreen2,state,xshift=5cm,yshift=3.5cm]     (\\text)    at\n        (\\angle:1cm) {\\text};\n      }\n      \\path (B2) edge (B5)\n      (B1) edge (B4);\n      \\foreach \\from/\\to in {1/2,2/3,4/5,5/1}{\n        \\path (B\\from) edge [bend left] (B\\to);\n      }\n\n      \\path    (B3)    edge     [bend    left]    node[fill=white]\n      {$\\pi_{\\textcolor{dgreen2!80!black}{\\bullet}\\textcolor{dgreen2!80!black}{\\bullet}}$}  (B4) ;\n      \n      \\tikzstyle{every node}=[fill=green!50!black]\n      % troisieme cluster\n      \\node[state] (C1) at (3,-.5) {C1};\n      \\node[state] (C2) at (4,0) {C2};\n\n      \\path (C1) edge [bend right] node[fill=white,below=.25cm]\n      {$\\pi_{\\textcolor{green!50!black}{\\bullet}\\textcolor{green!50!black}{\\bullet}}$}\n      (C2);\n\n      % inter cluster\n      \\path (A3) edge [bend right]  (B2)\n      (A3)    edge    [bend    left]    node[fill=white]\n      {$\\pi_{\\textcolor{yellow!40!orange}{\\bullet}\\textcolor{dgreen2!80!black}{\\bullet}}$}\n      (B3)\n      (C2) edge [bend right] node[fill=white,right]\n      {$\\pi_{\\textcolor{dgreen2!80!black}{\\bullet}\\textcolor{green!50!black}{\\bullet}}$}\n      (B4)\n      (A2) edge [bend right] node[fill=white]\n      {$\\pi_{\\textcolor{yellow!40!orange}{\\bullet}\\textcolor{green!50!black}{\\bullet}}$}\n      (C1);\n      \n      \\tikzstyle{every node}=[fill=white]\n\n      \\node at (9,2) {$n$ n≈ìuds r√©partis en $Q=3$ clusters};\n\n      \\node[below=1,align=center ] at (9,2.5) {$\\begin{aligned}\n        & \\bullet \\quad \\text{Clusters\\,:}\\  \\{\\textcolor{yellow!40!orange}{\\bullet},\\textcolor{dgreen2!80!black}{\\bullet},\\textcolor{green!50!black}{\\bullet}\\}\\\\\n     & \\bullet \\quad \\alpha_{\\bullet}  =  \\mathbb{P}(i  \\in  \\bullet), i=1,\\dots,n \\\\\n     & \\bullet \\quad \\pi_{\\textcolor{yellow!40!orange}{\\bullet}\\textcolor{dgreen2!80!black}{\\bullet}}     =      \\mathbb{P}(i\n     \\leftrightarrow j | i\\in\\textcolor{yellow!40!orange}{\\bullet},j\\in\\textcolor{dgreen2!80!black}{\\bullet})\n     \\end{aligned}$\n     };\n     \n     \\node at (9,-1) {$A \\sim SBM_{n}(Q,\\alpha,\\pi)$};\n\n   \n\n  \\end{tikzpicture}\n\n\n\\end{document}"
  },
  {
    "objectID": "latex/schema_autoencoder.html",
    "href": "latex/schema_autoencoder.html",
    "title": "Auto encoder",
    "section": "",
    "text": "\\documentclass[border=0pt,tikz]{standalone}\n\\usepackage{amsmath}\n\\usepackage[dvipsnames]{xcolor}\n\\usepackage{pgfplots}\n\\usepackage{tikz-cd}\n\n\\begin{document}\n\\begin{tikzcd}\n    B,X_1,X_2 \\arrow[r,\"q\"] \\arrow[d, \"\\mathbf{1}( P^{\\top}B&gt;0)\"] & Z_1, Z_2 \\arrow[r,\"p\"] \\arrow[dd,\"\\Tilde{q}\"] & \\widehat{B} \\arrow[d,\"\\Tilde{P}^T \\widehat{B} \",dashed] & \\text{AUC}(\\widehat{B}) \\\\\n    B' &  & \\widehat{B'} & \\text{AUC}(\\widehat{B'}) \\\\[-25pt]\n    & Z'_1,Z_2  \\arrow[r,\"p\"]& \\Tilde{B'}& \\text{AUC}(\\Tilde{B'})  \n    \\end{tikzcd}\n\\end{document}"
  },
  {
    "objectID": "latex/reseau_de_neurones.html",
    "href": "latex/reseau_de_neurones.html",
    "title": "Neural network",
    "section": "",
    "text": "\\documentclass[border=3pt,tikz]{standalone}\n\\usepackage{amsmath} % for aligned\n\\usepackage{listofitems} % for \\readlist to create arrays\n\\usetikzlibrary{arrows.meta} % for arrow size\n\\usepackage[outline]{contour} % glow around text\n\\contourlength{1.4pt}\n\n% COLORS\n\\usepackage{xcolor}\n\\colorlet{myred}{red!80!black}\n\\colorlet{myblue}{blue!80!black}\n\\colorlet{mygreen}{green!60!black}\n\\colorlet{myyellow}{yellow!60!white}\n\\colorlet{myorange}{orange!70!red!60!black}\n\\colorlet{mydarkred}{red!30!black}\n\\colorlet{mydarkblue}{blue!40!black}\n\\colorlet{mydarkgreen}{green!30!black}\n\\colorlet{mydarkyellow}{yellow!30!black}\n\n% STYLES\n\\tikzset{\n  &gt;=latex, % for default LaTeX arrow head\n  node/.style={thick,circle,draw=myblue,minimum size=22,inner sep=0.5,outer sep=0.6},\n  node in/.style={node,green!20!black,draw=mygreen!30!black,fill=mygreen!25},\n  node hidden/.style={node,blue!20!black,draw=myblue!30!black,fill=myblue!20},\n  node convol/.style={node,orange!20!black,draw=myorange!30!black,fill=myorange!20},\n  node out/.style={node,red!20!black,draw=myred!30!black,fill=myred!20},\n  connect/.style={thick,mydarkblue}, %,line cap=round\n  connect arrow/.style={-{Latex[length=4,width=3.5]},thick,mydarkblue,shorten &lt;=0.5,shorten &gt;=1},\n  node 1/.style={node in}, % node styles, numbered for easy mapping with \\nstyle\n  node 2/.style={node hidden},\n  node 3/.style={node out}\n}\n\\def\\nstyle{int(\\lay&lt;\\Nnodlen?min(2,\\lay):3)} % map layer number onto 1, 2, or 3\n\n\\begin{document}\n\n\n\\begin{tikzpicture}[x=2.2cm,y=1.4cm]\n    \\message{^^JNeural network, shifted}\n    \\readlist\\Nnod{4,5,5,5,3} % array of number of nodes per layer\n    \\readlist\\Nstr{n,m_1,m_2,m_3,m} % array of string number of nodes per layer\n    \\readlist\\Cstr{\\strut x^{(0)},x^{(\\prev)},x^{(\\prev)},x^{(\\prev)},y} % array of coefficient symbol per layer\n    \\def\\yshift{0.5} % shift last node for dots\n    \n    \\message{^^J  Layer}\n    \\foreachitem \\N \\in \\Nnod{ % loop over layers\n      \\def\\lay{\\Ncnt} % alias of index of current layer\n      \\pgfmathsetmacro\\prev{int(\\Ncnt-1)} % number of previous layer\n      \\message{\\lay,}\n      \\foreach \\i [evaluate={\\c=int(\\i==\\N); \\y=\\N/2-\\i-\\c*\\yshift;\n                   \\index=(\\i&lt;\\N?int(\\i):\"\\Nstr[\\lay]\");\n                   \\x=\\lay; \\n=\\nstyle;}] in {1,...,\\N}{ % loop over nodes\n        % NODES\n        \\node[node \\n] (N\\lay-\\i) at (\\x,\\y) {$\\Cstr[\\lay]_{\\index}$};\n        \n        % CONNECTIONS\n        \\ifnum\\lay&gt;1 % connect to previous layer\n          \\foreach \\j in {1,...,\\Nnod[\\prev]}{ % loop over nodes in previous layer\n            \\draw[connect arrow,white,line width=1.2] (N\\prev-\\j) -- (N\\lay-\\i);\n            \\draw[connect arrow] (N\\prev-\\j) -- (N\\lay-\\i);\n            %\\draw[connect] (N\\prev-\\j.0) -- (N\\lay-\\i.180); % connect to left\n          }\n        \\fi % else: nothing to connect first layer\n        \n      }\n      \\path (N\\lay-\\N) --++ (0,1+\\yshift) node[midway,scale=1.5] {$\\vdots$};\n    }\n  \n    \\node[thick,circle,draw=mydarkyellow,fill=myyellow,minimum size=22,inner sep=0.5,outer sep=0.6](epsilon) at (6,-0.5){$\\varepsilon$};\n      \\foreach \\j in {1,2,3}{ % loop over nodes in previous layer\n            %\\draw[connect arrow,white,line width=1.2] (N5-\\j) -- (epsilon);\n            \\draw[connect arrow] (N5-\\j) -- (epsilon);\n            }\n    \n    % LABELS\n    \\node[above=5,align=center,mygreen!60!black] at (N1-1.90) {Couche\\\\[-0.2em]d'entr√©e};\n    \\node[above=2,align=center,myblue!60!black] at (N3-1.90) {Couche(s) cach√©e(s)};\n    \\node[above=8,align=center,myred!60!black] at (N\\Nnodlen-1.90) {Couche\\\\[-0.2em]de sortie};\n     \\node[above=10,align=center,mydarkyellow!60!black] at (epsilon) {Fonction\\\\[-0.2em]de co√ªt\\\\[-0.2em]};\n    \n  \\end{tikzpicture}\n\\end{document}"
  },
  {
    "objectID": "latex/Pooling_node_edge.html",
    "href": "latex/Pooling_node_edge.html",
    "title": "Pooling from nodes to edges",
    "section": "",
    "text": "\\documentclass[border=3pt,tikz]{standalone}\n\\usepackage{amsmath}\n\\usepackage[dvipsnames]{xcolor}\n\\usepackage{pgfplots}\n\\definecolor{taupegray}{rgb}{0.55, 0.52, 0.54}\n\\def\\general_height{0.2}\n\\usepackage{tikz-network}\n\\begin{document}\n\n\n\n\\begin{tikzpicture}\n\\begin{scope}[scale=0.9]\n\n\\begin{scope}[scale=2,xshift=-1cm]\n    \\Vertex[x=0.88,y=0.48,label=A,color=red]{A}\n    \\Vertex[x=-0.18,y=0.98,label=B,color=green]{B}\n    \\Vertex[x=-1,y=0.12,label=C,color=pink]{C}\n    \\Vertex[x=-0.42,y=-0.9,label=D,color=yellow]{D}\n    \\Vertex[x=0.72,y=-0.69,label=E,color=cyan]{E}\n    \\Edge[color=gray](A)(B)\n    \\Edge[color=gray](A)(C)\n    \\Edge[color=gray](A)(D)\n    \\Edge[color=gray](A)(E)\n    \\Edge[color=gray](B)(C)\n    \\Edge[color=gray](B)(D)\n    \\Edge[color=gray](B)(E)\n\\end{scope}\n\n\\begin{scope}[xshift=2cm]\n\\node[] at (1.5cm,4.5cm) {\\huge $X^{V(l)}$};\n\\node[align = center, text width=5cm] at (1.5cm,6cm) {\\Large Donn√©es sur les noeuds };\n\n\\Vertex[x=0,y=3,Pseudo]{bar_1}\n\\begin{axis}[ybar stacked, \nyshift = 3cm,\nheight=\\general_height\\textwidth,\n bar width=13pt,ymin=0,\n x=17pt,\n ytick=\\empty,\n xtick=\\empty,\n hide axis]\n    \\addplot[fill=green,opacity=0.5] coordinates\n        {(0,0.15) (1,0.1) (2,0.1) (3,0.2) (4,0.1)};\n    \\end{axis}\n\n\\Vertex[x=0,y=2,Pseudo]{bar_2}\n\\begin{axis}[ybar stacked, \nyshift = 2cm,\nheight=\\general_height\\textwidth,\n bar width=13pt,ymin=0,\n x=17pt,\n ytick=\\empty,\n xtick=\\empty,\n hide axis]\n    \\addplot[fill=red,opacity=0.5] coordinates\n        {(0,0.1) (1,0.05) (2,0.3) (3,0.2) (4,0.0)};\n    \\end{axis}\n\n\n \n\\Vertex[x=0,y=-2,Pseudo]{bar_4}\n\\begin{axis}[ybar stacked,\nyshift = -2cm,\nheight=\\general_height\\textwidth,\n bar width=13pt,ymin=0,\n x=17pt,\n ytick=\\empty,\n xtick=\\empty,\n hide axis]\n    \\addplot[fill=cyan,opacity=0.5] coordinates\n        {(0,0.1) (1,0.1) (2,0.15) (3,0.2) (4,0.15)};\n    \\end{axis}\n\n\n\n\\Vertex[x=0,y=-3,Pseudo]{bar_7}\n \n\\begin{axis}[ybar stacked, \nyshift = -3cm,\nheight=\\general_height\\textwidth,\n bar width=13pt,ymin=0,\n x=17pt,\n ytick=\\empty,\n xtick=\\empty,\n hide axis]\n\\addplot[fill=yellow,opacity=0.5] coordinates\n        {(0,0.2) (1,0.1) (2,0.1) (3,0.2) (4,0.1)};\n\\end{axis}\n \n \\Vertex[x=3,y=2.5,Pseudo]{barplots}\n \\Vertex[x=3,y=-2.5,Pseudo]{barplots2}\n\n \n\\end{scope}\n\n\\begin{scope}[xshift=8cm]\n\\node[] at (1.5cm,4.5cm) {\\huge $X^{E(l+1)}/X^{E^*(l+1)}$};\n\\node[align = center, text width=6cm] at (1.5cm,6cm) {\\Large Donn√©es sur les ar√™tes ou les ar√™tes potentielles};\n\n\\Vertex[x=0,y=2.5,Pseudo]{agregation}\n\\Vertex[x=0,y=-2.5,Pseudo]{agregation2}\n\n\n\\begin{axis}[ybar stacked,\nheight= 1.2*\\general_height\\textwidth,\nyshift = 2.5cm,\n bar width=13pt,ymin=0,\n x=17pt,\n ytick=\\empty,\n xtick=\\empty,\n hide axis]\n  \\addplot[fill=red,opacity=0.5] coordinates\n  {(0,0.1) (1,0.05) (2,0.3) (3,0.2) (4,0.0)};\n  \\addplot[fill=green,opacity=0.5] coordinates\n  {(0,0.15) (1,0.1) (2,0.1) (3,0.2) (4,0.1)};\n \\end{axis}\n \\Vertex[x=3,y=3,Pseudo]{N} \n\n \\begin{axis}[ybar stacked,\n    height= 1.2*\\general_height\\textwidth,\n    yshift = -2.5cm,\n     bar width=13pt,ymin=0,\n     x=17pt,\n     ytick=\\empty,\n     xtick=\\empty,\n     hide axis]\n     \\addplot[fill=yellow,opacity=0.5] coordinates\n     {(0,0.2) (1,0.1) (2,0.1) (3,0.2) (4,0.1)};\n     \n     \n     \\addplot[fill=cyan,opacity=0.5] coordinates\n     {(0,0.1) (1,0.1) (2,0.15) (3,0.2) (4,0.15)};\n      \n      \n     \\end{axis}\n     \\Vertex[x=3,y=-2.5,Pseudo]{N2} \n\\end{scope}\n\n\n\\Edge[bend=35,style={dashed},Direct](A)(bar_2)\n%\\Edge[bend=35,style={dashed},Direct]($(A)!.5!(C)$)(bar_3)\n%\\Edge[bend=-35,style={dashed},Direct]($(A)!.5!(D)$)(bar_6)\n%\\Edge[bend=-35,style={dashed},Direct]($(A)!.5!(E)$)(bar_5)\n\\Edge[bend=35,style={dashed},Direct](B)(bar_1)\n\\Edge[bend=-35,style={dashed},Direct](D)(bar_7)\n\\Edge[bend=-35,style={dashed},Direct](E)(bar_4)\n\n\n\n\n\n\\begin{scope}[xshift=14cm,scale=2]\n\\Vertex[x=0.88,y=0.48,label=A,color=red]{A2}\n\\Vertex[x=-0.18,y=0.98,label=B,color=green]{B2}\n\\Vertex[x=-1,y=0.12,label=C,color=pink]{C2}\n\\Vertex[x=-0.42,y=-0.9,label=D,color=yellow]{D2}\n\\Vertex[x=0.72,y=-0.69,label=E,color=cyan]{E2}\n\n\\Vertex[x=0.35,y=0.73,color=red,Pseudo]{A2B2}\n\\Vertex[x=0.15,y=-0.795,color=red,Pseudo]{D2E2}\n\n\n\\Edge[color=green,lw=4](A2)(B2)\n\\Edge[color=red,style={dashed},lw=4](A2)(B2)\n\n\\Edge[color=red,lw=4](A2)(C2)\n\\Edge[color=pink,style={dashed},lw=4](A2)(C2)\n\n\\Edge[color=red,lw=4](A2)(D2)\n\\Edge[color=yellow,style={dashed},lw=4](A2)(D2)\n\n\\Edge[color=red,lw=4](A2)(E2)\n\\Edge[color=cyan,style={dashed},lw=4](A2)(E2)\n\n\\Edge[color=green,lw=4](B2)(C2)\n\\Edge[color=pink,style={dashed},lw=4](B2)(C2)\n\n\\Edge[color=green,lw=4](B2)(D2)\n\\Edge[color=yellow,style={dashed},lw=4](B2)(D2)\n\n\\Edge[color=green,lw=4](B2)(E2)\n\\Edge[color=cyan,style={dashed},lw=4](B2)(E2)\n\n\\Edge[color=yellow,style = {dotted}](D2)(E2)\n\\Edge[color=cyan  ,style = {loosely dotted}](D2)(E2)\n\n\\Edge[color=yellow,style = {dotted}](C2)(D2)\n\\Edge[color=pink  ,style = {loosely dotted}](C2)(D2)\n\n\\Edge[color=pink,style = {dotted}](C2)(E2)\n\\Edge[color=cyan  ,style = {loosely dotted}](C2)(E2)\n\n\\end{scope}\n\n\\Edge[style={dashed},Direct,label={\\Huge $\\phi$}](barplots)(agregation)\n\\Edge[style={dashed},Direct,label={\\Huge $\\phi$}](barplots2)(agregation2)\n\n\n\\Edge[style={dashed},bend=35,Direct](N)(A2B2)\n\\Edge[style={dashed},bend=-35,Direct](N2)(D2E2)\n\n\\end{scope}\n\\end{tikzpicture}\n    \n    \n\\end{document}"
  },
  {
    "objectID": "latex/Pooling_node.html",
    "href": "latex/Pooling_node.html",
    "title": "Pooling nodes",
    "section": "",
    "text": "\\documentclass[border=3pt,tikz]{standalone}\n\\usepackage{amsmath}\n\\usepackage[dvipsnames]{xcolor}\n\\usepackage{pgfplots}\n\\definecolor{taupegray}{rgb}{0.55, 0.52, 0.54}\n\\def\\general_height{0.2}\n\\usepackage{tikz-network}\n\\begin{document}\n\n\\begin{tikzpicture}\n\n    %\\Text[x=-0.18,y=3cm]{\\Large Couche $N$}\n    %\\Text[x=14cm,y=3cm]{\\Large Couche $N+1$}\n    \n    \\begin{scope}[scale=2]\n    \\Vertex[x=0.88,y=0.48,label=A,color=red]{A}\n    \\Vertex[x=-0.18,y=0.98,label=B,color=green]{B}\n    \\Vertex[x=-1,y=0.12,label=C,color=pink]{C}\n    \\Vertex[x=-0.42,y=-0.9,label=D,color=yellow]{D}\n    \\Vertex[x=0.72,y=-0.69,label=E,color=cyan]{E}\n    \\Edge[color=gray](A)(B)\n    \\Edge[color=gray](A)(C)\n    \\Edge[color=gray](A)(D)\n    \\Edge[color=gray](A)(E)\n    \\Edge[color=gray](B)(C)\n    \\Edge[color=gray](B)(D)\n    \\Edge[color=gray](B)(E)\n    \\end{scope}\n    \n    \\begin{scope}[xshift=4cm]\n    \\node[] at (1.5cm,3.5cm) {\\huge $X^{V(l)}$};\n    \\node[align = center, text width=5cm] at (1.5cm,5cm) {\\Large Donn√©es sur tous les noeuds};\n    \n    \\Vertex[x=0,y=2,Pseudo]{bar_C}\n    \\begin{axis}[ybar stacked, \n    yshift = 2cm,\n    height=\\general_height\\textwidth,\n     bar width=13pt,ymin=0,\n     x=17pt,\n     ytick=\\empty,\n     xtick=\\empty,\n     hide axis]\n        \\addplot[fill=pink,opacity=0.5] coordinates\n            {(0,0.1) (1,0.05) (2,0.3) (3,0.2) (4,0.0)};\n        \\end{axis}\n     \n    \\Vertex[x=0,y=0,Pseudo]{K}\n    \\begin{axis}[ybar stacked,\n    height=\\general_height\\textwidth,\n     bar width=13pt,ymin=0,\n     x=17pt,\n     ytick=\\empty,\n     xtick=\\empty,\n     hide axis]\n        \\addplot[fill=red,opacity=0.5] coordinates\n            {(0,0.1) (1,0.1) (2,0.15) (3,0.2) (4,0.15)};\n        \\end{axis}\n    \n    \\Vertex[x=0,y=1,Pseudo]{L}\n    \\begin{axis}[ybar stacked, \n    yshift = 1cm,\n    height=\\general_height\\textwidth,\n     bar width=13pt,ymin=0,\n     x=17pt,\n     ytick=\\empty,\n     xtick=\\empty,\n     hide axis]\n        \\addplot[fill=green,opacity=0.5] coordinates\n            {(0,0.2) (1,0.05) (2,0.1) (3,0.15) (4,0.05)};\n        \\end{axis}\n    \n    \\Vertex[x=0,y=-1,Pseudo]{bar_E}\n    \\begin{axis}[ybar stacked, \n    yshift = -1cm,\n    height=\\general_height\\textwidth,\n     bar width=13pt,ymin=0,\n     x=17pt,\n     ytick=\\empty,\n     xtick=\\empty,\n     hide axis]\n        \\addplot[fill=blue,opacity=0.5] coordinates\n            {(0,0.2) (1,0.1) (2,0.2) (3,0.15) (4,0.05)};\n        \\end{axis}\n    \n    \\Vertex[x=0,y=-2,Pseudo]{M}\n    \\begin{axis}[ybar stacked, \n    yshift = -2cm,\n    height=\\general_height\\textwidth,\n     bar width=13pt,ymin=0,\n     x=17pt,\n     ytick=\\empty,\n     xtick=\\empty,\n     hide axis]\n        \\addplot[fill=yellow,opacity=0.5] coordinates\n            {(0,0.1) (1,0.2) (2,0) (3,0.1) (4,0.1)};\n        \\end{axis}\n    \n    %\\draw (0,-2.5cm) -- (3,-2.5cm);\n     %\\Text[x=3.5,y=-2.5cm]{\\Huge $\\mathbf{+}$}\n     \\Vertex[x=3,y=0,Pseudo]{barplots}\n    \n    \\end{scope}\n    \\begin{scope}[xshift=12cm]\n    \\node[] at (1.5cm,3.5cm) {\\huge $X^{U(l+1)}$};\n    \\node[align = center, text width=4cm] at (1.5cm,5cm) {\\Large Donn√©es de contexte global};\n    \n    \\Vertex[x=0,y=0,Pseudo]{agregation}\n    \n    \n    \\begin{axis}[ybar stacked,\n    height= 5cm,\n    yshift = -1cm,\n     bar width=13pt,ymin=0,\n     x=17pt,\n     ytick=\\empty,\n     xtick=\\empty,\n     hide axis]\n     \\addplot[fill=yellow,opacity=0.5] coordinates\n            {(0,0.1) (1,0.2) (2,0) (3,0.1) (4,0.1)};\n      \\addplot[fill=blue,opacity=0.5] coordinates\n            {(0,0.2) (1,0.1) (2,0.2) (3,0.15) (4,0.05)};\n      \\addplot[fill=red,opacity=0.5] coordinates\n            {(0,0.1) (1,0.1) (2,0.15) (3,0.2) (4,0.15)};\n     \\addplot[fill=green,opacity=0.5] coordinates\n            {(0,0.2) (1,0.05) (2,0.1) (3,0.15) (4,0.05)};\n      \\addplot[fill=pink,opacity=0.5] coordinates\n            {(0,0.1) (1,0.05) (2,0.3) (3,0.2) (4,0.0)};\n     \\end{axis}\n     \\Vertex[x=3,y=-3.5,Pseudo]{N}  \n    \\end{scope}\n    %\\node[align=center,text width=5cm] at (1,-4.5) {\\large Agr√©gation des donn√©es des noeuds voisins};\n    \n    \\Edge[bend=35,style={dashed},Direct](A)(K)\n    \\Edge[bend=35,style={dashed},Direct](B)(L)\n    \\Edge[bend=-35,style={dashed},Direct](D)(M)\n    \\Edge[bend=70,style={dashed},Direct](C)(bar_C)\n    \\Edge[bend=35,style={dashed},Direct](E)(bar_E)\n    \n    \\Edge[style={dashed},Direct,label={\\Huge $\\phi$}](barplots)(agregation)\n\\end{tikzpicture}\n\n\n    \n\\end{document}"
  },
  {
    "objectID": "latex/Pooling_edge_node.html",
    "href": "latex/Pooling_edge_node.html",
    "title": "Pooling from edges to nodes",
    "section": "",
    "text": "\\documentclass[border=3pt,tikz]{standalone}\n\\usepackage{amsmath}\n\\usepackage[dvipsnames]{xcolor}\n\\usepackage{pgfplots}\n\\definecolor{taupegray}{rgb}{0.55, 0.52, 0.54}\n\\def\\general_height{0.2}\n\\usepackage{tikz-network}\n\\begin{document}\n\n\\def\\a{0.8}\n\\tikzset{pics/four colors/.style args=\n    {#1|#2|#3|#4|rotate=#5}{code={%\n\\fill[#1,rotate=#5] (0,\\a/2) arc(90:180:\\a/2)--(0,0)--cycle;            \n\\fill[#2,rotate=#5] (0,\\a/2) arc(90:0:\\a/2)--(0,0)--cycle;\n\\fill[#3,rotate=#5] (180:\\a/2) arc(180:270:\\a/2)--(0,0)--cycle;\n\\fill[#4,rotate=#5] (270:\\a/2) arc(270:360:\\a/2)--(0,0)--cycle;\n%\\path (0,0) node[c] (-boundary) {};\n}}}\n\n\\begin{tikzpicture}\n\\begin{scope}[scale=0.9]\n\n\\begin{scope}[scale=2,xshift=-1cm]\n\\Vertex[x=0.88,y=0.48,label=A,color=white]{A}\n\\Vertex[x=-0.18,y=0.98,label=B,style={line width=1.5mm},color=white]{B}\n\\Vertex[x=-1,y=0.12,label=C,color=white]{C}\n\\Vertex[x=-0.42,y=-0.9,label=D,color=white]{D}\n\\Vertex[x=0.72,y=-0.69,label=E,color=white]{E}\n\\Edge[color=pink,lw=5](A)(B)\n\\Edge[color=green](A)(C)\n\\Edge[color=red](A)(D)\n\\Edge[color=blue](A)(E)\n\\Edge[color=yellow,lw=5](B)(C)\n\\Edge[color=orange,lw=5](B)(D)\n\\Edge[color=gray,lw=5](B)(E)\n\\end{scope}\n\n\\begin{scope}[xshift=2cm]\n\\node[] at (1.5cm,4.5cm) {\\huge $X^{E(l)}$};\n\\node[align = center, text width=5cm] at (1.5cm,6cm) {\\Large Donn√©es sur les ar√™tes adjacente √† B};\n\n\\Vertex[x=0,y=3,Pseudo]{bar_1}\n\\begin{axis}[ybar stacked, \nyshift = 3cm,\nheight=\\general_height\\textwidth,\n bar width=13pt,ymin=0,\n x=17pt,\n ytick=\\empty,\n xtick=\\empty,\n hide axis]\n    \\addplot[fill=yellow,opacity=0.5] coordinates\n        {(0,0.15) (1,0.1) (2,0.1) (3,0.2) (4,0.1)};\n    \\end{axis}\n\n\\Vertex[x=0,y=2,Pseudo]{bar_2}\n\\begin{axis}[ybar stacked, \nyshift = 2cm,\nheight=\\general_height\\textwidth,\n bar width=13pt,ymin=0,\n x=17pt,\n ytick=\\empty,\n xtick=\\empty,\n hide axis]\n    \\addplot[fill=pink,opacity=0.5] coordinates\n        {(0,0.1) (1,0.05) (2,0.3) (3,0.2) (4,0.0)};\n    \\end{axis}\n\n\n \n\\Vertex[x=0,y=0,Pseudo]{bar_4}\n\\begin{axis}[ybar stacked,\nheight=\\general_height\\textwidth,\n bar width=13pt,ymin=0,\n x=17pt,\n ytick=\\empty,\n xtick=\\empty,\n hide axis]\n    \\addplot[fill=gray,opacity=0.5] coordinates\n        {(0,0.1) (1,0.1) (2,0.15) (3,0.2) (4,0.15)};\n    \\end{axis}\n\n\n\n\\Vertex[x=0,y=-3,Pseudo]{bar_7}\n \n\\begin{axis}[ybar stacked, \nyshift = -3cm,\nheight=\\general_height\\textwidth,\n bar width=13pt,ymin=0,\n x=17pt,\n ytick=\\empty,\n xtick=\\empty,\n hide axis]\n\\addplot[fill=orange,opacity=0.5] coordinates\n        {(0,0.2) (1,0.1) (2,0.1) (3,0.2) (4,0.1)};\n\\end{axis}\n \n \\Vertex[x=3,y=0,Pseudo]{barplots}\n \n\\end{scope}\n\n\\begin{scope}[xshift=8cm]\n\\node[] at (1.5cm,4.5cm) {\\huge $X^{V(l+1)}$};\n\\node[align = center, text width=4cm] at (1.5cm,6cm) {\\Large Donn√©es sur le noeuds B};\n\n\\Vertex[x=0,y=0,Pseudo]{agregation}\n\n\n\\begin{axis}[ybar stacked,\nheight= 2*\\general_height\\textwidth,\nyshift = 0cm,\n bar width=13pt,ymin=0,\n x=17pt,\n ytick=\\empty,\n xtick=\\empty,\n hide axis]\n \\addplot[fill=orange,opacity=0.5] coordinates\n        {(0,0.2) (1,0.1) (2,0.1) (3,0.2) (4,0.1)};\n \n \n \\addplot[fill=gray,opacity=0.5] coordinates\n {(0,0.1) (1,0.1) (2,0.15) (3,0.2) (4,0.15)};\n  \n  \\addplot[fill=pink,opacity=0.5] coordinates\n  {(0,0.1) (1,0.05) (2,0.3) (3,0.2) (4,0.0)};\n  \\addplot[fill=yellow,opacity=0.5] coordinates\n  {(0,0.15) (1,0.1) (2,0.1) (3,0.2) (4,0.1)};\n \\end{axis}\n \\Vertex[x=3,y=1.5,Pseudo]{N}   \n\\end{scope}\n\n\n\\Edge[bend=35,style={dashed},Direct]($(A)!.5!(B)$)(bar_2)\n%\\Edge[bend=35,style={dashed},Direct]($(A)!.5!(C)$)(bar_3)\n%\\Edge[bend=-35,style={dashed},Direct]($(A)!.5!(D)$)(bar_6)\n%\\Edge[bend=-35,style={dashed},Direct]($(A)!.5!(E)$)(bar_5)\n\\Edge[bend=70,style={dashed},Direct]($(B)!.5!(C)$)(bar_1)\n\\Edge[bend=-35,style={dashed},Direct]($(B)!.5!(D)$)(bar_7)\n\\Edge[bend=10,style={dashed},Direct]($(B)!.5!(E)$)(bar_4)\n\n\n\n\n\n\\begin{scope}[xshift=14cm,scale=2]\n    \\Vertex[x=0.88,y=0.48,label=A,color=purple,opacity=0.5]{A2}\n\\Vertex[x=-0.18,y=0.98,label=B,color=purple,opacity=0.7]{B2}\n\\Vertex[x=-1,y=0.12,label=C,color=purple,opacity=0.4]{C2}\n\\Vertex[x=-0.42,y=-0.9,label=D,color=purple]{D2}\n\\Vertex[x=0.72,y=-0.69,label=E,color=purple,opacity=0.2]{E2}\n\n\\draw (A2) pic (YGH) {four colors={pink|green|red|blue|rotate=72}};\n\\draw (B2) pic (YGH) {four colors={yellow|pink|orange|gray|rotate=144}};\n\\draw (C2) pic (YGH) {four colors={yellow|yellow|green|green|rotate=36}};\n\\draw (D2) pic (YGH) {four colors={orange|orange|red|red|rotate=65}};\n\\draw (E2) pic (YGH) {four colors={gray|gray|blue|blue|rotate=100}};\n\n\\Edge[color=gray](A2)(B2)\n\\Edge[color=gray](A2)(C2)\n\\Edge[color=gray](A2)(D2)\n\\Edge[color=gray](A2)(E2)\n\\Edge[color=gray](B2)(C2)\n\\Edge[color=gray](B2)(D2)\n\\Edge[color=gray](B2)(E2)\n\\end{scope}\n\n\\Edge[style={dashed},Direct,label={\\Huge $\\phi$}](barplots)(agregation)\n\\Edge[style={dashed},bend=35,Direct](N)(B2)\n\n\\end{scope}\n\\end{tikzpicture}\n    \n    \n\\end{document}"
  },
  {
    "objectID": "latex/Pooling_edge.html",
    "href": "latex/Pooling_edge.html",
    "title": "Pooling edges",
    "section": "",
    "text": "\\documentclass[border=3pt,tikz]{standalone}\n\\usepackage{amsmath}\n\\usepackage[dvipsnames]{xcolor}\n\\usepackage{pgfplots}\n\\definecolor{taupegray}{rgb}{0.55, 0.52, 0.54}\n\\def\\general_height{0.2}\n\n\\usepackage{tikz-network}\n\\begin{document}\n\n\\begin{tikzpicture}\n\n    %\\Text[x=-0.18,y=3cm]{\\Large Couche $N$}\n    %\\Text[x=14cm,y=3cm]{\\Large Couche $N+1$}\n    \n    \\begin{scope}[scale=2]\n    \\Vertex[x=0.88,y=0.48,label=A,color=white]{A}\n    \\Vertex[x=-0.18,y=0.98,label=B,color=white]{B}\n    \\Vertex[x=-1,y=0.12,label=C,color=white]{C}\n    \\Vertex[x=-0.42,y=-0.9,label=D,color=white]{D}\n    \\Vertex[x=0.72,y=-0.69,label=E,color=white]{E}\n    \\Edge[color=pink](A)(B)\n    \\Edge[color=green](A)(C)\n    \\Edge[color=red](A)(D)\n    \\Edge[color=blue](A)(E)\n    \\Edge[color=yellow](B)(C)\n    \\Edge[color=orange](B)(D)\n    \\Edge[color=gray](B)(E)\n    \\end{scope}\n    \n    \\begin{scope}[xshift=4cm]\n    \\node[] at (1.5cm,4.5cm) {\\huge $X^{E(l)}$};\n    \\node[align = center, text width=5cm] at (1.5cm,6cm) {\\Large Donn√©es sur toutes les ar√™tes};\n    \n    \\Vertex[x=0,y=3,Pseudo]{bar_1}\n    \\begin{axis}[ybar stacked, \n    yshift = 3cm,\n    height=\\general_height\\textwidth,\n     bar width=13pt,ymin=0,\n     x=17pt,\n     ytick=\\empty,\n     xtick=\\empty,\n     hide axis]\n        \\addplot[fill=yellow,opacity=0.5] coordinates\n            {(0,0.15) (1,0.1) (2,0.1) (3,0.2) (4,0.1)};\n        \\end{axis}\n    \n    \\Vertex[x=0,y=2,Pseudo]{bar_2}\n    \\begin{axis}[ybar stacked, \n    yshift = 2cm,\n    height=\\general_height\\textwidth,\n     bar width=13pt,ymin=0,\n     x=17pt,\n     ytick=\\empty,\n     xtick=\\empty,\n     hide axis]\n        \\addplot[fill=pink,opacity=0.5] coordinates\n            {(0,0.1) (1,0.05) (2,0.3) (3,0.2) (4,0.0)};\n        \\end{axis}\n    \n    \\Vertex[x=0,y=1,Pseudo]{bar_3}\n    \\begin{axis}[ybar stacked, \n    yshift = 1cm,\n    height=\\general_height\\textwidth,\n     bar width=13pt,ymin=0,\n     x=17pt,\n     ytick=\\empty,\n     xtick=\\empty,\n     hide axis]\n        \\addplot[fill=green,opacity=0.5] coordinates\n            {(0,0.2) (1,0.05) (2,0.1) (3,0.15) (4,0.05)};\n        \\end{axis}\n     \n    \\Vertex[x=0,y=0,Pseudo]{bar_4}\n    \\begin{axis}[ybar stacked,\n    height=\\general_height\\textwidth,\n     bar width=13pt,ymin=0,\n     x=17pt,\n     ytick=\\empty,\n     xtick=\\empty,\n     hide axis]\n        \\addplot[fill=gray,opacity=0.5] coordinates\n            {(0,0.1) (1,0.1) (2,0.15) (3,0.2) (4,0.15)};\n        \\end{axis}\n    \n    \n    \n    \\Vertex[x=0,y=-1,Pseudo]{bar_5}\n    \\begin{axis}[ybar stacked, \n    yshift = -1cm,\n    height=\\general_height\\textwidth,\n     bar width=13pt,ymin=0,\n     x=17pt,\n     ytick=\\empty,\n     xtick=\\empty,\n     hide axis]\n        \\addplot[fill=blue,opacity=0.5] coordinates\n            {(0,0.2) (1,0.1) (2,0.2) (3,0.15) (4,0.05)};\n        \\end{axis}\n    \n    \\Vertex[x=0,y=-2,Pseudo]{bar_6}\n    \\begin{axis}[ybar stacked, \n    yshift = -2cm,\n    height=\\general_height\\textwidth,\n     bar width=13pt,ymin=0,\n     x=17pt,\n     ytick=\\empty,\n     xtick=\\empty,\n     hide axis]\n        \\addplot[fill=red,opacity=0.5] coordinates\n            {(0,0.1) (1,0.2) (2,0) (3,0.1) (4,0.1)};\n        \\end{axis}\n    \\Vertex[x=0,y=-3,Pseudo]{bar_7}\n     \n    \\begin{axis}[ybar stacked, \n    yshift = -3cm,\n    height=\\general_height\\textwidth,\n     bar width=13pt,ymin=0,\n     x=17pt,\n     ytick=\\empty,\n     xtick=\\empty,\n     hide axis]\n    \\addplot[fill=orange,opacity=0.5] coordinates\n            {(0,0.2) (1,0.1) (2,0.1) (3,0.2) (4,0.1)};\n    \\end{axis}\n     \n     \\Vertex[x=3,y=0,Pseudo]{barplots}\n    \n    \\end{scope}\n    \\begin{scope}[xshift=12cm]\n    \\node[] at (1.5cm,4.5cm) {\\huge $X^{U(l+1)}$};\n    \\node[align = center, text width=4cm] at (1.5cm,6cm) {\\Large Donn√©es de contexte global};\n    \n    \\Vertex[x=0,y=0,Pseudo]{agregation}\n    \n    \n    \\begin{axis}[ybar stacked,\n    height= 7cm,\n    yshift = -2cm,\n     bar width=13pt,ymin=0,\n     x=17pt,\n     ytick=\\empty,\n     xtick=\\empty,\n     hide axis]\n     \\addplot[fill=orange,opacity=0.5] coordinates\n            {(0,0.15) (1,0.1) (2,0.1) (3,0.2) (4,0.1)};\n      \\addplot[fill=red,opacity=0.5] coordinates\n            {(0,0.1) (1,0.05) (2,0.3) (3,0.2) (4,0.0)};\n      \\addplot[fill=blue,opacity=0.5] coordinates\n            {(0,0.2) (1,0.05) (2,0.1) (3,0.15) (4,0.05)};\n     \\addplot[fill=gray,opacity=0.5] coordinates\n            {(0,0.1) (1,0.1) (2,0.15) (3,0.2) (4,0.15)};\n      \\addplot[fill=green,opacity=0.5] coordinates\n            {(0,0.2) (1,0.1) (2,0.2) (3,0.15) (4,0.05)};\n      \\addplot[fill=pink,opacity=0.5] coordinates\n            {(0,0.1) (1,0.2) (2,0) (3,0.1) (4,0.1)};\n      \\addplot[fill=yellow,opacity=0.5] coordinates\n            {(0,0.2) (1,0.1) (2,0.1) (3,0.2) (4,0.1)};\n     \\end{axis}\n     \\Vertex[x=3,y=-3.5,Pseudo]{N}  \n    \\end{scope}\n    %\\node[align=center,text width=5cm] at (1,-4.5) {\\large Agr√©gation des donn√©es des noeuds voisins};\n    \n    \\Edge[bend=35,style={dashed},Direct]($(A)!.5!(B)$)(bar_2)\n    \\Edge[bend=35,style={dashed},Direct]($(A)!.5!(C)$)(bar_3)\n    \\Edge[bend=-35,style={dashed},Direct]($(A)!.5!(D)$)(bar_6)\n    \\Edge[bend=-35,style={dashed},Direct]($(A)!.5!(E)$)(bar_5)\n    \\Edge[bend=70,style={dashed},Direct]($(B)!.5!(C)$)(bar_1)\n    \\Edge[bend=-35,style={dashed},Direct]($(B)!.5!(D)$)(bar_7)\n    \\Edge[bend=10,style={dashed},Direct]($(B)!.5!(E)$)(bar_4)\n    \n    \\Edge[style={dashed},Direct,label={\\Huge $\\phi$}](barplots)(agregation)\n    \\end{tikzpicture}\n    \n    \n\\end{document}"
  },
  {
    "objectID": "latex/echantillonnage_etymologie.html",
    "href": "latex/echantillonnage_etymologie.html",
    "title": "Etymology of the word ‚Äú√©chantillonnage‚Äù",
    "section": "",
    "text": "\\documentclass[border=3pt,tikz]{standalone}\n\\usepackage{amsmath}\n\\usepackage[dvipsnames]{xcolor}\n\\usepackage{pgfplots}\n\\usetikzlibrary{calc}\n\\usetikzlibrary{shapes.geometric}\n\\usetikzlibrary{positioning}\n\\usetikzlibrary{arrows.meta} \n\\def\\v1{-4}\n\n\\begin{document}\n\n\\begin{tikzpicture}[thick,scale=1, every node/.style={scale=1.1}]\n    \\node[draw] (A) at (0,0) {√âchantillonnage};\n    \\node[text width = 5.5cm] (A2) at ($(A) + (5,1)$) {\\textit{Action d'√©chantillonner, d√©tacher un morceau, prendre un fragment ou une partie d'un ensemble pour repr√©senter l'ensemble.}};\n\n    \\node[diamond,draw] (age) at ($(A) + (7,-2)$) {-age};\n    \\node[text width = 2.2cm] (age2) at ($(age) + (2,0)$) {\\textit{R√©sultat d'une action.}};\n    \\draw[-&gt;,&gt;=stealth] (age)--(A);\n\n    \\node[diamond,draw] (aticus) at ($(age) + (0,-14.5)$) {-aticus};\n    \\node[text width = 2.2cm] (aticus2) at ($(aticus) + (2.1,0)$) {\\textit{R√©sultat d'une action.}};\n    \\draw[-&gt;,&gt;=stealth] (aticus)--(age);\n\n\n    \\node[draw,align=center,text width={width(\"√âchantillonnage\")}] (eschantillon) at ($(A) + (-2,-4)$) {eschantillon};\n\n    \\draw[-&gt;,&gt;=stealth] (eschantillon)--(A);\n\\node[text width = 3cm] (eschantillon2) at ($(eschantillon) + (3.2,0)$) {\\textit{Morceau de bois, brique, ou bord.}};\n    \\node[diamond,draw,align=center,text width={width(\" -age\")}] (on) at ($(eschantillon) + (6.5,-2)$) { -on};\n    \\node[text width = 2.2cm] (on2) at ($(on) + (2,0)$) {\\textit{Suffixe diminutif}};\n    \\draw[-&gt;,&gt;=stealth] (on)--(eschantillon);\n\n    \\node[draw,align=center,text width={width(\"√âchantillonnage\")}] (eschantille) at ($(eschantillon) + (0,-2.5)$) {eschantille};\n    \\node[text width = 2.5cm] (eschantille2) at ($(eschantille) + (2.9,0)$) {\\textit{Brique de petite √©paisseur.}};    \n    \\draw[-&gt;,&gt;=stealth] (eschantille)--(eschantillon);\n\n    \\node[diamond,draw,align=center,text width={width(\" -age\")}] (es) at ($(eschantille) + (-3.5,-2.5)$) { es-};\n    \\node[text width = 2.2cm] (es2) at ($(es) + (1.5,-0.5)$) {\\textit{\"Hors de\".}};\n\n    \\draw[-&gt;,&gt;=stealth] (es)--(eschantille);\n\n    \\node[diamond,draw,align=center,text width={width(\" -age\")}] (ex) at ($(es) + (0,-7)$) { ex-};\n    \\node[text width = 2.2cm] (ex2) at ($(ex) + (1.5,0.5)$) {\\textit{\"Hors de\".}};\n    \\draw[-&gt;,&gt;=stealth] (ex)--(es);\n\n  %  \\node[inner sep=0pt] (whitehead) at (-6,-2)\n  %  {\\includegraphics[width=0.5\\textwidth]{Vocabulaire_face_chant_bout.pdf}};\n\n    \\node[draw,align=center,text width={width(\"√âchantillonnage\")}] (chantille) at ($(eschantille) + (0,-2.5)$) {chantille};\n    \\node[text width = 2.5cm] (chantille2) at ($(chantille) + (2.9,0)$) {\\textit{Brique, r√©sultat d'une brisure.}};  \n    \\draw[-&gt;,&gt;=stealth] (chantille)--(eschantille);\n    \n\n    \\node[draw,align=center,text width={width(\"√âchantillonnage\")}] (chantel) at ($(chantille) + (0,-2.5)$) {chantel};\n    \\node[text width = 2.2cm] (chantel2) at ($(chantel) + (2.9,0)$) {\\textit{Morceau, fragment.}};  \n    \\draw[-&gt;,&gt;=stealth] (chantel)--(chantille);\n\n    \\node[diamond,draw,align=center,text width={width(\" -age\")}] (el) at ($(chantel) + (3,-2.5)$) { -el};\n    \\node[text width = 2.2cm] (el2) at ($(el) + (2,0)$) {\\textit{Suffixe diminutif.}};\n    \\draw[-&gt;,&gt;=stealth] (el)--(chantel);\n\n    \\node[diamond,draw,align=center] (ellus) at ($(el) + (0,-2.5)$) { -ellus};\n    \\node[text width = 2.2cm] (ellus2) at ($(ellus) + (2,0)$) {\\textit{Suffixe diminutif.}};\n    \\draw[-&gt;,&gt;=stealth] (ellus)--(el);\n\n    \\node[diamond,draw,align=center] (onis) at ($(on) + (0,-10.5)$) { -onis};\n    \\node[text width = 4cm] (onis2) at ($(onis) + (0,-1.5)$) {\\textit{Suffixe potentiellement augmentatif ou diminutif.}};\n    \\draw[-&gt;,&gt;=stealth] (onis)--(on);\n\n\n    \\node[draw,align=center,text width={width(\"√âchantillonnage\")}] (chant) at ($(chantel) + (0,-2.5)$) {chant};\n    \\node[text width = 2.2cm] (chant2) at ($(chant) + (-1.7,0.5)$) {\\textit{Bord le plus long d'une planche.}};  \n    \\draw[-&gt;,&gt;=stealth] (chant)--(chantel);\n\n    \\node[draw,align=center,text width={width(\"√âchantillonnage\")}] (canthus) at ($(chant) + (0,-2.5)$) {canthus};\n    \\node[text width = 2.2cm] (canthus2) at ($(canthus) + (-1.2,-0.7)$) {\\textit{Cerclage d'une roue.}};  \n    \\draw[-&gt;,&gt;=stealth] (canthus)--(chant);\n\n    \\node[draw,align=center,text width={width(\"√âchantillonnage\")}] (cantos) at ($(canthus) + (0,-2.5)$) {*cantos};\n    \\node[text width = 2.2cm] (cantos2) at ($(cantos) + (2.9,0)$) {\\textit{Cerclage d'une roue.}};  \n    \\draw[-&gt;,&gt;=stealth] (cantos)--(canthus);\n\n    \\draw[dashed] (-7.5,-3) -- (9,-3);\n    \\draw[dashed] (-7.5,-15) -- (9,-15);\n    \\draw[dashed] (-7.5,-18.5) -- (9,-18.5);\n\n    \\node[] (FR) at (-6,-2.5) {Fran√ßais}; \n    \\node[] (FR) at (-6,-3.5) {Ancien Fran√ßais}; \n    \\node[] (FR) at (-7,-14.5) {Ancien Fran√ßais}; \n    \\node[] (FR) at (-7,-15.5) {Latin}; \n    \\node[] (FR) at (-7,-18) {Latin};\n    \\node[] (FR) at (-7,-19) {Gaulois}; \n \n\n\n\n\n\\end{tikzpicture}\n%,align=left,label = right:\\textit{action d'√©chantilloner,\\\\ d√©tacher un morceau, prendre \\\\ un fragment ou une partie d'un ensemble pour repr√©senter l'ensemble.}\n\n\n\\end{document}"
  },
  {
    "objectID": "latex/complete_manquante.html",
    "href": "latex/complete_manquante.html",
    "title": "Missing data VS incomplete data",
    "section": "",
    "text": "\\documentclass[border=3pt,tikz]{standalone}\n\\usepackage{amsmath}\n\\usepackage[dvipsnames]{xcolor}\n\\usepackage{pgfplots}\n\\definecolor{taupegray}{rgb}{0.55, 0.52, 0.54}\n\\usepackage{tikz-network}\n\n\\begin{document}\n\n\\begin{tikzpicture}\n\n\n    %\\draw (0.1,1.25) node{$V^1$};\n    \\Vertex[x=0,y=0,label=1,color=white]{n1}\n    \\Vertex[x=0,y=-1,label=2,color=white]{n2}\n    \\Vertex[x=0,y=-2,label=3,color=white]{n3}\n\n    %\\draw (3.1,1.25) node{$V^2$};\n    \\Vertex[x=3,y=0.5,label=1,color=white,shape = rectangle]{m1}\n    \\Vertex[x=3,y=-0.5,label=2,color=white,shape = rectangle]{m2}\n    \\Vertex[x=3,y=-1.5,label=3,color=white,shape = rectangle]{m3}\n    \\Vertex[x=3,y=-2.5,label=4,color=white,shape = rectangle]{m4}\n\n\n    \\Edge[style=dashed,label=?,fontscale=1.5](n1)(m1)\n    \\Edge(n1)(m3)\n    \\Edge(n1)(m4)\n\n    \\Edge(n2)(m1)\n    \\Edge(n2)(m2)\n    \\Edge(n2)(m4)\n\n    \\Edge(n3)(m2)\n    \\Edge(n3)(m3)\n    \\Edge[style=dashed,label=?,fontscale=1.5](n3)(m4)\n\n\n    \n    \\draw (1.5,-4) node[scale=1]{\n        $B = \\begin{bmatrix}\n        \\texttt{NA} & 0 & 1 & 1 \\\\\n        1 & 1 & 0 & 1 \\\\\n        0 & 1 & 1 & \\texttt{NA} \\\\\n        \\end{bmatrix}\n        $};\n\n\n        \\begin{scope}[xshift=7 cm]\n        \n            %\\draw (0.1,1.25) node{$V^1$};\n            \\Vertex[x=0,y=0,label=1,color=white]{n1a}\n            \\Vertex[x=0,y=-1,label=2,color=white]{n2a}\n            \\Vertex[x=0,y=-2,label=3,color=white]{n3a}\n        \n            %\\draw (3.1,1.25) node{$V^2$};\n            \\Vertex[x=3,y=0.5,label=1,color=white,shape = rectangle]{m1a}\n            \\Vertex[x=3,y=-0.5,label=2,color=white,shape = rectangle]{m2a}\n            \\Vertex[x=3,y=-1.5,label=3,color=white,shape = rectangle]{m3a}\n            \\Vertex[x=3,y=-2.5,label=4,color=white,shape = rectangle]{m4a}\n        \n        \n            \\Edge[style=dashed,label=?,fontscale=1.5](n1a)(m1a)\n            \\Edge(n1a)(m3a)\n            \\Edge(n1a)(m4a)\n        \n            \\Edge(n2a)(m1a)\n            \\Edge(n2a)(m2a)\n            \\Edge(n2a)(m4a)\n        \n            \\Edge(n3a)(m2a)\n            \\Edge(n3a)(m3a)\n\n            \\Edge[style=dashed,label=?,fontscale=1.5,distance=.3](n1a)(m2a)\n            \\Edge[style=dashed,label=?,fontscale=1.5,distance=.7](n2a)(m3a)\n            \\Edge[style=dashed,label=?,fontscale=1.5,distance=.65](n3a)(m1a)\n            \\Edge[style=dashed,label=?,fontscale=1.5](n3a)(m4a)\n        \n\n\n    \n    \\draw (1.5,-4) node[scale=1]{\n        $B = \\begin{bmatrix}\n            \\texttt{NA} & \\texttt{NA} & 1 & 1 \\\\\n        1 & 1 & \\texttt{NA} & 1 \\\\\n        \\texttt{NA} & 1 & 1 & \\texttt{NA} \\\\\n        \\end{bmatrix}\n        $};\n\n\n            \n        \\end{scope}\n      \n\n\\end{tikzpicture}\n\\end{document}"
  },
  {
    "objectID": "latex/Neurone_formel.html",
    "href": "latex/Neurone_formel.html",
    "title": "Artificial neuron",
    "section": "",
    "text": "\\documentclass[border=3pt,tikz]{standalone}\n\\usepackage{amsmath} % for aligned\n\\usepackage{listofitems} % for \\readlist to create arrays\n\\usetikzlibrary{arrows.meta} % for arrow size\n\\usepackage[outline]{contour} % glow around text\n\\contourlength{1.4pt}\n\n% COLORS\n\n\\usepackage{contour} % glow around text\n\\contourlength{1.4pt}\n\n\\usepackage[dvipsnames]{xcolor}\n\\usepackage{pgfplots}\n\\definecolor{taupegray}{rgb}{0.55, 0.52, 0.54}\n\\usepackage{neuralnetwork}\n\n\\usepackage{tikz-network}\n\\usepackage{xcolor}\n\\colorlet{myred}{red!80!black}\n\\colorlet{myblue}{blue!80!black}\n\\colorlet{mygreen}{green!60!black}\n\\colorlet{myyellow}{yellow!60!white}\n\\colorlet{myorange}{orange!70!red!60!black}\n\\colorlet{mydarkred}{red!30!black}\n\\colorlet{mydarkblue}{blue!40!black}\n\\colorlet{mydarkgreen}{green!30!black}\n\\colorlet{mydarkyellow}{yellow!30!black}\n\n\\tikzset{\n  &gt;=latex, % for default LaTeX arrow head\n  node/.style={thick,circle,draw=myblue,minimum size=22,inner sep=0.5,outer sep=0.6},\n  node in/.style={node,green!20!black,draw=mygreen!30!black,fill=mygreen!25},\n  node hidden/.style={node,blue!20!black,draw=myblue!30!black,fill=myblue!20},\n  node convol/.style={node,orange!20!black,draw=myorange!30!black,fill=myorange!20},\n  node out/.style={node,red!20!black,draw=myred!30!black,fill=myred!20},\n  connect/.style={thick,mydarkblue}, %,line cap=round\n  connect arrow/.style={-{Latex[length=4,width=3.5]},thick,mydarkblue,shorten &lt;=0.5,shorten &gt;=1},\n  node 1/.style={node in}, % node styles, numbered for easy mapping with \\nstyle\n  node 2/.style={node hidden},\n  node 3/.style={node out}\n}\n\\def\\nstyle{int(\\lay&lt;\\Nnodlen?min(2,\\lay):3)} % map layer number onto 1, 2, or 3\n\n\\begin{document}\n\n\\begin{tikzpicture}%[x=2.7cm,y=1.6cm]\n  \\message{^^JNeural network activation}\n  \\def\\NI{5} % number of nodes in input layers\n  \\def\\NO{1} % number of nodes in output layers\n  \\def\\yshift{0.4} % shift last node for dots\n  \n  % INPUT LAYER\n  \\foreach \\i [evaluate={\\c=int(\\i==\\NI); \\y=\\NI/2-\\i-\\c*\\yshift; \\index=(\\i&lt;\\NI?int(\\i):\"n\");}]\n              in {1,...,\\NI}{ % loop over nodes\n    \\node[node in,outer sep=0.6] (NI-\\i) at (0,\\y) {$x_{\\index}$};\n  }\n  \n  % OUTPUT LAYER\n    \\node[node hidden]\n        (NO) at (3,-2*\\yshift) {$\\Sigma$};\n      \n      \\foreach \\j [evaluate={\\index=(\\j&lt;\\NI?int(\\j):\"n\");}] in {1,...,\\NI}{ % loop over nodes in previous layer\n         \\draw[connect arrow,white,line width=1.2] (NI-\\j) -- (NO);\n         \\draw[connect arrow] (NI-\\j) -- (NO)\n           node[pos=0.50] {\\contour{white}{$w_{\\index}$}};\n      }\n    \n    % \\fi\n  % DOTS\n  \\path (NI-\\NI) --++ (0,0.8+\\yshift) node[midway,scale=1.2] {$\\vdots$};\n\n  \\node[dashed, circle,draw=myblue,fill=mygreen!25]\n  (NB) at (3,2*\\yshift) {$b$};\n  \\draw[connect arrow] (NB) -- (NO);\n  \n  \\node[dashed,circle,draw=black,minimum size=22] (activation) at (5,-2*\\yshift) {};\n  %\\path (NO-\\NO) --++ (0,1+\\yshift) node[midway,scale=1.2] {$\\vdots$};\n      \\begin{scope}[shift={(5,-2*\\yshift)},scale=0.08]\n      \\draw[thick] (0,0) plot[domain=-3:3] (\\x,{6/(1 + exp(-1*\\x))-3});\n    \\end{scope}\n    \\draw[connect] (NO) -- (activation);\n  \n  \\node[node out] (output) at (7,-2*\\yshift) {$y$}; \n      \\draw[connect arrow] (activation) -- (output);\n\n  \\node[above=0.5,align=center,mygreen!60!black] at (NI-1.90) {Couche\\\\[-0.2em]d'entr√©e};\n  \\node[above=0.5,align=center,mygreen!60!black] at (NB) {Biais};\n  \\node[above=0.5,align=center,myblue!60!black] at (output) {Sortie};\n  \\node[above=0.5,align=center,black] at (activation) {Fonction\\\\[-0.2em]d'activation};\n  \\node[above=0.75,align=center,myblue!60!black] at (1.5,0) {Poids};\n  \\node[below=1,align=center ] at (6,-2*\\yshift) {$\\begin{aligned}\n  y=\\sigma\\left(\\sum_{i=1}^n  w_i x_i +b\\right)\n  \\end{aligned}$};\n\n\\end{tikzpicture}\n\n\\end{document}"
  },
  {
    "objectID": "latex/LBM.html",
    "href": "latex/LBM.html",
    "title": "Latent block model",
    "section": "",
    "text": "\\documentclass[border=3pt,tikz]{standalone}\n\\usepackage{pgfplots}\n\\usepackage[dvipsnames,table,xcdraw]{xcolor}\n\\usepackage{tikz}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{enumitem}\n\\usepackage[outline]{contour} % glow around text\n\\contourlength{0.4pt}\n\\definecolor{electricblue}{rgb}{0.49, 0.98, 1.0}\n\\definecolor{cyanind}{rgb}{0.0, 0.4, 0.65}\n\\definecolor{blueind}{rgb}{0.45, 0.76, 0.98}\n\\definecolor{burntorange}{rgb}{0.8, 0.33, 0.0}\n\\definecolor{goldenyellow}{rgb}{1.0, 0.87, 0.0}\n\\definecolor{peach}{rgb}{1.0, 0.23, 0.13 }\n\n\\usetikzlibrary{arrows,automata}\n\n\\begin{document}\n\\begin{tikzpicture}[scale=0.35]\n    \\tikzstyle{every state}=[draw, text=black,scale=0.95,\n    transform shape]\n    \\tikzstyle{every state}=[draw=none,text=black,scale=0.75,\n    transform shape]\n    \\tikzset{edge_proba/.style={draw=white, fill=none,\n                text=black}}\n\n    \\tikzstyle{every node}=[fill=blueind]\n    \\node[edge_proba] (pi1) at (1,5.7)\n    {\\textbf{$\\alpha_{{\\color{blueind}\\bullet}}$}};\n    \\node[state, draw=black!50] (R11) at (0,5) {\\textbf{A1 1}};\n    \\node[state, draw=black!50] (R12) at (1,5) {\\textbf{A1 2}};\n    \\node[state, draw=black!50] (R13) at (2,5) {\\textbf{A1 3}};\n\n    \\tikzstyle{every node}=[fill=cyanind]\n    \\node[edge_proba] (pi2) at (6.75,5.7)\n    {\\textbf{$\\alpha_{{\\color{cyanind}\\bullet}}$}};\n    \\node[state, draw=black!50] (R21) at (6.25,5)\n    {\\textbf{A2 1}};\n    \\node[state, draw=black!50] (R22) at (7.25,5)\n    {\\textbf{A2 2}};\n\n   % \\tikzstyle{every node}=[fill=electricblue]\n    %\\node[edge_proba] (pi3) at (10,5.7)\n    %{\\textbf{$\\alpha_{{\\color{electricblue}\\bullet}}$}};\n    %\\node[state, draw=black!50] (R31) at (10,5) {\\textbf{R31}};\n\n    \\tikzstyle{every node}=[fill=burntorange, shape=rectangle]\n    \\node[edge_proba] (pi3) at (-2.5,-1)\n    {\\textbf{$\\beta_{{\\color{burntorange}\\bullet}}$}};\n    \\tikzstyle{every state}=[draw=none,text=black,scale=0.75,\n    transform shape, shape=rectangle]\n    \\node[state, draw=black!50] (C11) at (-3,0) {\\textbf{B1 1}};\n    \\node[state, draw=black!50] (C12) at (-2,0) {\\textbf{B1 2}};\n    \\tikzstyle{every node}=[fill=goldenyellow, shape=rectangle]\n    \\node[edge_proba] (pi3) at (4,-1)\n    {\\textbf{$\\beta_{{\\color{goldenyellow}\\bullet}}$}};\n    \\node[state, draw=black!50] (C21) at (3.5,0) {\\textbf{B2 1}};\n    \\node[state, draw=black!50] (C22) at (4.5,0) {\\textbf{B2 2}};\n    \\tikzstyle{every node}=[fill=peach, shape=rectangle]\n    \\node[edge_proba] (pi3) at (10,-1)\n    {\\textbf{$\\beta_{{\\color{peach}\\bullet}}$}};\n    \\node[state, draw=black!50] (C31) at (10,0) {\\textbf{B3 1}};\n\n    \\tikzstyle{every edge}=[-,&gt;=stealth',shorten\n    &gt;=1pt,auto,draw,line width=1.5pt,draw opacity=0.2]\n\n    \\path (R11) edge[-,&gt;=stealth',shorten\n            &gt;=1pt,auto,draw=gray,line width=1.5pt, fill=gray, opacity=1] node[midway, left,\n            fill=none] {\\contour{white}{$\\pi_{{\\color{blueind}\\bullet}{\\color{burntorange}\\bullet}}$}}\n    (C11);\n    \\path (R11) edge (C12);\n    \\path (R11) edge  (C21);\n    \\path (R11) edge  (C22);\n\n    \\path (R11) edge  (C31);\n    \\path (R12) edge  (C31);\n    \\path (R13) edge  [-,&gt;=stealth',shorten\n    &gt;=1pt,auto,draw=gray,line width=1.5pt, fill=gray, opacity=1] node[pos = 0.75, right = -0.6cm,\n    fill=none] {\\contour{white}{$\\pi_{{\\color{blueind}\\bullet}{\\color{peach}\\bullet}}$}}(C31) ;\n\n\n    \\path (R12) edge  (C11);\n    \\path (R12) edge  (C12);\n    \\path (R12) edge  (C21);\n    \\path (R12) edge  (C22);\n\n    \\path (R13) edge [] (C11);\n    \\path (R13) edge  (C12);\n    \\path (R13) edge  (C21);\n    \\path (R13) edge[-,&gt;=stealth',shorten\n            &gt;=1pt,auto,draw=gray,line width=1.5pt, fill=gray, opacity=1] node[pos=0.7, right = -0.6cm,\n            fill=none] {\\contour{white}{$\\pi_{{\\color{blueind}\\bullet}{\\color{goldenyellow}\\bullet}}$}}\n    (C22);\n\n\n    \\path (R21) edge  (C22);\n    \\path (R21) edge  (C31);\n\n    \\path (R22) edge  (C21);\n    \\path (R22) edge  (C22);\n    \\path (R21) edge[-,&gt;=stealth',shorten\n            &gt;=1pt,auto,draw=gray,line width=1.5pt, fill=gray, opacity=1] node[pos=0.2,\n            right = -0.2cm, fill=none]\n        {\\contour{white}{$\\pi_{{\\color{cyanind}\\bullet}{\\color{goldenyellow}\\bullet}}$}} (C21);\n\n    \\path (R22) edge[-,&gt;=stealth',shorten\n            &gt;=1pt,auto,draw=gray,line width=1.5pt, fill=gray, opacity=1] node[midway, right = -0.6cm,\n            fill=none] {\\contour{white}{$\\pi_{{\\color{cyanind}\\bullet}{\\color{peach}\\bullet}}$}} (C31);\n\n    \\path (R21) edge   (C11);\n    \\path (R21) edge[-,&gt;=stealth',shorten\n    &gt;=1pt,auto,draw=gray,line width=1.5pt, fill=gray, opacity=1] node[pos = 0.60, right = -0.6cm,\n    fill=none] {\\contour{white}{$\\pi_{{\\color{cyanind}\\bullet}{\\color{burntorange}\\bullet}}$}}  (C12);\n\n  %  \\path (R31) edge[-,&gt;=stealth',shorten\n   %         &gt;=1pt,auto,draw=gray,line width=1.5pt, fill=gray, opacity=1] node[midway,\n    %        right, fill=none]\n     %   {\\contour{white}{$\\pi_{{\\color{electricblue}\\bullet}{\\color{peach}\\bullet}}$}} (C31);\n     \\tikzstyle{every node}=[fill=white, shape=rectangle,scale=0.5]\n\n     \\node at (15,5) {\n     $ \\begin{aligned}\n     & n_1 \\text{ n≈ìuds } i \\text{ r√©partis en  }Q_1=2 \\text{ clusters}\\\\\n     & n_2 \\text{ n≈ìuds } j \\text{ r√©partis en  }Q_2=3 \\text{ clusters}\n     \\end{aligned}$   \n     \n     };\n     %\\node at (15,4) {$n_2$ n≈ìuds $i$ r√©partis en $Q_2=3$ clusters};\n\n     \\node[below=1,align=center ] at (15,4) {$\\begin{aligned}\n       & \\bullet \\quad \\text{Clusters 1\\,:}\\  \\{\\textcolor{blueind}{\\bullet},\\textcolor{cyanind}{\\bullet}\\}\\\\\n       & \\bullet \\quad \\alpha_{\\bullet}  =  \\mathbb{P}(i  \\in  \\bullet), i=1,\\dots,n_1 \\\\\n       & \\\\\n       & \\bullet \\quad \\text{Clusters 2\\,:}\\  \\{\\textcolor{burntorange}{\\bullet},\\textcolor{goldenyellow}{\\bullet},\\textcolor{peach}{\\bullet}\\}\\\\\n       & \\bullet \\quad \\beta_{\\bullet}  =  \\mathbb{P}(j  \\in  \\bullet), j=1,\\dots,n_2 \\\\\n       &\\\\\n    & \\bullet \\quad \\pi_{\\textcolor{cyanind}{\\bullet}\\textcolor{burntorange}{\\bullet}}     =      \\mathbb{P}(i\n    \\leftrightarrow j | i\\in\\textcolor{cyanind}{\\bullet},j\\in\\textcolor{burntorange}{\\bullet})\n    \\end{aligned}$\n    };\n    \n    \\node at (15,-2) {$B \\sim LBM_{n_1\\times n_2}(Q_1,Q_2,\\alpha,\\beta,\\pi)$};\n\n\\end{tikzpicture}\n\n\\end{document}"
  },
  {
    "objectID": "latex/Node_clustering.html",
    "href": "latex/Node_clustering.html",
    "title": "Node clustering",
    "section": "",
    "text": "The following code assumes that the following files are located in the same directory as the .tex file :vertices.csv edges.csv\n\nvertices = read.table(\"vertices.csv\",header=T, sep= \",\")\nhead(vertices)\n\n  id          x          y  color\n1  H -1.6101224  0.2582157 yellow\n2  2 -0.7862112  0.1226055 yellow\n3  3 -0.2621141  0.9662158 yellow\n4  4 -1.3783554  1.1100772 yellow\n5  5 -2.8386329 -0.4002378 yellow\n6  6 -3.4978099 -0.2904431 yellow\n\n\n\nedges = read.table(\"edges.csv\",header=T, sep= \",\")\nhead(edges)\n\n  u v\n1 H 2\n2 H 3\n3 H 4\n4 H 5\n5 H 6\n6 H 7\n\n\n\\documentclass[border=3pt,tikz]{standalone}\n\\usepackage{amsmath}\n\\usepackage[dvipsnames]{xcolor}\n\\usepackage{pgfplots}\n\\definecolor{taupegray}{rgb}{0.55, 0.52, 0.54}\n\n\\usepackage{tikz-network}\n\n\\begin{document}\n\n\\begin{tikzpicture}\n    %\\draw (-4,-3) grid (3,3);\n    \\draw[color=red,dashed,fill=red, fill opacity = 0.25] (-2.1,0.25) ellipse (3 and 2);\n    \\draw[color=blue,dashed,fill=blue, fill opacity = 0.25,rotate around = {-45:(2.9,1.4)}] (2.9,1.4) ellipse (3 and 2);\n    \\Vertices[color=vertexfill]{vertices.csv}\n    \\Edges{edges.csv}\n\\end{tikzpicture}\n\n\n\\end{document}"
  },
  {
    "objectID": "latex/neurone_formel_matriciel.html",
    "href": "latex/neurone_formel_matriciel.html",
    "title": "Matrix formulation of neural networks",
    "section": "",
    "text": "\\documentclass[border=3pt,tikz]{standalone}\n\\usepackage{amsmath} % for aligned\n\\usepackage{amssymb}\n\\usepackage{listofitems} % for \\readlist to create arrays\n\\usetikzlibrary{arrows.meta} % for arrow size\n\\usepackage[outline]{contour} % glow around text\n\\contourlength{1.4pt}\n\n% COLORS\n\\usepackage{xcolor}\n\\colorlet{myred}{red!80!black}\n\\colorlet{myblue}{blue!80!black}\n\\colorlet{mygreen}{green!60!black}\n\\colorlet{myyellow}{yellow!60!white}\n\\colorlet{myorange}{orange!70!red!60!black}\n\\colorlet{mydarkred}{red!30!black}\n\\colorlet{mydarkblue}{blue!40!black}\n\\colorlet{mydarkgreen}{green!30!black}\n\\colorlet{mydarkyellow}{yellow!30!black}\n\n% STYLES\n\\tikzset{\n  &gt;=latex, % for default LaTeX arrow head\n  node/.style={thick,circle,draw=myblue,minimum size=22,inner sep=0.5,outer sep=0.6},\n  node in/.style={node,green!20!black,draw=mygreen!30!black,fill=mygreen!25},\n  node hidden/.style={node,blue!20!black,draw=myblue!30!black,fill=myblue!20},\n  node convol/.style={node,orange!20!black,draw=myorange!30!black,fill=myorange!20},\n  node out/.style={node,red!20!black,draw=myred!30!black,fill=myred!20},\n  connect/.style={thick,mydarkblue}, %,line cap=round\n  connect arrow/.style={-{Latex[length=4,width=3.5]},thick,mydarkblue,shorten &lt;=0.5,shorten &gt;=1},\n  node 1/.style={node in}, % node styles, numbered for easy mapping with \\nstyle\n  node 2/.style={node hidden},\n  node 3/.style={node out}\n}\n\\def\\nstyle{int(\\lay&lt;\\Nnodlen?min(2,\\lay):3)} % map layer number onto 1, 2, or 3\n\n\n\\begin{document}\n\n\\begin{tikzpicture}[x=2.7cm,y=1.6cm]\n  \\message{^^JNeural network activation}\n  \\def\\NI{5} % number of nodes in input layers\n  \\def\\NO{4} % number of nodes in output layers\n  \\def\\yshift{0.4} % shift last node for dots\n  \n  % INPUT LAYER\n  \\foreach \\i [evaluate={\\c=int(\\i==\\NI); \\y=\\NI/2-\\i-\\c*\\yshift; \\index=(\\i&lt;\\NI?int(\\i):\"n\");}]\n              in {1,...,\\NI}{ % loop over nodes\n    \\node[node in,outer sep=0.6] (NI-\\i) at (0,\\y) {$x_{\\index}^{(0)}$};\n  }\n  \n  % OUTPUT LAYER\n  \\foreach \\i [evaluate={\\c=int(\\i==\\NO); \\y=\\NO/2-\\i-\\c*\\yshift; \\index=(\\i&lt;\\NO?int(\\i):\"m\");}]\n    in {\\NO,...,1}{ % loop over nodes\n    \\ifnum\\i=1 % high-lighted node\n      \\node[node hidden]\n        (NO-\\i) at (1,\\y) {$x_{\\index}^{(1)}$};\n      \\foreach \\j [evaluate={\\index=(\\j&lt;\\NI?int(\\j):\"n\");}] in {1,...,\\NI}{ % loop over nodes in previous layer\n        \\draw[connect arrow,white,line width=1.2] (NI-\\j) -- (NO-\\i);\n        \\draw[connect arrow] (NI-\\j) -- (NO-\\i)\n          node[pos=0.50] {\\contour{white}{$w_{1,\\index}$}};\n      }\n    \\else % other light-colored nodes\n      \\node[node,blue!20!black!80,draw=myblue!20,fill=myblue!5]\n        (NO-\\i) at (1,\\y) {$x_{\\index}^{(1)}$};\n      \\foreach \\j in {1,...,\\NI}{ % loop over nodes in previous layer\n        %\\draw[connect,white,line width=1.2] (NI-\\j) -- (NO-\\i);\n        \\draw[connect arrow,myblue!20] (NI-\\j) -- (NO-\\i);\n      }\n    \\fi\n  }\n  \n  % DOTS\n  \\path (NI-\\NI) --++ (0,1+\\yshift) node[midway,scale=1.2] {$\\vdots$};\n  \\path (NO-\\NO) --++ (0,1+\\yshift) node[midway,scale=1.2] {$\\vdots$};\n  \n  % EQUATIONS\n  \\def\\agr#1{{\\color{mydarkgreen}x_{#1}^{(0)}}} % green a_i^j\n  \\node[below=16,right=11,mydarkblue,scale=0.95] at (NO-1)\n    {$\\begin{aligned} %\\underset{\\text{bias}}{b_1}\n       &= \\color{mydarkred}\\sigma\\left( \\color{black}\n            w_{1,1}\\agr{1} + w_{1,2}\\agr{2} + \\ldots + w_{1,n}\\agr{n} + b_1^{(0)}\n          \\color{mydarkred}\\right)\\\\\n       &= \\color{mydarkred}\\sigma\\left( \\color{black}\n            \\sum_{i=1}^{n} w_{1,i}\\agr{i} + b_1^{(0)}\n           \\color{mydarkred}\\right) = \\sigma\\left(z^{(1)}_1 \\right) \\in \\mathbb{R}\n     \\end{aligned}$ };\n  \\node[right,scale=0.9] at (1.3,-1.3)\n    {$\\begin{aligned}\n      {\\color{mydarkblue}\n      \\begin{pmatrix}\n        x_{1}^{(1)} \\\\[0.3em]\n        x_{2}^{(1)} \\\\\n        \\vdots \\\\\n        x_{m}^{(1)}\n      \\end{pmatrix}}\n      &=\n      \\color{mydarkred}\\sigma\\left[ \\color{black}\n      \\begin{pmatrix}\n        w_{1,1} & w_{1,2} & \\ldots & w_{1,n} \\\\\n        w_{2,1} & w_{2,2} & \\ldots & w_{2,n} \\\\\n        \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n        w_{m,1} & w_{m,2} & \\ldots & w_{m,n}\n      \\end{pmatrix}\n      {\\color{mydarkgreen}\n      \\begin{pmatrix}\n        x_{1}^{(0)} \\\\[0.3em]\n        x_{2}^{(0)} \\\\\n        \\vdots \\\\\n        x_{n}^{(0)}\n      \\end{pmatrix}}\n      +\n      \\begin{pmatrix}\n        b_{1}^{(0)} \\\\[0.3em]\n        b_{2}^{(0)} \\\\\n        \\vdots \\\\\n        b_{m}^{(0)}\n      \\end{pmatrix}\n      \\color{mydarkred}\\right]\\\\[0.5em]\n      {\\color{mydarkblue}\\mathbf{x}^{(1)}} % vector (bold)\n      &= \\color{mydarkred}\\sigma\\left( \\color{black}\n           \\mathbf{W}^{(0)} {\\color{mydarkgreen}\\mathbf{x}^{(0)}}+\\mathbf{b}^{(0)}\n         \\color{mydarkred}\\right) \\color{black} = \\sigma\\left(z^{(1)} \\right)  \\in \\mathbb{R}^m \n    \\end{aligned}$};\n\\end{tikzpicture}\n\n\\end{document}"
  },
  {
    "objectID": "latex/Node_classification.html",
    "href": "latex/Node_classification.html",
    "title": "Node classification",
    "section": "",
    "text": "The following code assumes that the following files are located in the same directory as the .tex file :vertices.csv edges.csv\n\nvertices = read.table(\"vertices.csv\",header=T, sep= \",\")\nhead(vertices)\n\n  id          x          y  color\n1  H -1.6101224  0.2582157 yellow\n2  2 -0.7862112  0.1226055 yellow\n3  3 -0.2621141  0.9662158 yellow\n4  4 -1.3783554  1.1100772 yellow\n5  5 -2.8386329 -0.4002378 yellow\n6  6 -3.4978099 -0.2904431 yellow\n\n\n\nedges = read.table(\"edges.csv\",header=T, sep= \",\")\nhead(edges)\n\n  u v\n1 H 2\n2 H 3\n3 H 4\n4 H 5\n5 H 6\n6 H 7\n\n\n\\documentclass[border=3pt,tikz]{standalone}\n\\usepackage{amsmath}\n\\usepackage[dvipsnames]{xcolor}\n\\usepackage{pgfplots}\n\\definecolor{taupegray}{rgb}{0.55, 0.52, 0.54}\n\n\\usepackage{tikz-network}\n\\begin{document}\n\n\\begin{tikzpicture}\n    \\Vertices{vertices.csv}\n    \\Edges{edges.csv}\n    %I'm just covering two nodes with black nodes\n    \\Vertex[x=-3.46945129191032,y=0.133852921140818,color=black,fontcolor= white,label=\\textbf{?},fontsize=\\LARGE]{t1}\n    \\Vertex[x=3.89715084263323,y=0.296719898386208,color=black,fontcolor= white,label=\\textbf{?},fontsize=\\LARGE]{t2}\n\\end{tikzpicture}\n    \n    \n\\end{document}"
  },
  {
    "objectID": "latex/Link_prediction.html",
    "href": "latex/Link_prediction.html",
    "title": "Link prediction",
    "section": "",
    "text": "The following code assumes that the following files are located in the same directory as the .tex file :vertices.csv edges.csv\n\nvertices = read.table(\"vertices.csv\",header=T, sep= \",\")\nhead(vertices)\n\n  id          x          y  color\n1  H -1.6101224  0.2582157 yellow\n2  2 -0.7862112  0.1226055 yellow\n3  3 -0.2621141  0.9662158 yellow\n4  4 -1.3783554  1.1100772 yellow\n5  5 -2.8386329 -0.4002378 yellow\n6  6 -3.4978099 -0.2904431 yellow\n\n\n\nedges = read.table(\"edges.csv\",header=T, sep= \",\")\nhead(edges)\n\n  u v\n1 H 2\n2 H 3\n3 H 4\n4 H 5\n5 H 6\n6 H 7\n\n\n\\documentclass[border=3pt,tikz]{standalone}\n\\usepackage{amsmath}\n\\usepackage[dvipsnames]{xcolor}\n\\usepackage{pgfplots}\n\\definecolor{taupegray}{rgb}{0.55, 0.52, 0.54}\n\n\\usepackage{tikz-network}\n\\begin{document}\n\n\\begin{tikzpicture}\n    \\Vertices[color=vertexfill]{vertices.csv}\n    \\Edges{edges.csv}\n    \\Edge[style={dashed},label=\\textbf{?},fontcolor=black,fontsize=\\LARGE](13)(10)\n    \\Edge[style={dashed},label=\\textbf{?},fontcolor=black,fontsize=\\LARGE](20)(21)\n    \\Edge[style={dashed},label=\\textbf{?},fontcolor=black,fontsize=\\LARGE](17)(13)\n\\end{tikzpicture}\n\n\\end{document}"
  },
  {
    "objectID": "posts/GNN_feature_importance.html",
    "href": "posts/GNN_feature_importance.html",
    "title": "Interpretability of Graph Neural Networks to Assess Effects of Global Change Drivers on Ecological Networks",
    "section": "",
    "text": "Pollinators play a crucial role for plant reproduction, either in natural ecosystem or in human-modified landscape. Global change drivers,including climate change or land use modifications, can alter the plant-pollinator interactions. To assess the potential influence of global change drivers on pollination, large-scale interactions, climate and land use data are required. While recent machine learning methods, such as graph neural networks (GNNs), allow the analysis of such datasets, interpreting their results can be challenging. We explore existing methods for interpreting GNNs in order to highlight the effects of various environmental covariates on pollination network connectivity. A large simulation study is performed to confirm whether these methods can detect the interactive effect between a covariate and a genus of plant on connectivity, and whether the application of debiasing techniques influences the estimation of these effects. An application on the Spipoll dataset, with and without accounting for sampling effects, highlights the potential impact of land use on network connectivity and shows that accounting for sampling effects partially alters the estimation of these effects.\nLink to paper\nLink to preprint\nGitHub Repository"
  },
  {
    "objectID": "posts/GNN_feature_importance.html#abstract",
    "href": "posts/GNN_feature_importance.html#abstract",
    "title": "Interpretability of Graph Neural Networks to Assess Effects of Global Change Drivers on Ecological Networks",
    "section": "",
    "text": "Pollinators play a crucial role for plant reproduction, either in natural ecosystem or in human-modified landscape. Global change drivers,including climate change or land use modifications, can alter the plant-pollinator interactions. To assess the potential influence of global change drivers on pollination, large-scale interactions, climate and land use data are required. While recent machine learning methods, such as graph neural networks (GNNs), allow the analysis of such datasets, interpreting their results can be challenging. We explore existing methods for interpreting GNNs in order to highlight the effects of various environmental covariates on pollination network connectivity. A large simulation study is performed to confirm whether these methods can detect the interactive effect between a covariate and a genus of plant on connectivity, and whether the application of debiasing techniques influences the estimation of these effects. An application on the Spipoll dataset, with and without accounting for sampling effects, highlights the potential impact of land use on network connectivity and shows that accounting for sampling effects partially alters the estimation of these effects.\nLink to paper\nLink to preprint\nGitHub Repository"
  },
  {
    "objectID": "Cours/ML_cours2.html",
    "href": "Cours/ML_cours2.html",
    "title": "Mod√®le lin√©aire multiple",
    "section": "",
    "text": "library(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.1     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.2     ‚úî tibble    3.3.0\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.1\n‚úî purrr     1.1.0     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(extrafont) \n\nRegistering fonts with R\n\nrequire(ggsci)\n\nLe chargement a n√©cessit√© le package : ggsci\n\nlibrary(ggpubr)\nlibrary(knitr)\nlibrary(ggfortify)\nlibrary(ggrepel)",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#probl√©matique-biologique",
    "href": "Cours/ML_cours2.html#probl√©matique-biologique",
    "title": "Mod√®le lin√©aire multiple",
    "section": "0.1 Probl√©matique biologique",
    "text": "0.1 Probl√©matique biologique\n\n\n\n\n\n\nWarningObjectif\n\n\n\n\nPeut-on pr√©dire le poids des poissons par leurs largeurs, leurs longueurs et leurs √©paisseurs ?\nTester le caract√®re significatif de la liaison : Y‚Äôa t‚Äôil un lien significatif entre le poids des poissons et leurs largeurs, leurs longueurs et leurs √©paisseurs ?\nY‚Äôa t‚Äôil un lien entre le poids du poisson et sa largeur apr√®s avoir pris en compte sa longueur et son epaisseur ?\n\n\n\n\nDonn√©es On a pour 20 br√®mes p√©ch√©es dans le lac Laengelmavesi en Finland leurs poids (en gramme) et leurs longeurs (en cm), leurs largeurs (en cm) leurs √©paisseur (en cm).",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#√©criture-du-mod√®le",
    "href": "Cours/ML_cours2.html#√©criture-du-mod√®le",
    "title": "Mod√®le lin√©aire multiple",
    "section": "1.1 √âcriture du mod√®le",
    "text": "1.1 √âcriture du mod√®le\n\n1.1.0.1 Notations\n\nOn a \\(n = 20\\) observations. On note, pour \\(1 \\leq i \\leq 20\\)\n\n\\(x_{1,i}\\) la mesure de la longueur du poisson \\(i\\).\n\\(x_{2,i}\\) la mesure de la largeure du poisson \\(i\\).\n\\(x_{3,i}\\) la mesure de l‚Äôepaisseur du poisson \\(i\\).\n\\(y_i\\) la mesure du poids du poisson \\(i\\).\n\n\n\n\n\n\n\nNoteD√©finition : Mod√®le de r√©gression lin√©aire multiple\n\n\n\nOn suppose que \\(y_i\\) est la r√©alisation d‚Äôune variable al√©atoire \\(Y_i\\) telle que: \\[Y_i = \\alpha_1 x_{1,i} + \\alpha_2 x_{2,i} + \\alpha_3 x_{3,i} + \\beta  + E_i,\\quad 1 \\leq i \\leq n\\]\n\n\\(\\alpha_1\\) (resp \\(\\alpha_2\\) , \\(\\alpha_3\\) ) est un param√®tre inconnu, l‚Äôeffet de la longueur (resp largeur, √©paisseur) sur le poids;\n\\(\\beta\\) est un param√®tre inconnu;\n\\(E_i\\) une variable al√©atoire, \\(E_i \\overset{i.i.d.}\\sim \\mathcal{N}(0, \\sigma^2)\\)\nLes \\(x_i\\) sont lin√©airement ind√©pendants",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#√©criture-plus-g√©n√©rale-du-mod√®le",
    "href": "Cours/ML_cours2.html#√©criture-plus-g√©n√©rale-du-mod√®le",
    "title": "Mod√®le lin√©aire multiple",
    "section": "1.2 √âcriture plus g√©n√©rale du mod√®le",
    "text": "1.2 √âcriture plus g√©n√©rale du mod√®le\n\n1.2.0.1 Notations\n\nOn a \\(n = 20\\) observations. On note, pour \\(1 \\leq i \\leq 20\\)\n\n\\(x_{1}, \\dots, x_{p}\\), \\(p\\) variables explicatives et \\(y\\) une variable r√©ponse\n\\(y_i\\) la mesure de la variable r√©ponse de l‚Äôindividu \\(i\\).\n\\(\\forall j \\in \\{ 1,\\dots, p \\}\\), \\(x_{j,i}\\) la valeur de la variable \\(x_j\\) de l‚Äôindividu \\(i\\)\n\n\n\n\n\n\n\nNoteD√©finition : Mod√®le de r√©gression lin√©aire multiple\n\n\n\nOn suppose que \\(y_i\\) est la r√©alisation d‚Äôune variable al√©atoire \\(Y_i\\) telle que: \\[Y_i = \\sum_{j=1}^p \\alpha_j x_{j,i} + \\beta  + E_i,\\quad 1 \\leq i \\leq n\\]\n\n\\(\\alpha_j\\) est un param√®tre inconnu, l‚Äôeffet de la variable \\(x_j\\) sur le y;\n\\(\\beta\\) est un param√®tre inconnu\n\\(E_i\\) une variable al√©atoire, \\(E_i \\overset{i.i.d.}\\sim \\mathcal{N}(0, \\sigma^2)\\)\nLes \\(x_i\\) sont lin√©airement ind√©pendants (en pratique v√©rifier avec le VIF)",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#deux-√©critures-√©quivalentes",
    "href": "Cours/ML_cours2.html#deux-√©critures-√©quivalentes",
    "title": "Mod√®le lin√©aire multiple",
    "section": "1.3 Deux √©critures √©quivalentes",
    "text": "1.3 Deux √©critures √©quivalentes\n\n\n\n\n\n\nCautionRemarques\n\n\n\nLes deux mod√®les suivant sont √©quivalent :\n\n\\(\\forall i \\in \\{1, \\dots, n\\} \\;\\;\\)\n\n\\[ Y_i = \\sum_{j=1}^p \\alpha_j x_{j,i} + \\beta  + E_i,\\quad  \\ E_i \\overset{i.i.d.}\\sim \\mathcal{N}(0, \\sigma^2)\\]\n\n\\(\\forall i \\in \\{1, \\dots, n\\} \\;\\;\\)\n\n\\[ Y_i \\overset{i.i.d.}\\sim \\mathcal{N}\\left(\\sum_{j=1}^p \\alpha_j x_{j,i} + \\beta, \\sigma^2\\right)\\]",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#dans-lexemple-des-poissons",
    "href": "Cours/ML_cours2.html#dans-lexemple-des-poissons",
    "title": "Mod√®le lin√©aire multiple",
    "section": "1.4 Dans l‚Äôexemple des poissons",
    "text": "1.4 Dans l‚Äôexemple des poissons\n\n\n\n\n\n\nCautionRemarques\n\n\n\nLes deux mod√®les suivant sont √©quivalent :\n\n\\(\\forall i \\in \\{1, \\dots, n\\} \\;\\;\\) \\[ Y_i = \\alpha_1 x_{1,i} + \\alpha_2 x_{2,i} + \\alpha_3 x_{3,i} + \\beta  + E_i,\\quad  \\ E_i \\overset{i.i.d.}\\sim \\mathcal{N}(0, \\sigma^2)\\]\n\\(\\forall i \\in \\{1, \\dots, n\\} \\;\\;\\) \\[Y_i \\overset{i.i.d.}\\sim \\mathcal{N}\\left(\\alpha_1 x_{1,i} + \\alpha_2 x_{2,i} + \\alpha_3 x_{3,i} + \\beta, \\sigma^2\\right)\\]",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#remarques-sur-les-param√®tres",
    "href": "Cours/ML_cours2.html#remarques-sur-les-param√®tres",
    "title": "Mod√®le lin√©aire multiple",
    "section": "1.5 Remarques sur les param√®tres",
    "text": "1.5 Remarques sur les param√®tres\n\n\n\n\n\n\n\nCautionRemarques\n\n\n\nDans le mod√®le \\(\\forall i \\in \\{1, \\dots, n\\} \\;\\;\\) \\[ Y_i = \\sum_{j=1}^p \\alpha_j x_{j,i} + \\beta  + E_i,\\quad\\ E_i \\overset{i.i.d.}\\sim \\mathcal{N}(0, \\sigma^2)\\]\n\n\\(\\alpha_j\\) repr√©sente l‚Äôaccroissement de \\(Y_i\\) correspondant √† l‚Äôaccroissement d‚Äôune unit√© sur \\(x_j\\) si les autres variables explicatives sont fix√©es. Dans l‚Äôexemple des poissons : \\(\\alpha_1\\) represente l‚Äôaccroissement du poids correspondant √† l‚Äôaccroissement d‚Äô1 cm sur la longeurs du poisson si la largeur et l‚Äô√©paisseur son fix√©.\nCe mod√®le est de dimension \\(p + 1\\). (Avec \\(p+1\\) param√®tres d‚Äôesp√©rance √† estimer \\(p\\) pour \\(\\alpha\\) et \\(1\\) pour\\(\\beta\\))\n\\(\\forall i \\in \\{1, \\dots, n\\}\\) \\(Y_i\\) se d√©compose en \\(\\color{red}{Y_i} = {\\color{blue}{\\underbrace{\\displaystyle\\sum_{j=1}^p \\alpha_j x_{j,i} + \\beta}_{{d√©terministe}{}}}}  + \\color{red}{\\overbrace{E_i}^{al√©atoire}}\\)",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#rappel-sur-les-matrices",
    "href": "Cours/ML_cours2.html#rappel-sur-les-matrices",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.1 Rappel sur les matrices",
    "text": "2.1 Rappel sur les matrices\n\nQu‚Äôest ce qu‚Äôune matrice ?\nLa multiplication matricielle\nLa transpos√©e d‚Äôune matrice\nL‚Äôinverse d‚Äôune matrice\nPetits topo sur les vecteurs",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#rappels-dalg√®bre",
    "href": "Cours/ML_cours2.html#rappels-dalg√®bre",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.2 Rappels d‚Äôalg√®bre",
    "text": "2.2 Rappels d‚Äôalg√®bre\n\n\n\n\n\n\n\n\n\nNoteRappel : Matrice\n\n\n\n\\(A = (a_{i,j})_{1\\leq i \\leq p, 1\\leq j \\leq q}\\) est une matrice √† coefficients r√©els de format \\((p \\times q)\\)\n\\[A = \\begin{bmatrix}\na_{11} & a_{12} & \\ldots & a_{1q}\\\\\na_{21} & a_{22} & \\ldots & a_{2q}\\\\\n\\vdots & \\vdots & & \\vdots \\\\\na_{p1} & a_{p2} & \\ldots & a_{pq}\n\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\n\nNoteRappel : Transpos√©e d‚Äôune matrice\n\n\n\nSi \\(A = (a_{i,j})_{1\\leq i \\leq p, 1\\leq j \\leq q}\\) est une matrice \\((p \\times q)\\), on note alors \\(A^t\\) sa transpos√©e, la matrice \\((q \\times p)\\) d√©finie par\n\\[A^t = \\begin{bmatrix}\na_{11} & a_{21} & \\ldots & a_{p1}\\\\\na_{12} & a_{22} & \\ldots & a_{p2}\\\\\n\\vdots & \\vdots & & \\vdots \\\\\na_{1q} & a_{2q} & \\ldots & a_{pq}\n\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteRappel : Matrice sym√©trique\n\n\n\n\\(A\\) est une matrice sym√©trique si :\n\n\\(A\\) est une matrice carr√© (\\(p=q\\))\n\\(A^t = A\\)\n\n\n\n\n\n\n\n\n\n\nNoteRappel : Transpos√©e du produit\n\n\n\nSoit \\(A\\) et \\(B\\) deux matrices. On a\n\\[ (A  B)^t  = B^t A^t\\]",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#rappels-dalg√®bre-vecteur",
    "href": "Cours/ML_cours2.html#rappels-dalg√®bre-vecteur",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.3 Rappels d‚Äôalg√®bre : Vecteur",
    "text": "2.3 Rappels d‚Äôalg√®bre : Vecteur\n\n\n\n\n\n\nNoteRappel : Vecteurs\n\n\n\n\nOn note V un vecteur √† \\(p\\) √©l√©ments par\n\n\\[V = \\begin{bmatrix} v_{1} \\\\ v_{2}\\\\ \\vdots \\\\ v_{p} \\end{bmatrix}= \\left[{v_1, v_2, \\ldots, v_p}\\right]^t \\]",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#rappels-dalg√®bre-vecteur-1",
    "href": "Cours/ML_cours2.html#rappels-dalg√®bre-vecteur-1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.4 Rappels d‚Äôalg√®bre : Vecteur",
    "text": "2.4 Rappels d‚Äôalg√®bre : Vecteur\n\n\n\n\n\n\nNoteRappel : Produit matrice-vecteur\n\n\n\nSi \\(V\\) est un vecteur √† \\(q\\) √©l√©ments et \\(A\\) une matrice \\((p \\times q)\\) alors, \\(U=AV\\) est un vecteur √† \\(p\\) √©l√©ments\n\\[ \\begin{bmatrix} u_{1} \\\\ u_{2}\\\\ \\vdots \\\\ u_{p} \\end{bmatrix} = AV =\n\\begin{bmatrix}\na_{11} & a_{12} & \\ldots & a_{1q}\\\\\na_{21} & a_{22} & \\ldots & a_{2q}\\\\\n\\vdots & \\vdots & & \\vdots \\\\\na_{p1} & a_{p2} & \\ldots & a_{pq}\n\\end{bmatrix}\\begin{bmatrix} v_{1} \\\\ v_{2}\\\\ \\vdots \\\\ v_{p} \\end{bmatrix} = \\begin{bmatrix}  \\sum_{j=1}^{q} a_{1j} v_j \\\\ \\sum_{j=1}^{q} a_{2j} v_j\\\\ \\vdots \\\\\n\\sum_{j=1}^{q} a_{pj} \\end{bmatrix}\\]",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#rappels-dalg√®bre-identit√©-et-inverse",
    "href": "Cours/ML_cours2.html#rappels-dalg√®bre-identit√©-et-inverse",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.5 Rappels d‚Äôalg√®bre : Identit√© et inverse",
    "text": "2.5 Rappels d‚Äôalg√®bre : Identit√© et inverse\n\n\n\n\n\n\n\nNoteRappel : matrice identit√©\n\n\n\nLa matrice identit√© \\(I_n\\) est la matrice carr√© √† \\(n\\) lignes et \\(n\\) colonnes, dont les coefficients diagonaux valent \\(1\\) et les autres valent \\(0\\).\n\\[I_n =  \\begin{bmatrix}\n1 & 0 & \\ldots & 0\\\\\n0 & 1 & \\ldots & 0\\\\\n\\vdots & \\vdots & & \\vdots \\\\\n0 & 0 & \\ldots & 1\n\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\n\n\nNoteRappel : Inverse d‚Äôune matrice\n\n\n\nSi \\(A = (a_{i,j})_{1\\leq i \\leq p, 1\\leq j \\leq p}\\) est une matrice carr√©e \\((p \\times p)\\) inversible, alors on note son inverse \\(A^{-1}\\) la matrice \\((p \\times p)\\) telle que\n\\[A\\,A^{-1} = A^{-1}\\,A = I_p \\]\n\n\n\n\n\n\n\n\n\nNoteRappel : Transpos√©e de l‚Äôinverse\n\n\n\nSi \\(A\\) est une matrice inversible, alors\n\\[(A^{-1})^t=(A^t)^{-1}\\]",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#vecteurs-al√©atoires",
    "href": "Cours/ML_cours2.html#vecteurs-al√©atoires",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.6 Vecteurs al√©atoires",
    "text": "2.6 Vecteurs al√©atoires\n\n\n\n\n\n\n\nNoteRappel : Vecteurs al√©atoires\n\n\n\nSoient \\(V_1,V_2,\\dots,V_n\\), \\(n\\) variables al√©atoires r√©elles, alors\n\\[V = \\begin{bmatrix} V_1 \\\\ V_2 \\\\ \\vdots \\\\ V_n \\end{bmatrix} \\]\n\n\n\n\n\n\n\n\n\n\nNoteRappel : Esp√©rance d‚Äôun vecteur al√©atoire\n\n\n\n\\(V\\) a pour esp√©rance\n\\[\\mathbb{E}[V] =  \\begin{bmatrix} \\mathbb{E}[V_1] \\\\ \\mathbb{E}[V_2] \\\\ \\vdots \\\\ \\mathbb{E}[V_n] \\end{bmatrix}\\]\n\n\n\n\n\n\n\n\n\nNoteRappel : Matrice de variance-covariance\n\n\n\n\\(V\\) a pour matrice de variance-covariance (sym√©trique)\n\\[\\mathbb{V}[V] = \\mathbb{E}\\left[\\left(V- \\mathbb{E}[V] \\right)\\left(V- \\mathbb{E}[V] \\right)^t \\right] =\\]\n\n\\[\\begin{bmatrix} \\mathbb{V}[V_1] & cov(V_1,V_2) & \\dots& Cov(V_1,V_n) \\\\\ncov(V_2,V_1) & \\mathbb{V}[V_2] & \\dots& Cov(V_2,V_n) \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n  cov(V_n,V_1) & cov(V_n,V_2) & \\dots&  \\mathbb{V}[V_n]\\end{bmatrix}\\]",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#propri√©t√©s",
    "href": "Cours/ML_cours2.html#propri√©t√©s",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.7 Propri√©t√©s",
    "text": "2.7 Propri√©t√©s\n\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\nSoient \\(\\color{blue}{A}\\) et \\(\\color{blue}{B}\\) des matrices √† coefficients non al√©atoires et soit \\(\\color{red}{V}\\) un vecteur al√©atoire, alors\n\\[\\begin{align}\n\\mathbb{E}[\\color{blue}{A}\\color{red}{V}\\color{blue}{B}] &= \\color{blue}{A} \\mathbb{E}[\\color{red}{V}]\\color{blue}{B}\\\\\n\\mathbb{V}[\\color{blue}{A}\\color{red}{V}] & = \\color{blue}{A} \\mathbb{V}[\\color{red}{V}] \\color{blue}{A^t}\n\\end{align}\\]\n\n\n\n\n\n\n\n\nNoteRappel : Vecteurs gaussiens\n\n\n\nSi \\(V_1, V_2, \\ldots, V_n\\) sont gaussiennes et ind√©pendantes, alors \\(V = [V_1, \\ldots, V_n]^t\\) est un vecteur gaussien.\nSi \\(V_1, V_2, \\ldots, V_n \\overset{i.i.d}\\sim \\mathcal{N}(0,\\sigma ^2)\\), alors\n\\[V \\sim \\mathcal{N}\\left(\\vec{0}_n,\\,\\sigma^2 I_n\\right)\\] o√π \\(I_n\\) est la matrice identit√© d‚Äôordre \\(n\\).",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#√©criture-matricielle-du-mod√®le-1",
    "href": "Cours/ML_cours2.html#√©criture-matricielle-du-mod√®le-1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.8 √âcriture matricielle du mod√®le",
    "text": "2.8 √âcriture matricielle du mod√®le\n\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\n\\[\\left\\{\\begin{matrix}\nY_1  =  \\beta\\ +\\ \\alpha_1\\,x_{1,1}\\ +\\ \\alpha_2\\,x_{2,1}\\ +\\\n\\ldots\\ +\\ \\alpha_{p}\\,x_{p, 1}\\ +\\ E_1\\\\\nY_2  =  \\beta\\ +\\ \\alpha_1\\,x_{1, 2}\\ +\\ \\alpha_2\\,x_{2,2}\\ +\\\n\\ldots\\ +\\ \\alpha_{p}\\,x_{p, 2}\\ +\\ E_2\\\\\n\\vdots   \\\\\nY_n  =  \\beta\\ +\\ \\alpha_1\\,x_{1,n}\\ +\\ \\alpha_2\\,x_{2, n}\\ +\\\n\\ldots\\ +\\ \\alpha_{p}\\,x_{p,n}\\ +\\ E_n \\end{matrix} \\right.\\]\npeut se r√©√©crire sous la forme\n\\[ Y = X \\theta + E \\]\navec\n\\[Y =\\begin{bmatrix} Y_1\\\\ Y_2\\\\ \\vdots \\\\ Y_n\\end{bmatrix},\\quad  X = \\begin{bmatrix}\n1 & x_{1,1} & \\ldots & x_{p, 1}\\\\\n1 & x_{1, 2} & \\ldots & x_{p, 2}\\\\\n\\vdots & \\vdots & & \\vdots \\\\\n1 & x_{1, n} & \\ldots & x_{p, n}\n\\end{bmatrix},\\quad \\theta = \\begin{bmatrix} \\beta\\\\ \\alpha_1\\\\\n\\alpha_2\\\\ \\vdots \\\\ \\alpha_{p}\\end{bmatrix},\\quad E = \\begin{bmatrix}E_1\\\\\nE_2\\\\ \\vdots \\\\ E_n\\end{bmatrix}\\]",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#√©criture-matricielle-du-mod√®le-2",
    "href": "Cours/ML_cours2.html#√©criture-matricielle-du-mod√®le-2",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.9 √âcriture matricielle du mod√®le",
    "text": "2.9 √âcriture matricielle du mod√®le\n\n\n\n\n\n\n\nTipPropri√©t√©\n\n\n\n\n\\(X\\) est de taille \\(n\\times (p+1)\\)\n\\(\\theta\\) est de dimension \\((p+1)\\times 1\\) : vecteur des param√®tres d‚Äôesp√©rance\n\\(E\\) est de dimension \\((n\\times 1)\\) : est un vecteur Gaussien tel que\n\n\\[E \\sim \\mathcal{N}\\left(\\vec{0}_n,\\,\\sigma^2 I_n\\right) \\]\n\n\\(Y\\) est de dimension \\((n\\times 1)\\) : est un vecteur Gaussien tel que\n\n\\[ Y \\sim \\mathcal{N}\\left(X\\theta,\\,\\sigma^2 I_n\\right)\\]\n\n\n\n\n\n\n\n\nCautionRemarques\n\n\n\nSi les vecteurs colonnes de \\(X\\) sont lin√©airement ind√©pendants, \\(X\\) est de rang \\(p+1\\) et \\(X^t X\\) est inversible.",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#exercice-√©crire-le-mod√®le-lin√©aire-univari√©-sous-forme-matricielle",
    "href": "Cours/ML_cours2.html#exercice-√©crire-le-mod√®le-lin√©aire-univari√©-sous-forme-matricielle",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.10 Exercice : √©crire le mod√®le lin√©aire univari√© sous forme matricielle",
    "text": "2.10 Exercice : √©crire le mod√®le lin√©aire univari√© sous forme matricielle",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#correction",
    "href": "Cours/ML_cours2.html#correction",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.11 Correction",
    "text": "2.11 Correction\nLe mod√®le de r√©gression simple \\[Y_i=\\alpha x_i+\\beta+E_i\\] s‚Äô√©crit matriciellement \\(Y=X\\theta+E\\) avec \\[Y = \\begin{bmatrix} Y_1\\\\ Y_2\\\\ \\vdots \\\\ Y_n\\end{bmatrix},\\quad\nX =  \\begin{bmatrix}\n1 & x_{1} \\\\\n1 & x_{2} \\\\\n\\vdots & \\\\\n1 & x_{n} \\\\\n\\end{bmatrix},\\quad\n\\theta\\ =\\  \\begin{bmatrix}\\beta\\\\ \\alpha\\end{bmatrix},\\quad\nE\\ =\\  \\begin{bmatrix} E_1\\\\\nE_2\\\\ \\vdots \\\\ E_n\\end{bmatrix}\\]",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#√©criture-du-mod√®le-lin√©aire-simple",
    "href": "Cours/ML_cours2.html#√©criture-du-mod√®le-lin√©aire-simple",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.12 √âcriture du mod√®le lin√©aire simple",
    "text": "2.12 √âcriture du mod√®le lin√©aire simple\n\n\n\n\n\n\n\nTipPropri√©t√©\n\n\n\n\n\\(X\\) est de taille \\((n\\times 2)\\)\n\\(\\theta\\) est de dimension \\((2 \\times 1)\\) : vecteur des param√®tres d‚Äôesp√©rance\n\\(E\\) est de dimension \\((n\\times 1)\\) : est un vecteur Gaussien tel que\n\n\\[E \\sim \\mathcal{N}\\left(\\vec{0}_n,\\,\\sigma^2 I_n\\right) \\]\n\n\\(Y\\) est de dimension \\((n\\times 1)\\) : est un vecteur Gaussien tel que\n\n\\[ Y \\sim \\mathcal{N}\\left(X\\theta,\\,\\sigma^2 I_n\\right)\\]\n\n\n\n\n\n\n\n\nCautionRemarques\n\n\n\nSi les \\(x_i\\) ne sont pas tous √©gaux, les deux vecteurs colonnes de \\(X\\) sont lin√©airement ind√©pendants et \\(X\\) est de rang \\(p = 2\\).",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#exemple-sur-les-poissons",
    "href": "Cours/ML_cours2.html#exemple-sur-les-poissons",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.13 Exemple sur les poissons",
    "text": "2.13 Exemple sur les poissons\n\n2.13.0.1 Notations\n\nOn a \\(n = 20\\) observations. On note, pour \\(1 \\leq i \\leq 20\\)\n\n\\(x_{1,i}\\) la mesure de la longueur du poisson \\(i\\).\n\\(x_{2,i}\\) la mesure de la largeure du poisson \\(i\\).\n\\(x_{3,i}\\) la mesure de l‚Äôepaisseur du poisson \\(i\\).\n\\(y_i\\) la mesure du poids du poisson \\(i\\).\n\n\n\n\n\n\n\nNoteD√©finition : Mod√®le de r√©gression lin√©aire multiple\n\n\n\nOn suppose que \\(y_i\\) est la r√©alisation d‚Äôune variable al√©atoire \\(Y_i\\) telle que: \\[Y_i = \\alpha_1 x_{1,i} + \\alpha_2 x_{2,i} + \\alpha_3 x_{3,i} + \\beta  + E_i,\\quad 1 \\leq i \\leq n\\]\n\n\\(\\alpha_1\\) (resp \\(\\alpha_2\\) , \\(\\alpha_3\\) ) est un param√®tre inconnu, l‚Äôeffet de la longueur (resp largeur, √©paisseur) sur le poids;\n\\(\\beta\\) est un param√®tre inconnu;\n\\(E_i\\) une variable al√©atoire, \\(E_i \\overset{i.i.d.}\\sim \\mathcal{N}(0, \\sigma^2)\\)\nLes \\(x_i\\) sont lin√©airement ind√©pendants",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#comment-√©crire-le-mod√®le",
    "href": "Cours/ML_cours2.html#comment-√©crire-le-mod√®le",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.14 Comment √©crire le mod√®le :",
    "text": "2.14 Comment √©crire le mod√®le :\n\\[\\left\\{\\begin{matrix}\nY_1  =  \\beta\\ +\\ \\alpha_1\\,x_{1,1}\\ +\\ \\alpha_2\\,x_{2,1}\\\n+\\ \\alpha_{3}\\,x_{3, 1}\\ +\\ E_1\\\\\nY_2  =  \\beta\\ +\\ \\alpha_1\\,x_{1, 2}\\ +\\ \\alpha_2\\,x_{2,2}\\ +\\\n\\alpha_{3}\\,x_{3, 2}\\ +\\ E_2\\\\\n\\vdots   \\\\\nY_n  =  \\beta\\ +\\ \\alpha_1\\,x_{1,n}\\ +\\ \\alpha_2\\,x_{2, n}\\ +\\\n\\alpha_{3}\\,x_{3,n}\\ +\\ E_n \\end{matrix} \\right.\\]\npeut se r√©√©crire sous la forme\n\\[ Y = X \\theta + E \\]\navec\n\\[Y =\\begin{bmatrix} Y_1\\\\ Y_2\\\\ \\vdots \\\\ Y_n\\end{bmatrix},\\quad  X = \\begin{bmatrix}\n1 & x_{1,1} & x_{2,1} & x_{3, 1}\\\\\n1 & x_{1, 2} & x_{2,1} & x_{3, 2}\\\\\n\\vdots & \\vdots & & \\vdots \\\\\n1 & x_{1, n} & x_{2,1} & x_{3, n}\n\\end{bmatrix},\\quad \\theta = \\begin{bmatrix} \\beta\\\\ \\alpha_1\\\\\n\\alpha_2\\\\ \\alpha_{3}\\end{bmatrix},\\quad E = \\begin{bmatrix}E_1\\\\\nE_2\\\\ \\vdots \\\\ E_n\\end{bmatrix}\\]",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#avec-les-donn√©es",
    "href": "Cours/ML_cours2.html#avec-les-donn√©es",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.15 Avec les donn√©es :",
    "text": "2.15 Avec les donn√©es :\n\\[X = \\]\n\n\n\nIntercept\nLength1\nHeight\nWidth\n\n\n\n\n1\n23.2\n11.5200\n4.0200\n\n\n1\n24.0\n12.4800\n4.3056\n\n\n1\n23.9\n12.3778\n4.6961\n\n\n1\n26.3\n12.7300\n4.4555\n\n\n1\n26.5\n12.4440\n5.1340\n\n\n1\n26.8\n13.6024\n4.9274\n\n\n1\n26.8\n14.1795\n5.2785\n\n\n1\n27.6\n12.6700\n4.6900\n\n\n1\n27.6\n14.0049\n4.8438\n\n\n1\n28.5\n14.2266\n4.9594",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#estimateurs-des-moindres-carr√©s",
    "href": "Cours/ML_cours2.html#estimateurs-des-moindres-carr√©s",
    "title": "Mod√®le lin√©aire multiple",
    "section": "3.1 Estimateurs des moindres carr√©s",
    "text": "3.1 Estimateurs des moindres carr√©s\n\n\n\n\n\n\nWarningObjectif\n\n\n\nOn note \\(\\theta= [\\beta,\\alpha_1,...,\\alpha_p]^t\\).\nComme dans la regression lin√©aire simple on cherche √† minimiser :\n\\[J(\\theta) = \\sum_{i = 1}^n \\left( y_i -(\\beta +  \\sum_{j=1}^p \\alpha _j x_{j,i}) \\right)^2\\] √âcriture matricielle ?",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#rappels-dalg√®bre-norme",
    "href": "Cours/ML_cours2.html#rappels-dalg√®bre-norme",
    "title": "Mod√®le lin√©aire multiple",
    "section": "3.2 Rappels d‚Äôalg√®bre : norme",
    "text": "3.2 Rappels d‚Äôalg√®bre : norme\n\n\n\n\n\n\n\nNoteRappel : norme\n\n\n\nSoit \\[V\\ =\\ \\begin{bmatrix} v_{1} \\\\ v_{2}\\\\ \\vdots \\\\ v_{n}\\end{bmatrix}\n\\ =\\ [v_1, \\ldots, v_n]^t\\] un vecteur de \\(\\mathbb{R}^n\\). On appelle norme de \\(V\\) le r√©el\n\\[\\displaystyle V^t V \\ =\\ \\sum_{i=1}^{n} v_i^2\\ =\\ ||V||^2 \\]\n\n\n\n\n\n\n\n\nCautionRemarque\n\n\n\n\\[V^t V \\neq V V^t\\]\n\\[V V^t = \\begin{bmatrix} v_1^2 & v_1\\,v_2 & \\ldots & v_1\\,v_n\\\\\nv_2\\,v_1 & v_2^2 & \\ldots & v_2\\,v_n\\\\\n\\vdots & \\vdots & & \\vdots \\\\\nv_n\\,v_1 & v_n\\,v_2 & \\ldots & v_n^2 \\end{bmatrix}\\]",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#estimateurs-des-moindres-carr√©s-1",
    "href": "Cours/ML_cours2.html#estimateurs-des-moindres-carr√©s-1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "3.3 Estimateurs des moindres carr√©s",
    "text": "3.3 Estimateurs des moindres carr√©s\n\n\n\n\n\n\n\nWarningObjectif\n\n\n\nOn souhaite trouver \\(\\theta= (\\beta,\\alpha_1,...\\alpha_p)^t\\) qui minimise\n\\[J(\\theta)=\\sum_{i = 1}^n \\left( y_i -(\\beta +  \\sum_{j=1}^p \\alpha _j x_{j,i}) \\right)^2 = (Y-X\\theta)^t(Y-X\\theta) = ||Y-X\\theta||^2\\]\n\n\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\nLe \\(\\theta\\) optimal est la solution du syst√®me de \\(p+1\\) √©quations √† \\(p+1\\) inconnues\n\\[\n\\left\\{\\begin{array}{ccc}\n\\frac{\\partial \\sum_{i = 1}^n \\left( y_i -(\\beta +  \\sum_{j=1}^p \\alpha _j x_{j,i}) \\right)^2 }{\\partial \\beta} & = & 0 \\\\\n%\n\\frac{\\partial \\sum_{i = 1}^n \\left( y_i -(\\beta +  \\sum_{j=1}^p \\alpha _j x_{j,i}) \\right)^2 }{\\partial \\alpha_1} & = & 0\\\\\n\\vdots & & \\\\\n\\frac{\\partial \\sum_{i = 1}^n \\left( y_i -(\\beta +  \\sum_{j=1}^p \\alpha _j x_{j,i}) \\right)^2 }{\\partial \\alpha_p} & = & 0\n\\end{array}\\right.\n\\]",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#√†-la-recherche-de-widehattheta",
    "href": "Cours/ML_cours2.html#√†-la-recherche-de-widehattheta",
    "title": "Mod√®le lin√©aire multiple",
    "section": "3.4 √Ä la recherche de \\(\\widehat{\\theta}\\)",
    "text": "3.4 √Ä la recherche de \\(\\widehat{\\theta}\\)\n\\[\\widehat{\\theta} = \\underset{\\theta\\in\\mathbb{R}^{p+1}}{argmin} (Y-X\\theta)^t(Y-X\\theta) =\\underset{\\theta\\in\\mathbb{R}^{p+1}}{argmin} ||Y-X\\theta||^2\\]\n\\(\\widehat{\\theta} = [B,A_1, \\dots, A_p]^t\\) o√π \\(B\\) est l‚Äôestimateur de \\(\\beta\\) et \\(A_j\\) l‚Äôestimateur de \\(\\alpha_j\\)\n\\[\\begin{align}\n(Y-X\\theta)^t(Y-X\\theta) &= (Y^t-\\theta^tX^t)(Y-X\\theta)\\\\\n&= Y^tY - Y^tX\\theta  -\\theta^tX^t Y -\\theta^tX^tX\\theta \\\\\n&= Y^tY - 2 Y^tX\\theta -\\theta^tX^tX\\theta\n\\end{align}\\]\nEn d√©rivant par rapport √† \\(\\theta\\) on obtient : \\[-2Y^tX + 2\\theta^tX^tX \\] Le syst√®me \\(-2Y^tX + 2\\theta^tX^tX=0\\) est bien le m√™me que les \\(p+1\\) equations de la slide pr√©c√©dente",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#√†-la-recherche-de-widehattheta-1",
    "href": "Cours/ML_cours2.html#√†-la-recherche-de-widehattheta-1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "3.5 √Ä la recherche de \\(\\widehat{\\theta}\\)",
    "text": "3.5 √Ä la recherche de \\(\\widehat{\\theta}\\)\n\\[\\begin{align}\n-2Y^tX + 2\\widehat{\\theta}^tX^tX = 0 &\\iff \\widehat{\\theta}^tX^tX  =  Y^tX  \\\\\n\\iff X^tX  \\widehat{\\theta}   =  X^tY   & \\iff \\widehat{\\theta} = (X^tX)^{-1}  X^tY\n\\end{align}\\]\n\n\n\n\n\n\nCautionRemarques\n\n\n\n\\(X\\) est de rang \\(p+1\\) donc \\(X^tX\\) est inversible.\n\n\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\n\\[\\widehat{\\theta} =\\underset{\\theta\\in\\mathbb{R}^{p+1}}{argmin} ||Y-X\\theta||^2\\] a pour solution\n\\[\\widehat{\\theta} = (X^tX)^{-1}  X^tY\\]",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#estimateurs-des-param√®tres-desp√©rance",
    "href": "Cours/ML_cours2.html#estimateurs-des-param√®tres-desp√©rance",
    "title": "Mod√®le lin√©aire multiple",
    "section": "3.6 Estimateurs des param√®tres d‚Äôesp√©rance",
    "text": "3.6 Estimateurs des param√®tres d‚Äôesp√©rance\n\n\n\n\n\n\n\nWarningObjectif : Estimateur des moindres carr√©s de \\(\\theta\\)\n\n\n\n\\[\\widehat{\\theta}  =\\underset{\\theta\\in\\mathbb{R}^{p+1}}{argmin} ||Y-X\\theta||^2\\]\n\n\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\n\nSi \\(\\hat{\\theta}= [B, A_1, \\ldots, A_{p}]^t\\) est solution du syst√®me et que \\((X^t\\,X)\\) est inversible, alors\n\n\\[\\hat{\\theta}=(X^t\\,X)^{-1}\\,X^t\\,Y\\]\n\n\n\n\n\n\n\n\nParam√®tres\nEstimateurs\nEstimations\n\n\n\n\n\\([\\beta,\\alpha_1,...\\alpha_p]\\)\n\\([B, A_1, \\ldots, A_{p}]\\)\n\\([b,a_1,\\cdots,a_p]\\)",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#les-4-graphiques",
    "href": "Cours/ML_cours2.html#les-4-graphiques",
    "title": "Mod√®le lin√©aire multiple",
    "section": "4.1 Les 4 graphiques",
    "text": "4.1 Les 4 graphiques\n\nfish &lt;- read.table(file = \"Fish.csv\",\n                   sep =\",\", header = TRUE) %&gt;% filter(Species == \"Bream\") \n\n\nmod &lt;- lm(Weight ~Length1 + Height + Width , data =  fish)\npar(mfrow=c(2,2))\nplot(mod)",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#multicolin√©arit√©-des-x_i",
    "href": "Cours/ML_cours2.html#multicolin√©arit√©-des-x_i",
    "title": "Mod√®le lin√©aire multiple",
    "section": "4.2 Multicolin√©arit√© des \\(x_i\\)",
    "text": "4.2 Multicolin√©arit√© des \\(x_i\\)\nOn v√©rifie la corr√©lation entre les \\(x_i\\)\n\nlibrary(corrplot)\n\ncorrplot 0.95 loaded\n\nM = cor(fish[c(\"Length1\",\"Height\",\"Width\",\"Weight\")])\ncorrplot.mixed(M)",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#v√©rification-avec-le-vif",
    "href": "Cours/ML_cours2.html#v√©rification-avec-le-vif",
    "title": "Mod√®le lin√©aire multiple",
    "section": "4.3 V√©rification avec le VIF",
    "text": "4.3 V√©rification avec le VIF\n\n\n\n\n\n\nNoteD√©finition : VIF\n\n\n\n\\[\n  VIF(x_i) = \\frac{1}{1-R^2(x_i)}\n\\] o√π \\(R^2(x_i)\\) est le \\(R^2\\) du mod√®le lin√©aire dans lequel on explique \\(x_i\\) par toutes les autres covariables (\\(x_j\\))",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#exemple-du-vif-sur-les-poissons",
    "href": "Cours/ML_cours2.html#exemple-du-vif-sur-les-poissons",
    "title": "Mod√®le lin√©aire multiple",
    "section": "4.4 Exemple du VIF sur les poissons :",
    "text": "4.4 Exemple du VIF sur les poissons :\nCalcul ‚Äò√† la main‚Äô\n\nmod_length&lt;- lm(Length1 ~ Height + Width , data =  fish)\nvif_length &lt;- 1/ ( 1-summary(mod_length)$r.squared)\n\nAvec la fonction VIF :\n\nlibrary(car)\n\nLe chargement a n√©cessit√© le package : carData\n\n\n\nAttachement du package : 'car'\n\n\nL'objet suivant est masqu√© depuis 'package:dplyr':\n\n    recode\n\n\nL'objet suivant est masqu√© depuis 'package:purrr':\n\n    some\n\nvif(mod)\n\n  Length1    Height     Width \n 8.952978 12.123683  7.451746 \n\n\nEn pratique : on retire les covariales qui ont un VIF sup√©rieur √† 10 (ou 5 si on veut √™tre plus strict)",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#estimations-des-param√®tres-sur-notre-exemple",
    "href": "Cours/ML_cours2.html#estimations-des-param√®tres-sur-notre-exemple",
    "title": "Mod√®le lin√©aire multiple",
    "section": "4.5 Estimations des param√®tres sur notre exemple :",
    "text": "4.5 Estimations des param√®tres sur notre exemple :\n\nfish &lt;- read.table(file = \"Fish.csv\",\n                   sep =\",\", header = TRUE) %&gt;% filter(Species == \"Bream\") %&gt;% \n  slice(1:20)\n\n\nmod &lt;- lm(Weight ~Length1 + Height + Width , data =  fish)\nsummary(mod)\n\n\nCall:\nlm(formula = Weight ~ Length1 + Height + Width, data = fish)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-183.872  -17.044   -0.495   24.591  101.032 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1048.57     187.86  -5.582 4.13e-05 ***\nLength1        18.96      13.26   1.430    0.172    \nHeight         48.50      28.31   1.713    0.106    \nWidth          66.72      51.73   1.290    0.215    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 63.03 on 16 degrees of freedom\nMultiple R-squared:  0.808, Adjusted R-squared:  0.772 \nF-statistic: 22.44 on 3 and 16 DF,  p-value: 5.624e-06",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#sur-notre-exemple-sans-la-fonction-lm",
    "href": "Cours/ML_cours2.html#sur-notre-exemple-sans-la-fonction-lm",
    "title": "Mod√®le lin√©aire multiple",
    "section": "4.6 Sur notre exemple (sans la fonction lm)",
    "text": "4.6 Sur notre exemple (sans la fonction lm)\n\nOn r√©cup√®re les matrices X et Y :\n\n\nX1 &lt;- fish[, c(\"Length1\",  \"Height\",  \"Width\")] %&gt;% \n  as.matrix() \nX &lt;- cbind(Intercept = 1,X1)\nY &lt;- fish[,\"Weight\"] %&gt;% \n  as.matrix()",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#sur-notre-exemple-sans-la-fonction-lm-1",
    "href": "Cours/ML_cours2.html#sur-notre-exemple-sans-la-fonction-lm-1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "4.7 Sur notre exemple (sans la fonction lm)",
    "text": "4.7 Sur notre exemple (sans la fonction lm)\n\nOn cherche maintenant \\(\\widehat{\\theta}=(X^t\\,X)^{-1}\\,X^t\\,Y\\).\n\nLe produit matriciel \\(AB\\) s‚Äôobtient en faisant A %*% B, La transpos√©e d‚Äôune matrice A s‚Äôobtient avec la fonction t(A) et son inverse avec la fonction solve(A).\n\n\\(X^t\\,X\\) s‚Äôobtient donc :\n\n\nt(X) %*% X\n\n\n\\((X^t\\,X)^{-1}\\) s‚Äôobtient donc :\n\n\nsolve(t(X) %*% X)\n\nOn a finalement \\(\\widehat{\\theta}\\) :\n\nsolve(t(X) %*% X)%*% t(X)%*% Y",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#on-retrouve-bien-les-m√™mes-valeurs",
    "href": "Cours/ML_cours2.html#on-retrouve-bien-les-m√™mes-valeurs",
    "title": "Mod√®le lin√©aire multiple",
    "section": "4.8 On retrouve bien les m√™mes valeurs",
    "text": "4.8 On retrouve bien les m√™mes valeurs\n\ncoefficients(mod)\n\n(Intercept)     Length1      Height       Width \n-1048.57013    18.95867    48.49646    66.71559 \n\n\n\nsolve(t(X) %*% X)%*% t(X)%*% Y\n\n                 [,1]\nIntercept -1048.57013\nLength1      18.95867\nHeight       48.49646\nWidth        66.71559",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#dans-le-mod√®le-lin√©aire-simple",
    "href": "Cours/ML_cours2.html#dans-le-mod√®le-lin√©aire-simple",
    "title": "Mod√®le lin√©aire multiple",
    "section": "5.1 Dans le mod√®le lin√©aire simple",
    "text": "5.1 Dans le mod√®le lin√©aire simple\n\n\n\n\n\n\nNoteRappel\n\n\n\nDans le mod√®le \\(M_2\\) : \\(\\forall i \\in \\{1, \\dots, n\\} \\;\\;\\) \\[ Y_i =\\beta + \\alpha x_i  + E_i,\\quad  E_i \\overset{i.i.d.}{\\sim}\\mathcal{N}(0, \\sigma^2)\\]\nL‚Äôestimateur de la variance r√©siduelle √©tait :\n\\[\nS^2 = \\frac{1}{n-2}\\sum_{i=1}^n(Y_i-\\widehat{Y_i})^2=\\frac{1}{n-2}\\sum_{i=1}^n(Y_i-Ax_i-B)^2= \\frac{SCR(M_2)}{n-2},\n\\]\no√π \\(\\widehat{Y_i}=Ax_i+B\\), la pr√©vision (al√©atoire) par le mod√®le de r√©gression lin√©aire associ√©e √† \\(x_i\\).",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#le-param√®tre-de-variance-r√©siduelle",
    "href": "Cours/ML_cours2.html#le-param√®tre-de-variance-r√©siduelle",
    "title": "Mod√®le lin√©aire multiple",
    "section": "5.2 Le param√®tre de variance r√©siduelle",
    "text": "5.2 Le param√®tre de variance r√©siduelle\n\n\n\n\n\n\nWarningObjectif\n\n\n\nDans le mod√®le \\(M_{p+1}\\):\n\\(\\forall i \\in \\{1, \\dots, n\\} \\;\\;\\) \\[ Y_i =\\beta +  \\sum_{j=1}^p\\alpha_j x_{j,i}   + E_i,  \\quad E_i \\overset{i.i.d.}{\\sim}\\mathcal{N}(0, \\sigma^2)\\]\nil y‚Äôa un param√®tre de variance \\(\\sigma ^2\\) : la variance residuelle.\nQuel est son estimateur ?",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#estimation-de-la-variance-residuelle-du-mod√®le",
    "href": "Cours/ML_cours2.html#estimation-de-la-variance-residuelle-du-mod√®le",
    "title": "Mod√®le lin√©aire multiple",
    "section": "5.3 Estimation de la variance residuelle du mod√®le",
    "text": "5.3 Estimation de la variance residuelle du mod√®le\n\n\n\n\n\n\n\n\nNoteD√©finition : Pr√©vision al√©atoire par le mod√®le \\(M_{p+1}\\)\n\n\n\n\\[\\widehat{Y_i}=B+A_1x_{i,1}+\\cdots+A_px_{i,p}=B+\\sum_{j=1}^p A_jx_{i,j}\\]\n\n\n\n\n\n\n\n\nNoteD√©finition : R√©sidus al√©atoires du mod√®le \\(M_{p+1}\\)\n\n\n\n\\[E_i=Y_i-\\widehat{Y_i}\\]\n\n\n\n\n\n\n\n\nNoteD√©finition : Somme des carr√©s r√©siduels\n\n\n\n\\[SCR(M_{p+1})=\\sum_{i=1}^n E_i^2=\\sum_{i=1}^n\\left(Y_i-(B+A_1x_{i,1}+\\cdots+A_px_{i,p})\\right)^2\\]",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/ML_cours2.html#dun-point-de-vue-matriciel",
    "href": "Cours/ML_cours2.html#dun-point-de-vue-matriciel",
    "title": "Mod√®le lin√©aire multiple",
    "section": "5.4 D‚Äôun point de vue matriciel :",
    "text": "5.4 D‚Äôun point de vue matriciel :\n\nVecteur (al√©atoire) des pr√©visions \\[\\widehat{Y}\\ =\\ \\pa{\\begin{array}{c} \\widehat{Y_1}\\\\\n\\widehat{Y_2}\\\\ \\vdots \\\\ \\widehat{Y_n}\\end{array}}=\\ \\pa{\\begin{array}{c} B+\\sum_{j=1}^p A_jx_{1,j}\\\\\nB+\\sum_{j=1}^p A_jx_{2,j}\\\\ \\vdots \\\\ B+\\sum_{j=1}^p A_jx_{n,j}\\end{array}}=X\\hat{\\theta}\\]\nVecteur (al√©atoire) des r√©sidus \\[E\\ =\\ \\pa{\\begin{array}{c} E_1\\\\\nE_2\\\\ \\vdots \\\\ E_n\\end{array}}=\\ \\pa{\\begin{array}{c} Y_1-\\widehat{Y_1}\\\\\nY_2-\\widehat{Y_2}\\\\ \\vdots \\\\ Y_n-\\widehat{Y_n}\\end{array}}=Y-X\\hat{\\theta}\\]\nSomme des carr√©s r√©siduels \\[SCR(M_{p+1})=\\sum_{i=1}^n E_i^2=\\norm{E}^2=\\norm{Y-X\\hat{\\theta}}^2\\]",
    "crumbs": [
      "Cours",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours.html",
    "href": "Cours.html",
    "title": "Cours",
    "section": "",
    "text": "Les cours de l‚Äôann√©e 2025-2026 sont disponibles sur cette page.",
    "crumbs": [
      "Cours"
    ]
  },
  {
    "objectID": "Cours/ML_cours1.html",
    "href": "Cours/ML_cours1.html",
    "title": "ML_cours1",
    "section": "",
    "text": "![](cours1.html){width=\"100%\"}",
    "crumbs": [
      "Cours",
      "ML_cours1"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "",
    "text": "AC22.01 | Prendre conscience de la diff√©rence entre mod√©lisation statistique et analyse exploratoire\nAC22.03 | Comprendre l‚Äôint√©r√™t des analyses multivari√©es pour synth√©tiser et r√©sumer l‚Äôinformation port√©e par plusieurs variables\nAC22.05 | Appr√©cier les limites de validit√© et les conditions d‚Äôapplication d‚Äôune analyse\nAC24.03EMS | Comprendre l‚Äôimpact du type de donn√©es sur le choix de la mod√©lisation √† mettre en ≈ìuvre\nAC24.04EMS | Appr√©cier les limites de validit√© et les conditions d‚Äôapplication d‚Äôun mod√®le\nAC24.05EMS | R√©aliser l‚Äôimportance de la mise en oeuvre d‚Äôune proc√©dure de test statistique pour valider ou non une hypoth√®se\n\n\n\n\n\nI Mod√®le linaire simple\nII Mod√®le lin√©aire multiple\nIII S√©lection de variables\nIV ANOVA",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#apprentissage-critique",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#apprentissage-critique",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "",
    "text": "AC22.01 | Prendre conscience de la diff√©rence entre mod√©lisation statistique et analyse exploratoire\nAC22.03 | Comprendre l‚Äôint√©r√™t des analyses multivari√©es pour synth√©tiser et r√©sumer l‚Äôinformation port√©e par plusieurs variables\nAC22.05 | Appr√©cier les limites de validit√© et les conditions d‚Äôapplication d‚Äôune analyse\nAC24.03EMS | Comprendre l‚Äôimpact du type de donn√©es sur le choix de la mod√©lisation √† mettre en ≈ìuvre\nAC24.04EMS | Appr√©cier les limites de validit√© et les conditions d‚Äôapplication d‚Äôun mod√®le\nAC24.05EMS | R√©aliser l‚Äôimportance de la mise en oeuvre d‚Äôune proc√©dure de test statistique pour valider ou non une hypoth√®se",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#plan-du-cours",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#plan-du-cours",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "",
    "text": "I Mod√®le linaire simple\nII Mod√®le lin√©aire multiple\nIII S√©lection de variables\nIV ANOVA",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#probl√©matique-biologique",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#probl√©matique-biologique",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "2.1 Probl√©matique biologique",
    "text": "2.1 Probl√©matique biologique\nDonn√©es : On a pour 20 br√®mes p√©ch√©es dans le lac Laengelmavesi en Finland leurs poids (en gramme) et leurs tailles (en cm).\nPour \\(i \\in 1,\\dots, n\\) :\n\n\\(y_i\\) est le poids du poisson \\(i\\) (en grammes)\n\\(x_i\\) la longueur du poisson \\(i\\) (en cm).\n\n\n\n\n\n\nEspeces\nPoids\nLongueur\n\n\n\n\nP1\n242\n23.2\n\n\nP2\n290\n24.0\n\n\nP3\n340\n23.9\n\n\nP4\n363\n26.3\n\n\nP5\n430\n26.5",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#repr√©sentation",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#repr√©sentation",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "2.2 Repr√©sentation",
    "text": "2.2 Repr√©sentation\n\n\n\n\n\n\n\n\n\nQuestions\n\nExpliquer le poids des poissons en fonctions de leurs tailles ?\nY‚Äôa-t-il une relation lin√©aire entre les deux ?",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#trouver-la-meilleure-droite",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#trouver-la-meilleure-droite",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "2.3 Trouver ‚Äúla meilleure droite‚Äù ?",
    "text": "2.3 Trouver ‚Äúla meilleure droite‚Äù ?\n\n\n\n\n\n\n\n\n\n\\[\\begin{align}J(a,b) &=\\sum_{i=1}^n e_i ^2\\\\\n&=\\sum_{i=1}^n (y_i - \\widehat{y_i})^2\\\\\n&= \\sum_{i=1}^n (y_i - (ax_i + b))^2\n\\end{align}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#m√©thode-des-moindres-carr√©s",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#m√©thode-des-moindres-carr√©s",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "2.4 M√©thode des moindres carr√©s",
    "text": "2.4 M√©thode des moindres carr√©s\n\n\n\n\n\n\nNoteD√©finition\n\n\n\n\n√âquation de la droite des moindres carr√©s :\n\n\\[\\widehat{y}_i = ax_i+b\\]\n\n\\(a\\) et \\(b\\) sont obtenus en minimisant la somme des carr√©s des erreurs :\n\n\\[J(a,b)=\\sum_{i=1}^{n} \\left(y_i-(ax_i+b)\\right)^2\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#droite-des-moindres-carr√©s-et-erreurs",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#droite-des-moindres-carr√©s-et-erreurs",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "2.5 Droite des moindres carr√©s et erreurs",
    "text": "2.5 Droite des moindres carr√©s et erreurs\n\n\n\n\n\n\n\n\n\n\\[J(a,b)=91435.22\\]\n\n\n\n\n\n\nWarningObjectif\n\n\n\nAvec notre √©chantillon de \\(n\\) observations, quelle confiance donner √† l‚Äôestimation des coefficients \\(a\\) et \\(b\\) ?",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#ce-quil-faut-retenir-de-ce-cours",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#ce-quil-faut-retenir-de-ce-cours",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "2.6 Ce qu‚Äôil faut retenir de ce cours",
    "text": "2.6 Ce qu‚Äôil faut retenir de ce cours\n\n\n\n\n\n\n\nNoteMod√©lisation probabiliste du mod√®le lin√©aire\n\n\n\n\\(y_i\\) est la r√©alisation d‚Äôune variable al√©atoire \\(Y_i\\) telle que pour \\(1 \\leq i \\leq n\\): \\[Y_i = \\alpha x_i + \\beta  + E_i, \\quad E_i\\overset{i.i.d.}\\sim{\\cal N}(0,\\sigma^2) \\]\n\n\n\n\n\n\n\n\nTipEstimateurs du mod√®le\n\n\n\n\\[{A}=\\frac{\\sum_{i=1}^n(x_i-\\bar{x})(Y_i-\\bar{Y})}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\] \\[{B}=\\bar{Y}-A\\bar{x}\\] \\[S^2=\\frac{1}{n-2}\\sum_{i=1}^n(Y_i-\\widehat{Y_i})^2\\]\n\n\n\n\n\n\n\n\nTipValider les hypoth√®ses du mod√®le avec les 4 graphes de diagnostic",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#donn√©es",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#donn√©es",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "3.1 Donn√©es",
    "text": "3.1 Donn√©es\nOn a \\(n = 20\\) observations.\nPour \\(1 \\leq i \\leq n\\):\n\n\\(x_i\\) : longueur du poisson \\(i\\).\n\\(y_i\\) : poids du poisson \\(i\\).\n\n\nfish &lt;- read.table(file = \"fish_linsimple.csv\",\n                   sep =\";\", header = TRUE)\nkable(fish[1:5,])\n\n\n\n\nPoids\nLongueur\n\n\n\n\n242\n23.2\n\n\n290\n24.0\n\n\n340\n23.9\n\n\n363\n26.3\n\n\n430\n26.5\n\n\n\n\n\n\nsummary(fish)\n\n     Poids          Longueur    \n Min.   :242.0   Min.   :23.20  \n 1st Qu.:383.2   1st Qu.:26.73  \n Median :487.5   Median :28.45  \n Mean   :481.5   Mean   :27.92  \n 3rd Qu.:600.0   3rd Qu.:29.43  \n Max.   :700.0   Max.   :31.00  \n\n\n\nggplot(fish, aes(x = Longueur, y = Poids)) +\n  geom_point()",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#√©criture-du-mod√®le",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#√©criture-du-mod√®le",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "3.2 √âcriture du mod√®le",
    "text": "3.2 √âcriture du mod√®le\n\n3.2.0.1 Notations\n\nOn a \\(n=20\\) observations. On note, pour \\(1 \\leq i \\leq n\\)\n\n\\(x_i\\) la mesure de la longueur du poisson \\(i\\).\n\\(y_i\\) la mesure du poids du poisson \\(i\\).\n\n\n\n\n\n\n\nNoteD√©finition : Mod√®le de r√©gression lin√©aire simple\n\n\n\nOn suppose que \\(y_i\\) est la r√©alisation d‚Äôune variable al√©atoire \\(Y_i\\) telle que pour \\(1 \\leq i \\leq n\\): \\[Y_i = \\alpha x_i + \\beta  + E_i\\] o√π\n\n\\(\\alpha\\) est un param√®tre inconnu;\n\\(\\beta\\) est un param√®tre inconnu;\n\\(E_i\\) une variable al√©atoire appel√©e erreur r√©siduelle.\n\n\n\n\nDans notre exemple, \\(\\alpha\\) est l‚Äôeffet de la longueur sur le poids.",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#mod√©lisation-de-lerreur-r√©siduelle",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#mod√©lisation-de-lerreur-r√©siduelle",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "3.3 Mod√©lisation de l‚Äôerreur r√©siduelle",
    "text": "3.3 Mod√©lisation de l‚Äôerreur r√©siduelle\n\n\n\n\n\n\nNoteD√©finition : Mod√®le de r√©gression lin√©aire simple\n\n\n\n\\(E_i\\) une variable al√©atoire appel√©e erreur r√©siduelle , telle que:\n\nToutes les variables al√©atoires \\(E_1,\\dots, E_n\\) sont ind√©pendantes;\nTous les \\(E_i\\) ont la m√™me esp√©rance, √©gale √† 0;\nTous les \\(E_i\\) ont la m√™me variance, √©gale √† \\(\\mathbf{\\sigma^2}\\) (param√®tre inconnu);\nTous les \\(E_i\\) suivent une loi normale;\n\n\\(\\Rightarrow\\) les \\(E_i\\) sont ind√©pendants et identiquement distribu√©s de loi \\(\\mathcal{N}(0, \\sigma^2)\\)\n\nOn notera directement \\(E_i\\overset{i.i.d.}\\sim{\\cal N}(0,\\sigma^2)\\)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#al√©atoire-ou-pas",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#al√©atoire-ou-pas",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "3.4 Al√©atoire ou pas ?",
    "text": "3.4 Al√©atoire ou pas ?\n\n\n\n\n\n\nCautionRemarques\n\n\n\n\\[\\color{red}{Y_i} = {\\color{blue}{\\underbrace{\\alpha x_i + \\beta}_{{d√©terministe}{}}}}  + \\color{red}{\\overbrace{E_i}^{al√©atoire}}\\color{black}, 1 \\leq i \\leq n \\]\no√π\n\n\\(\\color{red}{Y_i}\\) r√©ponse al√©atoire pour l‚Äôunit√© \\(i\\)\n\\(\\color{blue}{x_i}\\) valeur non-al√©atoire de \\(x\\) pour l‚Äôunit√© \\(i\\)\n\\(\\color{blue}\\alpha\\) est un param√®tre inconnu, l‚Äôeffet de la longueur sur le poids;\n\\(\\color{blue}\\beta\\) est un param√®tre inconnu;\n\\(\\color{red}{E_i}\\) une variable al√©atoire appel√©e erreur r√©siduelle les \\(\\color{red}{E_i}\\) sont ind√©pendants et identiquement distribu√©s de loi \\(\\mathcal{N}(0, \\sigma^2)\\)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#autre-formulation-du-mod√®le-lin√©aire",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#autre-formulation-du-mod√®le-lin√©aire",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "3.5 Autre formulation du mod√®le lin√©aire",
    "text": "3.5 Autre formulation du mod√®le lin√©aire\n\n\n\n\n\n\nCautionRemarques\n\n\n\nLe mod√®le\n\\[Y_i = \\alpha x_i + \\beta  + E_i,\\quad 1 \\leq i \\leq n,\\]\n\\[\\text{avec } E_i\\overset{i.i.d.}\\sim \\mathcal{N}(0,\\sigma^2)\\]\nest √©quivalent √†\nLes \\(Y_i\\) sont ind√©pendants et\n\\[Y_i \\sim \\mathcal{N}( \\alpha x_i +\\beta, \\sigma^2 ), \\; 1 \\leq i \\leq n\\]\n\n\\(\\mathbb{E}[Y_i]=\\) \\(\\alpha x_i + \\beta\\) , \\(\\mathbb{V}[Y_i]=\\) \\(\\sigma^2\\)\n\\(x\\) n‚Äôinflue que sur la moyenne et pas sur la variance de \\(Y\\)\n\\(Y_i\\) se d√©compose en\n\nUne partie fixe expliqu√©e par le mod√®le:\nUne partie al√©atoire non expliqu√©e par le mod√®le",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#exemple-de-mod√©lisation-lin√©aire-simple",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#exemple-de-mod√©lisation-lin√©aire-simple",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "3.6 Exemple de mod√©lisation lin√©aire simple",
    "text": "3.6 Exemple de mod√©lisation lin√©aire simple\nOn a \\(n=20\\) observations. On note, pour \\(1 \\leq i \\leq n\\)\n\n\\(x_i\\) la mesure de la longueur du poisson \\(i\\).\n\\(y_i\\) la mesure du poids du poisson \\(i\\).\n\nOn suppose que \\(y_i\\) est la r√©alisation d‚Äôune v. a. \\(Y_i\\) telle que pour \\(1 \\leq i \\leq n\\): \\[Y_i = \\alpha x_i + \\beta  + E_i \\quad \\text{avec} \\quad E_i\\overset{i.i.d.}\\sim{\\cal N}(0,\\sigma^2)\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#rappel-covariance-et-corr√©lation",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#rappel-covariance-et-corr√©lation",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "4.1 Rappel : covariance et corr√©lation",
    "text": "4.1 Rappel : covariance et corr√©lation\n\n\n\n\n\n\nNoteRappel\n\n\n\n\n\\[\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i\\quad, \\quad \\bar{y}\\ =\\ \\frac{1}{n}\\sum_{i=1}^{n} y_i\\] \\[\\mathbb{V}_{emp}(x) = \\frac{1}{n}\\sum_{i=1}^{n}(x_i-\\bar{x})^2\\quad \\text{ (estimateur biais√©)}\\]\n\\[Cov_{emp}(x,y)= \\frac{1}{n}\\sum_{i=1}^{n}(x_i-\\bar{x})(y_i-\\bar{y}) \\] \\[\\begin{align}\nr(x,y) &= \\frac{\\displaystyle\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\displaystyle\\sum_{i=1}^n(x_i-\\bar{x})^2}\\sqrt{\\displaystyle \\sum_{i=1}^n(y_i-\\bar{y})^2}} \\\\\n& = \\frac{Cov_{emp}(x,y)}{\\sqrt{\\mathbb{V}_{emp}(x)}\\sqrt{\\mathbb{V}_{emp}(y)}}\n\\end{align}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#questions",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#questions",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "4.2 Questions",
    "text": "4.2 Questions\n\n\n\n\n\n\nNoteRappel\n\n\n\n\nQuelle est la moyenne empirique de \\(x\\) ? de \\(y\\) ?\nQuelle est la valeur du coefficient de correlation ? -2, -0.5 , 0, 0.3 , 0.8 ou 5 ?",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#questions-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#questions-1",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "4.3 Questions",
    "text": "4.3 Questions\n\n\n\n\n\n\nNoteRappel\n\n\n\n\nQuelle est la valeur du coefficients de correlation de \\(X\\) avec \\(X\\) ?\nQuelle est la valeur du coefficients de correlation de \\(X\\) avec \\(2X\\) ?\nQuelle est la valeur du coefficients de correlation de \\(X\\) avec \\(2X + 3\\) ?\nQuelle est la valeur du coefficients de correlation de \\(X\\) avec \\(-X\\) ?",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#m√©thode-des-moindres-carr√©s-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#m√©thode-des-moindres-carr√©s-1",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "4.4 M√©thode des moindres carr√©s",
    "text": "4.4 M√©thode des moindres carr√©s\n\n\n\n\n\n\nNoteD√©finition\n\n\n\n\n√âquation de la droite des moindres carr√©s :\n\n\\[\\widehat{y}_i = ax_i+b\\]\n\n\\(a\\) et \\(b\\) obtenus en minimisant la somme des carr√©s des erreurs\n\n\\[J(a,b)=\\sum_{i=1}^{n} \\left(y_i-(ax_i+b)\\right)^2\\]\n\n\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\n\nLa minimisation de \\(J(a,b)\\) en \\(a\\) et \\(b\\) conduit √†\n\nExercice :\n\\(a =\\) \\(\\frac{\\displaystyle\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\displaystyle\\sum_{i=1}^n(x_i-\\bar{x})^2}= \\frac{Cov_{emp}(x,y)}{\\mathbb{V}_{emp}(x)}\\) et\n\\(b\\) = \\(\\bar{y} - a\\bar{x}\\)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#estimateurs-des-param√®tres-du-mod√®le",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#estimateurs-des-param√®tres-du-mod√®le",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "4.5 Estimateurs des param√®tres du mod√®le :",
    "text": "4.5 Estimateurs des param√®tres du mod√®le :\n\n\n\n\n\n\n\nNoteD√©finition\n\n\n\n\nA et B estimateurs de \\(\\alpha\\) et \\(\\beta\\) obtenus par la m√©thode des moindres carr√©.\n\n\\[\\begin{align}\n\\color{red}{A}&=\\frac{\\sum_{i=1}^n(x_i-\\bar{x})(Y_i-\\bar{Y})}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\\\ \\color{red}{A}&=\\frac{\\sum_{i=1}^n(x_iY_i)-n\\bar{x}\\bar{Y}}{\\sum_{i=1}^n x_i^2-n(\\bar{x})^2}\\\\\n\\color{red}{B}&=\\bar{Y}-A\\bar{x}\n\\end{align}\\]\n\n\\(a\\) et \\(b\\) estimations de \\(\\alpha\\) et \\(\\beta\\) : r√©alisations \\(a\\) et \\(b\\) des estimateurs \\(A\\) et \\(B\\) sur les donn√©es\n\n\\[ \\begin{align}\n\\color{blue}{a}&=\\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\\\ \\color{blue}{a}&=\\frac{\\sum_{i=1}^n(x_iy_i)-n\\bar{x}\\bar{y}}{\\sum_{i=1}^n x_i^2-n(\\bar{x})^2}\\\\\n\\color{blue}{b}&=\\bar{y}-a\\bar{x}\n\\end{align}\\]\n\n\\(a\\) et \\(b\\) sont les coefficients de la droite des moindres carr√©s.",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#mod√®le-lin√©aire-avec-r",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#mod√®le-lin√©aire-avec-r",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "4.6 Mod√®le lin√©aire avec R",
    "text": "4.6 Mod√®le lin√©aire avec R\n\nmodele_reg_simple &lt;- lm(Poids~ Longueur, data = fish)\ncoef(modele_reg_simple)\n\n(Intercept)    Longueur \n -876.48191    48.63832 \n\n\n\\(a =\\) 48.6383206 et \\(b =\\) -876.4819101",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#estimateur-de-la-variance-des-r√©sidus",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#estimateur-de-la-variance-des-r√©sidus",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "4.7 Estimateur de la variance des r√©sidus",
    "text": "4.7 Estimateur de la variance des r√©sidus\n\n\n\n\n\n\n\nNoteD√©finition\n\n\n\n\n\\(\\widehat{Y_i}=Ax_i+B\\), la pr√©vision (al√©atoire) par le mod√®le de r√©gression lin√©aire associ√©e √† \\(x_i\\).\n\\(S^2\\) estimateur de \\(\\sigma^2\\) : variance empirique \\[\\color{red}{\\begin{align}S^2&=\\frac{1}{n-2}\\sum_{i=1}^n(Y_i-\\widehat{Y_i})^2\\\\&=\\frac{1}{n-2}\\sum_{i=1}^n(Y_i-Ax_i-B)^2\\end{align}}\\]\nEstimation de \\(\\sigma^2\\) : r√©alisation \\(s^2\\) de \\(S^2\\) sur les donn√©es \\[\\color{blue}{\\begin{align}s^2&=\\frac{1}{n-2}\\sum_{i=1}^n(y_i-ax_i-b)^2\\\\ &=\\frac{1}{n-2}\\sum_{i=1}^n \\widehat{e}_i^2\\end{align}}\\] o√π \\(\\widehat{e}_i = y_i - ax_i -b\\) sont les r√©sidus observ√©s.",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#mod√©lisation-des-donn√©es-avec-r",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#mod√©lisation-des-donn√©es-avec-r",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "4.8 Mod√©lisation des donn√©es avec R",
    "text": "4.8 Mod√©lisation des donn√©es avec R\n\nsummary(modele_reg_simple)\n\n\nCall:\nlm(formula = Poids ~ Longueur, data = fish)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-218.349  -22.040   -5.274   46.515   97.877 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -876.482    198.380  -4.418 0.000332 ***\nLongueur      48.638      7.082   6.868    2e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 71.27 on 18 degrees of freedom\nMultiple R-squared:  0.7238,    Adjusted R-squared:  0.7084 \nF-statistic: 47.16 on 1 and 18 DF,  p-value: 2.004e-06",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#r√©sidus-observ√©s",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#r√©sidus-observ√©s",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "4.9 R√©sidus observ√©s",
    "text": "4.9 R√©sidus observ√©s\n\nsummary(modele_reg_simple)$residuals %&gt;% head()\n\n          1           2           3           4           5           6 \n -9.9271269  -0.8377834  54.0260487 -39.7059207  17.5664152  22.9749190",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#fonction-summary",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#fonction-summary",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "4.10 Fonction summary",
    "text": "4.10 Fonction summary\nOn peut r√©cup√©rer les infos:\n\nCoef &lt;- summary(modele_reg_simple)$coefficients\nclass(Coef)\n\n[1] \"matrix\" \"array\" \n\n\n\n\n\nCoef\n\n              Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) -876.48191 198.379689 -4.418204 3.318341e-04\nLongueur      48.63832   7.082325  6.867565 2.004153e-06\n\n\n\n\n\nnames(summary(modele_reg_simple))\n\n [1] \"call\"          \"terms\"         \"residuals\"     \"coefficients\" \n [5] \"aliased\"       \"sigma\"         \"df\"            \"r.squared\"    \n [9] \"adj.r.squared\" \"fstatistic\"    \"cov.unscaled\" \n\n\n\n\n\nsummary(modele_reg_simple)$sigma\n\n[1] 71.27226",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#validit√©-des-hypoth√®ses-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#validit√©-des-hypoth√®ses-1",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "5.1 Validit√© des hypoth√®ses",
    "text": "5.1 Validit√© des hypoth√®ses\nLes r√©sidus observ√©s permettent de valider les hypoth√®ses du mod√®le lin√©aire:\n\n\\(E_i\\) une variable al√©atoire appel√©e r√©sidu, telle que:\n\nToutes les variables al√©atoires \\(E_1,\\dots, E_n\\) sont ind√©pendantes;\nTous les \\(E_i\\) ont la m√™me esp√©rance, √©gale √† 0;\nTous les \\(E_i\\) ont la m√™me variance, √©gale √† \\(\\mathbf{\\sigma^2}\\) (param√®tre inconnu);\nTous les \\(E_i\\) suivent une loi normale;\n\n\n\n5.1.1 Validation des hypoth√®ses\n\nHypoth√®se d‚Äôind√©pendance: Elle doit √™tre valid√©e par le plan d‚Äôexp√©rience !\nDistribution identique, de loi normale: Ces hypoth√®ses doivent √™tre v√©rifi√©es gr√¢ce aux \\(\\widehat{e}_i = y_i - \\widehat{y_i}\\).\nEn pratique: diagnostic graphique des r√©sidus",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#graphes-de-diagnostic",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#graphes-de-diagnostic",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "5.2 4 graphes de diagnostic",
    "text": "5.2 4 graphes de diagnostic\n\npar(mfrow = c(2,2))\nplot(modele_reg_simple)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#distribution-identique-esp√©rance-constante-et-nulle",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#distribution-identique-esp√©rance-constante-et-nulle",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "5.3 Distribution identique, esp√©rance constante et nulle",
    "text": "5.3 Distribution identique, esp√©rance constante et nulle\nCe qu‚Äôon regarde: Les r√©sidus observ√©s \\(\\widehat{e}_i\\) en fonction des pr√©dictions \\(\\widehat{y}_i\\).\n\n\n\n\n‚úÖ\n\n\n\n\n\n\n\n\n\n\n\n\nCe qu‚Äôon voit: La valeur des r√©sidus ne semble pas d√©pendre de la valeur des pr√©dictions (il ne sont donc pas structur√©s en fonction de la pr√©diction). Ils sont globalement identiquement distribu√©s autour de 0.\nCe qu‚Äôon conclut: On valide l‚Äôhypoth√®se d‚Äôesp√©rance constante et √©gale √† 0.\n\n\n\n\n\n‚ùå\n\n\n\n\n\n\n\n\n\n\n\nCe qu‚Äôon voit: Les valeurs des r√©sidus d√©pendent de la valeur des pr√©dictions (il sont donc structur√©s en fonction de la pr√©diction).\nCe qu‚Äôon conclut: On ne valide pas l‚Äôhypoth√®se d‚Äôesp√©rance constante et √©gale √† 0.",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#distribution-identique-variance-constante",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#distribution-identique-variance-constante",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "5.4 Distribution identique, variance constante",
    "text": "5.4 Distribution identique, variance constante\nCe qu‚Äôon regarde: la racine carr√©e de la valeur absolue des r√©sidus (standardis√©s) observ√©s en fonction des pr√©dictions \\(\\widehat{y}_k\\).\n\n\n\n\n‚úÖ\n\n\n\n\n\n\n\n\n\n\n\n\nCe qu‚Äôon voit: la racine carr√©e de la valeur absolue des r√©sidus ne semble pas d√©pendre de la valeur des pr√©dictions (il ne sont donc pas structur√©s en fonction de la pr√©diction). Ils sont globalement identiquement distribu√©s autour de 0.8.\nCe qu‚Äôon conclut: On valide l‚Äôhypoth√®se de variance constante.\n\n\n\n\n\n‚ùå\n\n\n\n\n\n\n\n\n\n\n\nCe qu‚Äôon voit: la racine carr√©e de la valeur absolue des r√©sidus d√©pend de la valeur des pr√©dictions (il sont donc structur√©s en fonction de la pr√©diction).\nCe qu‚Äôon conclut: On ne valide pas l‚Äôhypoth√®se de variance constante.",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#distribution-normale",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#distribution-normale",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "5.5 Distribution normale",
    "text": "5.5 Distribution normale\nCe qu‚Äôon regarde: La valeur des quantiles empiriques des r√©sidus standardis√©s en fonction de la valeur quantiles th√©oriques d‚Äôune loi normale \\(\\mathcal{N}(0 ,1)\\).\n\n\n\n\n‚úÖ\n\n\n\n\n\n\n\n\n\n\n\n\nCe qu‚Äôon voit: Les points sont globalement align√©s sur la droite \\(y = x\\). Les quantiles empiriques sont donc √† peu pr√®s √©gaux aux quantiles th√©oriques (si les hypoth√®ses du mod√®le sont vraies).\nCe qu‚Äôon conclut: On valide l‚Äôhypoth√®se de distribution normale des r√©sidus.\n\n\n\n\n\n‚ùå\n\n\n\n\n\n\n\n\n\n\n\nCe qu‚Äôon voit: Les points ne sont pas globalement align√©s sur la droite \\(y = x\\). Les quantiles empiriques sont donc diff√©rents des quantiles th√©oriques.\nCe qu‚Äôon conclut: On ne valide pas l‚Äôhypoth√®se de distribution normale des r√©sidus.",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#points-influents-ou-aberrants",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#points-influents-ou-aberrants",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "5.6 Points influents ou aberrants",
    "text": "5.6 Points influents ou aberrants\nCe qu‚Äôon regarde: La valeur des r√©sidus (standardis√©s) en fonction du levier de l‚Äôobservation (poids d‚Äôune observation dans l‚Äôestimation de sa pr√©diction).\n\n\n\n\n‚úÖ\n\n\n\n\n\n\n\n\n\n\n\n\nCe qu‚Äôon voit: Les points ont tous un petit levier, donc aucun point n‚Äôinflue trop sur la droite. Aucun point n‚Äôest en dehors de l‚Äôenveloppe d√©limit√©e par les hyperboles rouges, repr√©sentant les lignes de niveau 0.5 de la distance de Cook.\nCe qu‚Äôon conclut: Aucun point n‚Äôest aberrant ou trop influent.\n\n\n\n\n\n‚ùå\n\n\n\n\n\n\n\n\n\n\n\nCe qu‚Äôon voit: Un point est en dehors de l‚Äôenveloppe d√©limit√©e par les hyperboles rouges, repr√©sentant les lignes de niveau 0.5 de la distance de Cook.\nCe qu‚Äôon conclut: Il y a un point aberrant dans les donn√©es.",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#graphes",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#graphes",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "5.7 4 graphes",
    "text": "5.7 4 graphes\n\n\n\n\n\n\n\n\n\nDonc on valide les hypoth√®ses du mod√®le pour notre exemple.",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#ce-quil-faut-retenir-de-ce-cours-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#ce-quil-faut-retenir-de-ce-cours-1",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "5.8 Ce qu‚Äôil faut retenir de ce cours",
    "text": "5.8 Ce qu‚Äôil faut retenir de ce cours\n\n\n\n\n\n\n\nNoteMod√©lisation probabiliste du mod√®le lin√©aire\n\n\n\n\\(y_i\\) est la r√©alisation d‚Äôune variable al√©atoire \\(Y_i\\) telle que pour \\(1 \\leq i \\leq n\\): \\[Y_i = \\alpha x_i + \\beta  + E_i, \\quad E_i\\overset{i.i.d.}\\sim{\\cal N}(0,\\sigma^2) \\]\n\n\n\n\n\n\n\n\nTipEstimateurs du mod√®le\n\n\n\n\\[{A}=\\frac{\\sum_{i=1}^n(x_i-\\bar{x})(Y_i-\\bar{Y})}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\] \\[{B}=\\bar{Y}-A\\bar{x}\\] \\[S^2=\\frac{1}{n-2}\\sum_{i=1}^n(Y_i-\\widehat{Y_i})^2\n\\]\n\n\n\n\n\n\n\n\nTipValider les hypoth√®ses du mod√®le avec les 4 graphes de diagnostic",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#ce-quil-faut-retenir-de-ce-cours-13",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#ce-quil-faut-retenir-de-ce-cours-13",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.1 Ce qu‚Äôil faut retenir de ce cours 1/3",
    "text": "6.1 Ce qu‚Äôil faut retenir de ce cours 1/3\n\n\n\n\n\n\nTipLois des estimateurs\n\n\n\n\\[\\frac{(A-\\alpha)}{S_A}\\sim \\mathcal{T}{(n-2)}\\]\n\\[\\frac{(B-\\beta)}{S_B}\\sim \\mathcal{T}{(n-2)}\\]\n\n\n\n\n\n\n\n\nTipEstimateurs du mod√®le\n\n\n\n\\[\\begin{align}\nIC_{1-\\delta}(\\alpha) =& \\left[a-t_{1-\\frac{\\delta}{2}} s_A;a+t_{1-\\frac{\\delta}{2}} s_A\\right]\\\\\nIC_{1-\\delta}(\\beta)=&\\left[b-t_{1-\\frac{\\delta}{2}} s_B;b+t_{1-\\frac{\\delta}{2}} s_B\\right]\\\\\n\\end{align}\\]\n\n\\(s_A = \\sqrt{\\frac{s^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}}\\) et \\(s_B = \\sqrt{s^2\\left(\\frac{1}{n}+\\frac{\\bar{x}^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)}\\)\n\n\n\n\n\n\n\n\n\nNoteTest de Student de la nullit√© de la pente de r√©gression\n\n\n\n\n\\[H_0:\\alpha=0\\]\n\\[H_1:\\alpha\\neq 0\\]\n\n\n\n\n\n\n\n\n\nNoteTest de Fisher de Comparaison de mod√®les\n\n\n\n\\[H_0\\; :\\; \\text{mod√®le}\\; M_1:Y_i=\\beta+E_i\\]\n\\[H_1\\; :\\; \\text{mod√®le}\\; M_2:Y_i=\\alpha x_i+\\beta+E_i\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#ce-quil-faut-retenir-de-ce-cours-23",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#ce-quil-faut-retenir-de-ce-cours-23",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.2 Ce qu‚Äôil faut retenir de ce cours 2/3",
    "text": "6.2 Ce qu‚Äôil faut retenir de ce cours 2/3\n\n\n\n\n\n\n\nNoteD√©finition : SCT\n\n\n\nLa variabilit√© de \\(Y\\) sans tenir compte du mod√®le.\n\\[\\color{purple}{SCT =\\displaystyle\\sum_{i = 1}^n( Y_i - \\bar{Y})^2}\\]\n\n\n\n\n\n\n\n\nNoteD√©finition : SCM\n\n\n\nPartie de la variabilit√© de \\(Y\\) expliqu√©e par le mod√®le.\n\\[\\color{blue}{SCM = \\displaystyle\\sum_{i=1}^n(\\widehat{Y_i}-\\bar{Y})^2}\\]\n\n\n\n\n\n\n\n\nNoteD√©finition : SCR\n\n\n\nPartie de la variabilit√© de \\(Y\\) qui n‚Äôest pas expliqu√©e par le mod√®le.\n\\[\\color{red}{SCR = \\displaystyle\\sum_{i=1}^n(Y_i-\\widehat{Y_i})^2=\\displaystyle\\sum_{i=1}^n E_i ^2}\\]\n\n\n\n\n\n\n\n\nTipD√©composition de la variance\n\n\n\n\\[\\color{purple}{SCT} = \\color{blue}{SCM} + \\color{red}{SCR} \\]\n\n\n\n\n\n\n\n\nTipTest de Fisher\n\n\n\n\\[T_n=\\frac{SCM/1}{SCR/(n-2)} \\overset{H_0}{\\sim} \\mathcal{F}(1,n-2)\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#ce-quil-faut-retenir-de-ce-cours-33",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#ce-quil-faut-retenir-de-ce-cours-33",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.3 Ce qu‚Äôil faut retenir de ce cours 3/3",
    "text": "6.3 Ce qu‚Äôil faut retenir de ce cours 3/3\n\n\n\n\n\n\nNoteCoefficient de d√©termination\n\n\n\n\\[R^2 = \\frac{SCM}{SCT}\\]\n\n\n\n\n\n\n\n\nTipIntervalle de confiance de la droite de r√©gression\n\n\n\n\\[IC_{1-\\delta}(\\mathbb{E}[Y_0])= \\] \\[\\begin{align}\n&\\left[\\widehat{y_0}-t_{1-\\frac{\\delta}{2}}\\sqrt{s^2\\left(\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)};\\right.\\\\\n&\\left.\\widehat{y_0}+t_{1-\\frac{\\delta}{2}}\\sqrt{s^2\\left(\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)}\\right]\n\\end{align}\\]\n\n\n\n\n\n\n\n\nTipIntervalle de pr√©vision\n\n\n\n\\[IP_{1-\\delta}(Y_0)=\\]\n\\[\\begin{align}\n&\\left[\\widehat{y_0}-t_{1-\\frac{\\delta}{2}}\\sqrt{s^2\\left(1+\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)};\\right.\\\\\n&\\left.\\widehat{y_0}+t_{1-\\frac{\\delta}{2}}\\sqrt{s^2\\left(1+\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)}\\right]\n\\end{align}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#degr√©s-de-libert√©s-degrees-of-freedom",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#degr√©s-de-libert√©s-degrees-of-freedom",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.4 Degr√©s de libert√©s (Degrees of freedom)",
    "text": "6.4 Degr√©s de libert√©s (Degrees of freedom)\n\n\n\n\n\n\nNoteD√©finition\n\n\n\nDegr√©s de libert√©s (Degrees of freedom) : Le nombre d‚Äôobservations moins le nombre de param√®tres d‚Äôesp√©rance √† estimer.\n\n\n\nDans le cadre du mod√®le lin√©aire simple le nombre de param√®tre d‚Äôesp√©rance √† estimer est 2.\nOn a \\(n\\) observations le nombre de degr√©es de libert√©s est donc : \\(n-2\\)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#propri√©t√©-et-loi-de-lestimateur-s2",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#propri√©t√©-et-loi-de-lestimateur-s2",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.5 Propri√©t√© et loi de l‚Äôestimateur \\(S^2\\):",
    "text": "6.5 Propri√©t√© et loi de l‚Äôestimateur \\(S^2\\):\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\n\\(S^2\\) est un estimateur sans biais de \\(\\sigma^2\\) et on a\n\\[\\frac{(n-2)S^2}{\\sigma^2}=\\frac{\\sum_{i=1}^n(Y_i-Ax_i-B)^2}{\\sigma^2}\\]\n\\[\\frac{(n-2)S^2}{\\sigma^2}\\sim\\chi^2(n-2)\\] De plus \\(S^2\\) est ind√©pendant de \\(A\\), \\(B\\) et \\(\\bar{Y}\\)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#propri√©t√©s-et-loi-des-estimateurs-a-et-b",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#propri√©t√©s-et-loi-des-estimateurs-a-et-b",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.6 Propri√©t√©s et loi des estimateurs \\(A\\) et \\(B\\)",
    "text": "6.6 Propri√©t√©s et loi des estimateurs \\(A\\) et \\(B\\)\n\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\n\\(A\\) et \\(B\\) sont des estimateurs sans biais et consistants de \\(\\alpha\\) et \\(\\beta\\). \\(A\\) et \\(B\\) suivent des lois normales d‚Äôesp√©rance \\(\\alpha\\) et \\(\\beta\\), et de variance\n\\[\\begin{align}\nVar(A)&=\\frac{\\sigma^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\\\\n& \\\\\nVar(B)&=\\sigma^2\\left(\\frac{1}{n}+\\frac{\\bar{x}^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)\n\\end{align}\\] Si on remplace \\(\\sigma^2\\) par \\(S^2\\) pour obtenir des estimateurs des variances\n\\[S^2_A=\\frac{S^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\]\n\\[S^2_B=S^2\\left(\\frac{1}{n}+\\frac{\\bar{x}^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)\\]\non a\n\\[\\frac{(A-\\alpha)}{S_A}\\sim \\mathcal{T}{(n-2)}\\]\n\\[\\frac{(B-\\beta)}{S_B}\\sim \\mathcal{T}{(n-2)}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#intervalle-de-confiance-al√©atoire-de-alpha-et-beta",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#intervalle-de-confiance-al√©atoire-de-alpha-et-beta",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.7 Intervalle de confiance al√©atoire de \\(\\alpha\\) et \\(\\beta\\)",
    "text": "6.7 Intervalle de confiance al√©atoire de \\(\\alpha\\) et \\(\\beta\\)\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\nA partir des lois de \\(A\\) et \\(B\\), on obtient:\nIntervalles de confiance al√©atoire des estimateurs de niveau \\(1-\\delta\\) de \\(\\alpha\\) et \\(\\beta\\)\n\\[\\begin{align}\nIC_{1-\\delta}(\\alpha) = \\left[A-t_{1-\\frac{\\delta}{2}} S_A;A+t_{1-\\frac{\\delta}{2}} S_A\\right]\\\\\nIC_{1-\\delta}(\\beta)=\\left[B-t_{1-\\frac{\\delta}{2}} S_B;B+t_{1-\\frac{\\delta}{2}} S_B\\right]\\\\\n\\end{align}\\]\no√π \\(t_{1-\\frac{\\delta}{2}}\\) est tel que \\(\\mathbb{P}\\left(\\mid \\mathcal{T}(n-2)\\mid \\leq t_{1-\\frac{\\delta}{2}}\\right)=1-\\delta\\)\n\\(t_{1-\\frac{\\delta}{2}}\\) est le quantile d‚Äôordre \\(1-\\frac{\\delta}{2}\\) de la loi de \\(\\mathcal{T}(n-2)\\).",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#intervalle-de-confiance-de-alpha-et-beta",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#intervalle-de-confiance-de-alpha-et-beta",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.8 Intervalle de confiance de \\(\\alpha\\) et \\(\\beta\\)",
    "text": "6.8 Intervalle de confiance de \\(\\alpha\\) et \\(\\beta\\)\n\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\n\nIntervalles de confiance des estimateurs de niveau \\(1-\\delta\\) de \\(\\alpha\\) et \\(\\beta\\)\n\n\\[\\begin{align}\nIC_{1-\\delta}(\\alpha) = &\\left[a-t_{1-\\frac{\\delta}{2}} s_A;a+t_{1-\\frac{\\delta}{2}} s_A\\right]\\\\\nIC_{1-\\delta}(\\beta)=&\\left[b-t_{1-\\frac{\\delta}{2}} s_B;b+t_{1-\\frac{\\delta}{2}} s_B\\right]\\\\\n\\end{align}\\]\n\no√π \\(t_{1-\\frac{\\delta}{2}}\\) est tel que \\(\\mathbb{P}\\left(\\mid \\mathcal{T}(n-2)\\mid \\leq t_{1-\\frac{\\delta}{2}}\\right)=1-\\delta\\)\n\\(t_{1-\\frac{\\delta}{2}}\\) est le quantile d‚Äôordre \\(1-\\frac{\\delta}{2}\\) de la loi de \\(\\mathcal{T}(n-2)\\).\n\\(s_A = \\sqrt{\\frac{s^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}}\\) : r√©alisation de \\(S_A\\)\n\\(s_B = \\sqrt{s^2\\left(\\frac{1}{n}+\\frac{\\bar{x}^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)}\\) : r√©alisation de \\(S_B\\)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#intervalle-de-confiance-avec-r",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#intervalle-de-confiance-avec-r",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.9 Intervalle de confiance avec R",
    "text": "6.9 Intervalle de confiance avec R\n\nIntervalle de confiance √† 95%\n\n\nconfint(modele_reg_simple, level = 0.95)\n\n                  2.5 %     97.5 %\n(Intercept) -1293.26217 -459.70165\nLongueur       33.75891   63.51773",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#test-dans-le-mod√®le-de-r√©gression-lin√©aire-simple-gaussien",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#test-dans-le-mod√®le-de-r√©gression-lin√©aire-simple-gaussien",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.10 Test dans le mod√®le de r√©gression lin√©aire simple gaussien",
    "text": "6.10 Test dans le mod√®le de r√©gression lin√©aire simple gaussien\nTest du caract√®re significatif de la liaison lin√©aire\n\nTest de Student de la nullit√© de la pente de r√©gression \\(H_0:\\alpha=0\\) contre \\(H_1:\\alpha\\neq 0\\)\nTest de Fisher de Comparaison de mod√®les : \\[H_0\\; \\text{mod√®le}\\; M_1:Y_i=\\beta+E_i\\] \\[\\text{avec } E_i\\overset{i.i.d}\\sim {\\cal N}(0,\\sigma^2)\\]\n\n\ncontre l‚Äôalternative\n\n\\[H_1\\; :\\; \\text{mod√®le}\\; M_2:Y_i=\\alpha x_i+\\beta+E_i\\]\n\\[\\text{avec } E_i\\overset{i.i.d}\\sim {\\cal N}(0,\\sigma^2)\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#test-de-student-de-la-nullit√©-de-la-pente-de-r√©gression",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#test-de-student-de-la-nullit√©-de-la-pente-de-r√©gression",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.11 Test de Student de la nullit√© de la pente de r√©gression",
    "text": "6.11 Test de Student de la nullit√© de la pente de r√©gression\nMod√©lisation des donn√©es :\n\\((x_i,y_i)\\), \\(i=1,\\dots,n\\) : mod√®le lin√©aire \\(\\forall i=1,\\cdots,n\\)\n\\[Y_i=\\alpha x_i+\\beta+E_i, \\; E_i\\overset{i.i.d.}\\sim{\\cal N}(0,\\sigma^2)\\]\nHypoth√®ses :\nTest de \\[H_0:\\alpha=0\\]\ncontre\n\\[H_1:\\alpha\\neq 0\\] au risque \\(\\delta=5\\%\\)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#statistique-de-test",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#statistique-de-test",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.12 Statistique de test",
    "text": "6.12 Statistique de test\n\\(H_0:\\alpha=0\\) contre \\(H_1:\\alpha\\neq 0\\)\nStatistique de test :\n\\[T_n =\\frac{(A-\\alpha)}{S_A} \\overset{H_0}= \\frac{A}{S_A} \\overset{H_0}\\sim \\mathcal{T}{(n-2)}\\]\nZone de rejet :\n\\[R_\\delta = \\{|T_n| &gt; t_{1-\\frac{\\delta}{2}}\\}\\]\nOn rejette \\(H_0\\) si \\(t_{n} \\in R_{\\delta}\\)\nApplication num√©rique :\nOn calcule \\(t_{n} = \\frac{a}{s_A}\\) la r√©alisation de \\(T_n\\).\nOn compare avec \\(t_{1-\\frac{\\delta}{2}}\\) et on conclue.",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#p-valeur-du-test",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#p-valeur-du-test",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.13 p-valeur du test",
    "text": "6.13 p-valeur du test\n\\(p\\)-valeur :\n\\[\\begin{align}p_c&=\\mathbb{P}_{H_0}(\\mid T_n\\mid &gt;\\mid t_{obs}\\mid)\\\\&=2(1-\\mathbb{P}(T_n\\leq |t_n|))\\end{align}\\] o√π \\(T_n\\sim \\mathcal{T}(n-2)\\)\nPour un risque de 1ere esp√®ce \\(\\delta\\) fix√© acceptable (par ex \\(\\delta=5\\%\\))\n\nsi \\(p_c &lt;\\delta\\), on rejette \\(H_0\\), le test de niveau \\(\\delta\\) est significatif (liaison significative)\nsi \\(p_c &gt;\\delta\\), on ne rejette \\(H_0\\) pas, le test de niveau \\(\\delta\\) n‚Äôest pas significatif (liaison non significative)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#test-de-student-sur-la-pente-de-r√©gression-avec-r",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#test-de-student-sur-la-pente-de-r√©gression-avec-r",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.14 Test de student sur la pente de r√©gression avec R",
    "text": "6.14 Test de student sur la pente de r√©gression avec R\n\nsummary(modele_reg_simple)$coefficient\n\n              Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) -876.48191 198.379689 -4.418204 3.318341e-04\nLongueur      48.63832   7.082325  6.867565 2.004153e-06\n\n\n\n\\(T_n = \\frac{a}{s_A}\\)\n\n48.63832 / 7.082325\n\n[1] 6.867564\n\n\n\\(\\begin{align}p_c &=\\mathbb{P}_{H_0}(\\mid T_n\\mid &gt;\\mid t_n\\mid)\\\\&= 2(1-\\mathbb{P}_{H_0}(T_n\\leq |t_n|))\\end{align}\\) o√π \\(T_n\\sim \\mathcal{T}(n-2)\\)\n\nn &lt;- nrow(fish)\n2*(1-pt(abs(6.867564), n - 2))\n\n[1] 2.004155e-06",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#test-de-fisher-du-caract√®re-significatif-de-la-lin√©arit√©",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#test-de-fisher-du-caract√®re-significatif-de-la-lin√©arit√©",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.15 Test de Fisher du caract√®re significatif de la lin√©arit√©",
    "text": "6.15 Test de Fisher du caract√®re significatif de la lin√©arit√©\nApproche par comparaison de mod√®les\n\nComparer les mod√®les \\(M_1\\) et \\(M_2\\) (√† un et deux param√®tres d‚Äôesp√©rance) d√©finis par\n\n\\[\\begin{align}\nM_1 &: Y_i= \\beta+E_i,\\quad E_i\\ \\overset{i.i.d.}\\sim\\ {\\cal N}(0,\\sigma^2)\\\\\nM_2 &: Y_i=\\alpha x_i+\\beta+E_i,\\quad E_i\\ \\overset{i.i.d.}\\sim\\ {\\cal N}(0,\\sigma^2)\n\\end{align}\\]\n\nRevient √† tester, au risque \\(\\delta\\) fix√©, l‚Äôhypoth√®se nulle\n\n\\[H_0 : \\mbox{ mod√®le } M_1\\]\ncontre l‚Äôalternative\n\\[H_1 : \\mbox{ mod√®le } M_2\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#etude-de-la-variance",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#etude-de-la-variance",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.16 Etude de la variance",
    "text": "6.16 Etude de la variance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteD√©finition : Somme des Carr√©s Totale\n\n\n\nLa variabilit√© de \\(Y\\) sans tenir compte du mod√®le.\n\\[\\color{purple}{SCT =\\displaystyle\\sum_{i = 1}^n( Y_i - \\bar{Y})^2}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#etude-de-la-variance-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#etude-de-la-variance-1",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.17 Etude de la variance",
    "text": "6.17 Etude de la variance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteD√©finition : Somme des Carr√©s du Mod√®le\n\n\n\nPartie de la variabilit√© de \\(Y\\) expliqu√©e par le mod√®le.\n\\[\\color{blue}{SCM = \\displaystyle\\sum_{i=1}^n(\\widehat{Y_i}-\\bar{Y})^2}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteD√©finition : Somme des Carr√©s R√©siduelles\n\n\n\nPartie de la variabilit√© de \\(Y\\) qui n‚Äôest pas expliqu√©e par le mod√®le.\n\\[\\color{red}{SCR = \\displaystyle\\sum_{i=1}^n(Y_i-\\widehat{Y_i})^2=\\displaystyle\\sum_{i=1}^n E_i ^2}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#d√©composition-de-la-variance",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#d√©composition-de-la-variance",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.18 D√©composition de la variance",
    "text": "6.18 D√©composition de la variance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\\color{purple}{SCT =\\displaystyle\\sum_{i = 1}^n( Y_i - \\bar{Y})^2}\\]\n\\[\\color{blue}{SCM = \\displaystyle\\sum_{i=1}^n(\\widehat{Y_i}-\\bar{Y})^2}\\]\n\\[\\color{red}{SCR = \\displaystyle\\sum_{i=1}^n(Y_i-\\widehat{Y_i})^2=\\displaystyle\\sum_{i=1}^n E_i ^2}\\]\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\n\\[\\color{purple}{SCT} = \\color{blue}{SCM} + \\color{red}{SCR} \\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#lid√©e-derri√®re-le-test",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#lid√©e-derri√®re-le-test",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.19 L‚Äôid√©e derri√®re le test",
    "text": "6.19 L‚Äôid√©e derri√®re le test\n\n6.19.0.1 Mod√®le avec pente significative. \\(SCM\\) est significativement plus grande que \\(SCR\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.19.0.2 Mod√®le sans pente significative. \\(SCM\\) n‚Äôest pas significativement plus grande que \\(SCR\\).",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#test-de-fisher",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#test-de-fisher",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.20 Test de Fisher",
    "text": "6.20 Test de Fisher\nIl s‚Äôagit d‚Äôun test unilat√©ral de comparaison de variance !\nStatistique de test\n\\[T_n=\\frac{SCM/1}{SCR/(n-2)} \\overset{H_0}{\\sim} \\mathcal{F}(1,n-2)\\]\nZone de rejet\n\\[R_\\delta = \\{T_n &gt; f_{1-\\delta} \\}\\]\n\\(f_{1-\\delta}\\) est le quantile \\(1 - \\delta\\) de la loi de Fisher \\(\\mathcal{F}(1,n-2)\\).\n\\(\\mathbb{P}_{H_0}(T_n&lt;f_{1-\\delta})=1-\\delta\\)\nApplication num√©rique\n\nOn calcule \\(t_n\\)\nOn rejette \\(H_0\\) si \\(t_{n} \\in R_{\\delta}\\)\n\nCalcul de \\(p_c\\)\n\\(p_{c} = \\mathbb{P}_{H_0}(T_n &gt; t_n)=1-\\mathbb{P}(F&lt;t_n)\\) o√π \\(F\\sim \\mathcal{F}(1,n-2)\\)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#test-de-fisher-avec-r",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#test-de-fisher-avec-r",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.21 Test de fisher avec R",
    "text": "6.21 Test de fisher avec R\n\nsummary(modele_reg_simple)\n\n\nCall:\nlm(formula = Poids ~ Longueur, data = fish)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-218.349  -22.040   -5.274   46.515   97.877 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -876.482    198.380  -4.418 0.000332 ***\nLongueur      48.638      7.082   6.868    2e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 71.27 on 18 degrees of freedom\nMultiple R-squared:  0.7238,    Adjusted R-squared:  0.7084 \nF-statistic: 47.16 on 1 and 18 DF,  p-value: 2.004e-06",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#table-danalyse-de-la-variance",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#table-danalyse-de-la-variance",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.22 Table d‚Äôanalyse de la variance",
    "text": "6.22 Table d‚Äôanalyse de la variance\n\n\n\n\n\n\n\n\n\n\n\n\nSource de variabilit√©\nddl\nSomme des Carr√©s\nCarr√©s Moyens\nStatistique de test\n\\(p_c\\)\n\n\n\n\nMod√®le\n\\(1\\)\n\\(SCM\\)\n\\(CMM = SCM / 1\\)\n\\(t_n = \\frac{CMM}{CMR}\\)\n\\(\\mathbb{P}(\\mathcal{F}(1,n-2) &gt; t_n)\\)\n\n\nR√©sidu\n\\(n-2\\)\n\\(SCR\\)\n\\(CMR = SCR / (n-2)\\)\n\n\n\n\nTotal\n\\(n-1\\)\n\\(SCT\\)\n\\(CMT = SCT / (n-1)\\)\n\n\n\n\n\n\nanova(modele_reg_simple)\n\nAnalysis of Variance Table\n\nResponse: Poids\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nLongueur   1 239578  239578  47.163 2.004e-06 ***\nResiduals 18  91435    5080                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#une-autre-formulation-du-test-de-fisher",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#une-autre-formulation-du-test-de-fisher",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.23 Une autre formulation du test de Fisher",
    "text": "6.23 Une autre formulation du test de Fisher\nOn veut tester\n\n\\(H_0\\): Mod√®le \\(M_1\\) : \\(Y_i=\\beta+E_i\\) avec \\(E_i\\overset{i.i.d}\\sim{\\cal N}(0,\\sigma^2)\\)\n\ncontre\n\n\\(H_1\\): Mod√®le \\(M_2\\) : \\(Y_i=\\beta+ \\alpha x_i+E_i\\) avec \\(E_i\\overset{i.i.d}\\sim{\\cal N}(0,\\sigma^2)\\)\n\nCette fois-ci, on va se concentrer sur les r√©sidus de ces deux mod√®les.",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#les-r√©sidus-du-mod√®le-m_2",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#les-r√©sidus-du-mod√®le-m_2",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.24 Les r√©sidus du mod√®le \\(M_2\\)",
    "text": "6.24 Les r√©sidus du mod√®le \\(M_2\\)\n\\[Y_i=\\beta+ \\alpha x_i+E_i, \\mbox{ o√π } E_i\\overset{i.i.d.}\\sim{\\cal N}(0,\\sigma^2)\\]\n\n\\(Y_i \\overset{i.i.d.}\\sim {\\mathcal N}(\\alpha x_i+\\beta;\\sigma^2)\\).\n2 param√®tres d‚Äôesp√©rance \\(\\alpha\\) et \\(\\beta\\) estim√©s (par les moindres carr√©s) par \\(A\\) et \\(B\\).\nPr√©dicteur \\(\\widehat{Y_i}(M_2)=Ax_i+B\\)\nSomme des carr√©s r√©siduelles :\n\n\\[\\begin{align}SCR(M_2) = \\sum_{i=1}^n (Y_i-\\widehat{Y_i}(M_2))^2 \\\\= \\sum_{i=1}^n (Y_i-Axi-B)^2\\end{align}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#les-r√©sidus-du-mod√®le-m_1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#les-r√©sidus-du-mod√®le-m_1",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.25 Les r√©sidus du mod√®le \\(M_1\\)",
    "text": "6.25 Les r√©sidus du mod√®le \\(M_1\\)\n\\[Y_i=\\beta+E_i, \\mbox{ o√π }  E_i\\overset{i.i.d.}\\sim{\\cal N}(0,\\sigma^2)\\]\n\n\\(Y_i\\overset{i.i.d.}\\sim{\\cal N}(\\beta;\\sigma^2)\\)\n1 param√®tre d‚Äôesp√©rance \\(\\beta\\) estim√© (par les moindres carr√©s) par \\(\\bar{Y}\\).\nPr√©dicteur \\(\\widehat{Y_i}(M_1) = \\bar{Y}\\)\nSomme des carr√©s r√©siduelles :\n\n\\[\\begin{align}SCR(M_1)&=\\sum_{i=1}^n E_i^2(M_1)\\\\&=\\sum_{i=1}^n (Y_i-\\widehat{Y}_i(M_1))^2\\\\&=\\sum_{i=1}^n (Y_i-\\bar{Y})^2=SCT\\end{align}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#interpr√©tation-du-test-de-fisher",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#interpr√©tation-du-test-de-fisher",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.26 Interpr√©tation du test de Fisher",
    "text": "6.26 Interpr√©tation du test de Fisher\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\nStatistique de test \\(T_n\\) peut s‚Äô√©crire\n\\[\n\\begin{align}\nT_n &= \\frac{SCM/ 1}{SCR(M_2)/(n-2)} \\\\\n= &\\frac{(SCR(M_{\\color{red}{1}}) - SCR(M_{\\color{red}{2}}))/ ( 2 - 1)}{SCR(M_2)/(n- 2)}\\\\&\\overset{H_0}\\sim \\mathcal{F}(1,n-2)\n\\end{align}\n\\]\n\n\n\n\n\n\n\n\nCautionRemarques\n\n\n\n\n\\(SCR(M_{\\color{red}{1}}) - SCR(M_{\\color{red}{2}})\\) : diff√©rence des variances non expliqu√©es par les mod√®les.\n\\((2-1)\\) : diff√©rence du nombre de param√®tres.\n\\(SCR(M_1)\\geq SCR(M_2)\\) (toujours !).",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#remarque-sur-le-test-de-fisher",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#remarque-sur-le-test-de-fisher",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.27 Remarque sur le test de Fisher",
    "text": "6.27 Remarque sur le test de Fisher\n\n\n\n\n\n\nCautionRemarques\n\n\n\n\nLe test r√©pond √† la question : la droite des moindres carr√©s \\(y=ax+b\\) (mod√®le \\(M_2\\) estim√©) explique mieux le nuage de points que la droite horizontale \\(y=b\\) (mod√®le \\(M_1\\) estim√©), mais le gain est-il significatif ?\n\\(SCR(M_1)\\geq SCR(M_2)\\)\nOn n‚Äôabandonnera \\(M_1\\) pour que \\(M_2\\) que si la r√©duction d‚Äôerreurs en passant du ‚Äúpetit‚Äù mod√®le \\(M_1\\) au ‚Äúgrand‚Äù mod√®le \\(M_2\\) est significative.\nL‚Äôintroduction de la pente a permis d‚Äôexpliquer \\(SCM=SCR(M_1)-SCR(M_2)\\) et a laiss√© inexpliqu√©e \\(SCR(M_2)\\).",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#autre-m√©thode-test-de-fisher-avec-r",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#autre-m√©thode-test-de-fisher-avec-r",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.28 Autre m√©thode: test de Fisher avec R",
    "text": "6.28 Autre m√©thode: test de Fisher avec R\n\nmod1 &lt;- lm(Poids~1, data = fish)\n\nsummary(mod1)\n\n\nCall:\nlm(formula = Poids ~ 1, data = fish)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-239.50  -98.25    6.00  118.50  218.50 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   481.50      29.51   16.31 1.25e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 132 on 19 degrees of freedom",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#autre-m√©thode-test-de-fisher-avec-r-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#autre-m√©thode-test-de-fisher-avec-r-1",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.29 Autre m√©thode: test de Fisher avec R",
    "text": "6.29 Autre m√©thode: test de Fisher avec R\n\nanova(mod1,modele_reg_simple)\n\nAnalysis of Variance Table\n\nModel 1: Poids ~ 1\nModel 2: Poids ~ Longueur\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1     19 331013                                  \n2     18  91435  1    239578 47.163 2.004e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#lien-entre-les-deux-tests",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#lien-entre-les-deux-tests",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.30 Lien entre les deux tests",
    "text": "6.30 Lien entre les deux tests\n\n\n\n\n\n\nCautionRemarques\n\n\n\n\nTest de Student : \\(T^S_{n}=\\frac{A}{S_A}\\overset{H_0}\\sim \\mathcal{T}(n-2)\\)\nTest de Fisher : \\(T^F_{n}=\\displaystyle\\frac{SCM/1}{SCR/(n-2)}\\overset{H_0}\\sim \\mathcal{F}(1,n-2)\\).\nproc√©dure √©quivalente : \\(\\left(T^S_{n,1}\\right)^2=T^F_{n}\\) et la loi du carr√© d‚Äôune variable al√©atoire \\(\\mathcal{T}(n-2)\\) est une loi de Fisher \\(\\mathcal{F}(1,n-2)\\)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#coefficient-de-d√©termination",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#coefficient-de-d√©termination",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "7.1 Coefficient de d√©termination",
    "text": "7.1 Coefficient de d√©termination\n\n\n\n\n\n\nNoteD√©finition : Coefficient de d√©termination\n\n\n\nOn appelle le coefficient de d√©termination \\(R^2\\) la proportion de la variabilit√© de \\(Y\\) expliqu√©e par le mod√®le. Cette proportion est donn√©e par\n\\[R^2 = \\frac{SCM}{SCT}\\]\n\n\n\nOn a \\(0\\leq R^2\\leq 1\\). Plus \\(R^2\\) est proche de \\(1\\), meilleur est l‚Äôajustement.\n\nSi la qualit√© d‚Äôajustement est mauvais on ne peut pas esp√©rer avoir une bonne pr√©diction.",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#visualisation-coefficient-de-d√©termination",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#visualisation-coefficient-de-d√©termination",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "7.2 Visualisation : Coefficient de d√©termination",
    "text": "7.2 Visualisation : Coefficient de d√©termination\n\n7.2.0.1 Mod√®le avec pente significative.\n\n\\[R^2 = 0.8395522\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.2.0.2 Mod√®le sans pente significative.\n\n\\[R^2 = 0.0353026\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#pr√©vision",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#pr√©vision",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "8.1 Pr√©vision",
    "text": "8.1 Pr√©vision\n\nDonn√©es \\((x_i,y_i)_{i=1,\\cdots,n}\\) mod√©lis√©es par \\[Y_i=\\alpha x_i+\\beta +E_i,\\quad E_i\\overset{i.i.d.}\\sim{\\cal N}(0,\\sigma^2)\\]\nProbl√©matique\n\nEtant donn√©e une valeur \\(x_0\\) de \\(x\\) pour laquelle on n‚Äôa pas observ√© \\(y_0\\), construire une pr√©vision de ce \\(y_0\\) non disponible\npr√©vision intuitive par droite des moindres carr√©es de \\(y_0\\) : \\(\\widehat{y_0}=ax_0+b\\)\nQuel sens lui donner ? Quelle qualit√© ?",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#pr√©vision-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#pr√©vision-1",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "8.2 Pr√©vision",
    "text": "8.2 Pr√©vision\n\n\\({\\widehat y}_0 = ax_0 +b\\) est une r√©alisation de la variable al√©atoire \\(\\widehat{Y_0}\\) d√©finie par \\(\\widehat{Y_0}=Ax_0+B\\)\n\\(\\mathbb{E}[\\widehat{Y_0}]=\\alpha x_0+\\beta\\) : \\(\\widehat{Y_0}\\) est un estimateur sans biais de \\(\\mathbb{E}[Y_0] = \\alpha x_0+\\beta\\)\nDe plus, si \\(y_0\\) √©tait disponible, on lui associerait une v.a. \\(Y_0\\) d√©finie par \\[Y_0=\\alpha x_0+\\beta + E_0,\\quad\nE_0\\overset{i.i.d}\\sim{\\cal N}(0,\\sigma^2)\\]\n\\(\\widehat{y_0}\\) est donc √† la fois une estimation de \\(\\mathbb{E}[Y_0]\\) et une pr√©vision de \\(y_0\\)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#deux-probl√©matiques",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#deux-probl√©matiques",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "8.3 Deux probl√©matiques",
    "text": "8.3 Deux probl√©matiques\n\n\n\n\n\n\n\nWarning1 : On ne prend pas en compte la variabilit√© de \\(E_0\\)\n\n\n\n\\(\\widehat{y_0} = a x_0 +b\\) est une estimation de \\(\\mathbb{E}[Y_0]\\) :\n\nConstruire un intervalle de confiance pour le param√®tre \\(\\mathbb{E}[Y_0]\\). On s‚Äôinteresse ici √† la partie de la r√©ponse expliqu√©e par le mod√®le. (Seulement la partie du poids du poisson qui est expliqu√©e par sa longueur)\nEn faisant varier \\(x_0\\), construire un intervalle de confiance de la droite de r√©gression \\(\\alpha x+\\beta\\)\n\n\n\n\n\n\n\n\n\nWarning2 : On prend en compte la variabilit√© de \\(E_0\\)\n\n\n\n\\(\\widehat{y_0}\\) est une pr√©vision de \\(y_0\\) :\n\nConstruire un intervalle de pr√©diction pour \\(Y_0\\).\n\nOn s‚Äôinteresse ici √† la totalit√© de la r√©ponse. (On veut un intervalle sur le poids du poisson totale.)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#intervalle-de-confiance-de-mathbbey_0",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#intervalle-de-confiance-de-mathbbey_0",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "8.4 Intervalle de confiance de \\(\\mathbb{E}[Y_0]\\)",
    "text": "8.4 Intervalle de confiance de \\(\\mathbb{E}[Y_0]\\)\n\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\n\\(\\widehat{Y_0}=Ax_0+B\\) est un estimateur sans biais de \\(\\mathbb{E}[Y_0]=\\alpha x_0+ \\beta\\), de variance \\[\\mathbb{V}\\left[\\widehat{Y_0}\\right]=\\sigma^2\\left(\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right).\\]\nL‚Äôestimateur de la variance \\(\\mathbb{V}\\left[\\widehat{Y_0}\\right]\\) est donn√©e par \\[S_0^2=S^2\\left(\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)\\]\nDe plus, \\[\n\\frac{\\left(\\widehat{Y_0}-\\mathbb{E}[Y_0]\\right)}{S_0}\\sim \\mathcal{T}(n-2)\n\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#intervalle-de-confiance-de-mathbbey_0-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#intervalle-de-confiance-de-mathbbey_0-1",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "8.5 Intervalle de confiance de \\(\\mathbb{E}[Y_0]\\)",
    "text": "8.5 Intervalle de confiance de \\(\\mathbb{E}[Y_0]\\)\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\nIntervalle de confiance de \\(\\mathbb{E}[Y_0]\\) au niveau de confiance \\(1-\\delta\\)\n\\[\nIC_{1-\\delta}(\\mathbb{E}[Y_0]) =\n\\left[\\widehat{y_0}-t_{1-\\frac{\\delta}{2}}\\ s_0;\\right.\n\\left.\\widehat{y_0}+t_{1-\\frac{\\delta}{2}}\\ s_0\\right],\n\\] o√π\n\n\\(s_0 = \\sqrt{s^2\\left(\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)}\\)\n\\(t_{1-\\frac{\\delta}{2}}\\) est tel que \\(\\mathbb{P}\\left(\\mid \\mathcal{T}(n-2)\\mid \\leq t_{1-\\frac{\\delta}{2}}\\right)=1-\\delta\\).",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#intervalle-de-confiance-de-la-droite-de-r√©gression",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#intervalle-de-confiance-de-la-droite-de-r√©gression",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "8.6 Intervalle de confiance de la droite de r√©gression",
    "text": "8.6 Intervalle de confiance de la droite de r√©gression\n\n\n\n\n\n\nCautionRemarques\n\n\n\n\\(IC_{1-\\delta}(\\mathbb{E}[Y_0]) = \\left[\\widehat{y_0}-t_{1-\\frac{\\delta}{2}}\\ s_0;\\right.\\left.\\widehat{y_0}+t_{1-\\frac{\\delta}{2}}\\ s_0\\right],\\) avec \\(s_0 = \\sqrt{s^2\\left(\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)}\\)\n\nEn faisant varier \\(x_0\\), les IC d√©finissent deux hyperboles qui sont l‚ÄôIC de la droite de r√©gression\nPlus on s‚Äô√©loigne du point moyen \\((\\bar{x},\\bar{y})\\), moins l‚Äôestimation est pr√©cise\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#intervalle-de-pr√©vision-de-y_0",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#intervalle-de-pr√©vision-de-y_0",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "8.7 Intervalle de pr√©vision de \\(Y_0\\)",
    "text": "8.7 Intervalle de pr√©vision de \\(Y_0\\)\n\nOn rajoute l‚Äôal√©a non expliqu√© par le mod√®le\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\n\\(Y_0=\\alpha x_0+\\beta + E_0\\)\n\\[\\begin{align}\\mathbb{V}(\\widehat{Y_0} - Y_0)&= \\mathbb{V}[Ax_0+ B] + \\mathbb{V}[E_0] \\\\&= \\sigma^2\\left( 1 + \\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)\\end{align}\\] estim√©e par \\[S_{P_0}^2=S^2\\left( 1 + \\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)\\] De plus, \\[\n\\frac{(\\widehat{Y_0} -Y_0)}{S_{P_0}}\\sim\\mathcal{T}(n-2)\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#intervalle-de-pr√©vision-de-y_0-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#intervalle-de-pr√©vision-de-y_0-1",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "8.8 Intervalle de pr√©vision de \\(Y_0\\)",
    "text": "8.8 Intervalle de pr√©vision de \\(Y_0\\)\n\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\n\\[\\frac{(\\widehat{Y_0}-Y_0)}{\\sqrt{S^2\\left(1+\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)}}\\sim\\mathcal{T}(n-2)\\] Intervalle de pr√©diction de \\(Y_0\\) de niveau \\(1-\\delta\\) :\n\\[IP_{1-\\delta}(Y_0)=\\]\n\\[\n\\begin{align}\n&\\left[\\widehat{y_0}-t_{1-\\frac{\\delta}{2}}\\sqrt{s^2\\left(1+\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)};\\right.\\\\\n&\\left.\\widehat{y_0}+t_{1-\\frac{\\delta}{2}}\\sqrt{s^2\\left(1+\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)}\\right]\n\\end{align}\n\\]\no√π \\(t_{1-\\frac{\\delta}{2}}\\) est tel que \\(\\mathbb{P}\\left(\\mid \\mathcal{T}(n-2)\\mid \\leq t_{1-\\frac{\\delta}{2}}\\right)=1-\\delta\\)\n\n\n\n\n\n\n\n\nCautionRemarques\n\n\n\n\\[IC_{1-\\delta}(\\mathbb{E}[Y_0])\\subset\nIP_{1-\\delta}(Y_0)\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#repr√©sentation-intervalle-de-confiance-et-de-pr√©vision",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#repr√©sentation-intervalle-de-confiance-et-de-pr√©vision",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "8.9 Repr√©sentation intervalle de confiance et de pr√©vision",
    "text": "8.9 Repr√©sentation intervalle de confiance et de pr√©vision\n\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#pr√©visions-avec-r",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#pr√©visions-avec-r",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "8.10 Pr√©visions avec R",
    "text": "8.10 Pr√©visions avec R\n\nPr√©diction des \\(\\widehat{y}_i = ax_i+b\\) (utilis√©s pour faire le mod√®le)\n\n\ny_hat &lt;- fitted(modele_reg_simple)\nhead(y_hat)\n\n       1        2        3        4        5        6 \n251.9271 290.8378 285.9740 402.7059 412.4336 427.0251 \n\n\n\nPr√©diction du poids d‚Äôun poisson qui mesurerait 30 cm: pour \\(x_0=30\\)\n\n\nnew_data &lt;- data.frame(Longueur = 30)\n\n\nPr√©diction et intervalle de confiance ( de \\(E[Y_0]\\))\n\n\npredict(modele_reg_simple, new_data,interval=\"confidence\")\n\n       fit      lwr      upr\n1 582.6677 537.0726 628.2628\n\n\n\nPr√©diction et intervalle de pr√©vision ( de \\(Y_0\\))\n\n\npredict(modele_reg_simple, new_data, interval = \"prediction\")\n\n       fit      lwr      upr\n1 582.6677 426.1422 739.1932",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#ce-quil-faut-retenir-de-ce-cours-13-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#ce-quil-faut-retenir-de-ce-cours-13-1",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "8.11 Ce qu‚Äôil faut retenir de ce cours 1/3",
    "text": "8.11 Ce qu‚Äôil faut retenir de ce cours 1/3\n\n\n\n\n\n\nTipLois des estimateurs\n\n\n\n\\[\\frac{(A-\\alpha)}{S_A}\\sim \\mathcal{T}{(n-2)}\\]\n\\[\\frac{(B-\\beta)}{S_B}\\sim \\mathcal{T}{(n-2)}\\]\n\n\n\n\n\n\n\n\nTipEstimateurs du mod√®le\n\n\n\n\\[\\begin{align}\nIC_{1-\\delta}(\\alpha) =& \\left[a-t_{1-\\frac{\\delta}{2}} s_A;a+t_{1-\\frac{\\delta}{2}} s_A\\right]\\\\\nIC_{1-\\delta}(\\beta)=&\\left[b-t_{1-\\frac{\\delta}{2}} s_B;b+t_{1-\\frac{\\delta}{2}} s_B\\right]\\\\\n\\end{align}\\]\n\n\\(s_A = \\sqrt{\\frac{s^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}}\\) et \\(s_B = \\sqrt{s^2\\left(\\frac{1}{n}+\\frac{\\bar{x}^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)}\\)\n\n\n\n\n\n\n\n\n\nNoteTest de Student de la nullit√© de la pente de r√©gression\n\n\n\n\n\\[H_0:\\alpha=0\\]\n\\[H_1:\\alpha\\neq 0\\]\n\n\n\n\n\n\n\n\n\nNoteTest de Fisher de Comparaison de mod√®les\n\n\n\n\\[H_0\\; :\\; \\text{mod√®le}\\; M_1:Y_i=\\beta+E_i\\]\n\\[H_1\\; :\\; \\text{mod√®le}\\; M_2:Y_i=\\alpha x_i+\\beta+E_i\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#ce-quil-faut-retenir-de-ce-cours-23-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#ce-quil-faut-retenir-de-ce-cours-23-1",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "8.12 Ce qu‚Äôil faut retenir de ce cours 2/3",
    "text": "8.12 Ce qu‚Äôil faut retenir de ce cours 2/3\n\n\n\n\n\n\n\nNoteD√©finition : SCT\n\n\n\nLa variabilit√© de \\(Y\\) sans tenir compte du mod√®le.\n\\[\\color{purple}{SCT =\\displaystyle\\sum_{i = 1}^n( Y_i - \\bar{Y})^2}\\]\n\n\n\n\n\n\n\n\nNoteD√©finition : SCM\n\n\n\nPartie de la variabilit√© de \\(Y\\) expliqu√©e par le mod√®le.\n\\[\\color{blue}{SCM = \\displaystyle\\sum_{i=1}^n(\\widehat{Y_i}-\\bar{Y})^2}\\]\n\n\n\n\n\n\n\n\nNoteD√©finition : SCR\n\n\n\nPartie de la variabilit√© de \\(Y\\) qui n‚Äôest pas expliqu√©e par le mod√®le.\n\\[\\color{red}{SCR = \\displaystyle\\sum_{i=1}^n(Y_i-\\widehat{Y_i})^2=\\displaystyle\\sum_{i=1}^n E_i ^2}\\]\n\n\n\n\n\n\n\n\nTipD√©composition de la variance\n\n\n\n\\[\\color{purple}{SCT} = \\color{blue}{SCM} + \\color{red}{SCR} \\]\n\n\n\n\n\n\n\n\nTipTest de Fisher\n\n\n\n\\[T_n=\\frac{SCM/1}{SCR/(n-2)} \\overset{H_0}{\\sim} \\mathcal{F}(1,n-2)\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#ce-quil-faut-retenir-de-ce-cours-33-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#ce-quil-faut-retenir-de-ce-cours-33-1",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "8.13 Ce qu‚Äôil faut retenir de ce cours 3/3",
    "text": "8.13 Ce qu‚Äôil faut retenir de ce cours 3/3\n\n\n\n\n\n\nNoteCoefficient de d√©termination\n\n\n\n\\[R^2 = \\frac{SCM}{SCT}\\]\n\n\n\n\n\n\n\n\nTipIntervalle de confiance de la droite de r√©gression\n\n\n\n\\[IC_{1-\\delta}(\\mathbb{E}[Y_0])= \\] \\[\\begin{align}\n&\\left[\\widehat{y_0}-t_{1-\\frac{\\delta}{2}}\\sqrt{s^2\\left(\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)};\\right.\\\\\n&\\left.\\widehat{y_0}+t_{1-\\frac{\\delta}{2}}\\sqrt{s^2\\left(\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)}\\right]\n\\end{align}\\]\n\n\n\n\n\n\n\n\nTipIntervalle de pr√©vision\n\n\n\n\\[IP_{1-\\delta}(Y_0)=\\]\n\\[\\begin{align}\n&\\left[\\widehat{y_0}-t_{1-\\frac{\\delta}{2}}\\sqrt{s^2\\left(1+\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)};\\right.\\\\\n&\\left.\\widehat{y_0}+t_{1-\\frac{\\delta}{2}}\\sqrt{s^2\\left(1+\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right)}\\right]\n\\end{align}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html",
    "title": "Mod√®le lin√©aire multiple",
    "section": "",
    "text": "WarningObjectif\n\n\n\n\nPeut-on pr√©dire le poids des poissons par leurs largeurs, leurs longueurs et leurs √©paisseurs ?\nTester le caract√®re significatif de la liaison : Y‚Äôa t‚Äôil un lien significatif entre le poids des poissons et leurs largeurs, leurs longueurs et leurs √©paisseurs ?\nY‚Äôa t‚Äôil un lien entre le poids du poisson et sa largeur apr√®s avoir pris en compte sa longueur et son epaisseur ?\n\n\n\n\nDonn√©es On a pour 20 br√®mes p√©ch√©es dans le lac Laengelmavesi en Finland leurs poids (en gramme) et leurs longeurs (en cm), leurs largeurs (en cm) leurs √©paisseur (en cm).",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#probl√©matique-biologique",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#probl√©matique-biologique",
    "title": "Mod√®le lin√©aire multiple",
    "section": "",
    "text": "WarningObjectif\n\n\n\n\nPeut-on pr√©dire le poids des poissons par leurs largeurs, leurs longueurs et leurs √©paisseurs ?\nTester le caract√®re significatif de la liaison : Y‚Äôa t‚Äôil un lien significatif entre le poids des poissons et leurs largeurs, leurs longueurs et leurs √©paisseurs ?\nY‚Äôa t‚Äôil un lien entre le poids du poisson et sa largeur apr√®s avoir pris en compte sa longueur et son epaisseur ?\n\n\n\n\nDonn√©es On a pour 20 br√®mes p√©ch√©es dans le lac Laengelmavesi en Finland leurs poids (en gramme) et leurs longeurs (en cm), leurs largeurs (en cm) leurs √©paisseur (en cm).",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#√©criture-du-mod√®le",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#√©criture-du-mod√®le",
    "title": "Mod√®le lin√©aire multiple",
    "section": "1.1 √âcriture du mod√®le",
    "text": "1.1 √âcriture du mod√®le\n\n1.1.0.1 Notations\n\nOn a \\(n = 20\\) observations. On note, pour \\(1 \\leq i \\leq 20\\)\n\n\\(x_{1,i}\\) la mesure de la longueur du poisson \\(i\\).\n\\(x_{2,i}\\) la mesure de la largeure du poisson \\(i\\).\n\\(x_{3,i}\\) la mesure de l‚Äôepaisseur du poisson \\(i\\).\n\\(y_i\\) la mesure du poids du poisson \\(i\\).\n\n\n\n\n\n\n\nNoteD√©finition : Mod√®le de r√©gression lin√©aire multiple\n\n\n\nOn suppose que \\(y_i\\) est la r√©alisation d‚Äôune variable al√©atoire \\(Y_i\\) telle que: \\[Y_i = \\alpha_1 x_{1,i} + \\alpha_2 x_{2,i} + \\alpha_3 x_{3,i} + \\beta  + E_i,\\quad 1 \\leq i \\leq n\\]\n\n\\(\\alpha_1\\) (resp \\(\\alpha_2\\) , \\(\\alpha_3\\) ) est un param√®tre inconnu, l‚Äôeffet de la longueur (resp largeur, √©paisseur) sur le poids;\n\\(\\beta\\) est un param√®tre inconnu;\n\\(E_i\\) une variable al√©atoire, \\(E_i \\overset{i.i.d.}\\sim \\mathcal{N}(0, \\sigma^2)\\)\nLes \\(x_i\\) sont lin√©airement ind√©pendants",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#√©criture-plus-g√©n√©rale-du-mod√®le",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#√©criture-plus-g√©n√©rale-du-mod√®le",
    "title": "Mod√®le lin√©aire multiple",
    "section": "1.2 √âcriture plus g√©n√©rale du mod√®le",
    "text": "1.2 √âcriture plus g√©n√©rale du mod√®le\n\n1.2.0.1 Notations\n\nOn a \\(n = 20\\) observations. On note, pour \\(1 \\leq i \\leq 20\\)\n\n\\(x_{1}, \\dots, x_{p}\\), \\(p\\) variables explicatives et \\(y\\) une variable r√©ponse\n\\(y_i\\) la mesure de la variable r√©ponse de l‚Äôindividu \\(i\\).\n\\(\\forall j \\in \\{ 1,\\dots, p \\}\\), \\(x_{j,i}\\) la valeur de la variable \\(x_j\\) de l‚Äôindividu \\(i\\)\n\n\n\n\n\n\n\nNoteD√©finition : Mod√®le de r√©gression lin√©aire multiple\n\n\n\nOn suppose que \\(y_i\\) est la r√©alisation d‚Äôune variable al√©atoire \\(Y_i\\) telle que: \\[Y_i = \\sum_{j=1}^p \\alpha_j x_{j,i} + \\beta  + E_i,\\quad 1 \\leq i \\leq n\\]\n\n\\(\\alpha_j\\) est un param√®tre inconnu, l‚Äôeffet de la variable \\(x_j\\) sur le y;\n\\(\\beta\\) est un param√®tre inconnu\n\\(E_i\\) une variable al√©atoire, \\(E_i \\overset{i.i.d.}\\sim \\mathcal{N}(0, \\sigma^2)\\)\nLes \\(x_i\\) sont lin√©airement ind√©pendants (en pratique v√©rifier avec le VIF)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#deux-√©critures-√©quivalentes",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#deux-√©critures-√©quivalentes",
    "title": "Mod√®le lin√©aire multiple",
    "section": "1.3 Deux √©critures √©quivalentes",
    "text": "1.3 Deux √©critures √©quivalentes\n\n\n\n\n\n\nCautionRemarques\n\n\n\nLes deux mod√®les suivant sont √©quivalent :\n\n\\(\\forall i \\in \\{1, \\dots, n\\} \\;\\;\\)\n\n\\[ Y_i = \\sum_{j=1}^p \\alpha_j x_{j,i} + \\beta  + E_i,\\quad  \\ E_i \\overset{i.i.d.}\\sim \\mathcal{N}(0, \\sigma^2)\\]\n\n\\(\\forall i \\in \\{1, \\dots, n\\} \\;\\;\\)\n\n\\[ Y_i \\overset{i.i.d.}\\sim \\mathcal{N}\\left(\\sum_{j=1}^p \\alpha_j x_{j,i} + \\beta, \\sigma^2\\right)\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#dans-lexemple-des-poissons",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#dans-lexemple-des-poissons",
    "title": "Mod√®le lin√©aire multiple",
    "section": "1.4 Dans l‚Äôexemple des poissons",
    "text": "1.4 Dans l‚Äôexemple des poissons\n\n\n\n\n\n\nCautionRemarques\n\n\n\nLes deux mod√®les suivant sont √©quivalent :\n\n\\(\\forall i \\in \\{1, \\dots, n\\} \\;\\;\\) \\[ Y_i = \\alpha_1 x_{1,i} + \\alpha_2 x_{2,i} + \\alpha_3 x_{3,i} + \\beta  + E_i,\\quad  \\ E_i \\overset{i.i.d.}\\sim \\mathcal{N}(0, \\sigma^2)\\]\n\\(\\forall i \\in \\{1, \\dots, n\\} \\;\\;\\) \\[Y_i \\overset{i.i.d.}\\sim \\mathcal{N}\\left(\\alpha_1 x_{1,i} + \\alpha_2 x_{2,i} + \\alpha_3 x_{3,i} + \\beta, \\sigma^2\\right)\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#remarques-sur-les-param√®tres",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#remarques-sur-les-param√®tres",
    "title": "Mod√®le lin√©aire multiple",
    "section": "1.5 Remarques sur les param√®tres",
    "text": "1.5 Remarques sur les param√®tres\n\n\n\n\n\n\n\nCautionRemarques\n\n\n\nDans le mod√®le \\(\\forall i \\in \\{1, \\dots, n\\} \\;\\;\\) \\[ Y_i = \\sum_{j=1}^p \\alpha_j x_{j,i} + \\beta  + E_i,\\quad\\ E_i \\overset{i.i.d.}\\sim \\mathcal{N}(0, \\sigma^2)\\]\n\n\\(\\alpha_j\\) repr√©sente l‚Äôaccroissement de \\(Y_i\\) correspondant √† l‚Äôaccroissement d‚Äôune unit√© sur \\(x_j\\) si les autres variables explicatives sont fix√©es. Dans l‚Äôexemple des poissons : \\(\\alpha_1\\) represente l‚Äôaccroissement du poids correspondant √† l‚Äôaccroissement d‚Äô1 cm sur la longeurs du poisson si la largeur et l‚Äô√©paisseur son fix√©.\nCe mod√®le est de dimension \\(p + 1\\). (Avec \\(p+1\\) param√®tres d‚Äôesp√©rance √† estimer \\(p\\) pour \\(\\alpha\\) et \\(1\\) pour\\(\\beta\\))\n\\(\\forall i \\in \\{1, \\dots, n\\}\\) \\(Y_i\\) se d√©compose en \\(\\color{red}{Y_i} = {\\color{blue}{\\underbrace{\\displaystyle\\sum_{j=1}^p \\alpha_j x_{j,i} + \\beta}_{{d√©terministe}{}}}}  + \\color{red}{\\overbrace{E_i}^{al√©atoire}}\\)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#rappel-sur-les-matrices",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#rappel-sur-les-matrices",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.1 Rappel sur les matrices",
    "text": "2.1 Rappel sur les matrices\n\nQu‚Äôest ce qu‚Äôune matrice ?\nLa multiplication matricielle\nLa transpos√©e d‚Äôune matrice\nL‚Äôinverse d‚Äôune matrice\nPetits topo sur les vecteurs",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#rappels-dalg√®bre",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#rappels-dalg√®bre",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.2 Rappels d‚Äôalg√®bre",
    "text": "2.2 Rappels d‚Äôalg√®bre\n\n\n\n\n\n\n\n\n\nNoteRappel : Matrice\n\n\n\n\\(A = (a_{i,j})_{1\\leq i \\leq p, 1\\leq j \\leq q}\\) est une matrice √† coefficients r√©els de format \\((p \\times q)\\)\n\\[A = \\begin{bmatrix}\na_{11} & a_{12} & \\ldots & a_{1q}\\\\\na_{21} & a_{22} & \\ldots & a_{2q}\\\\\n\\vdots & \\vdots & & \\vdots \\\\\na_{p1} & a_{p2} & \\ldots & a_{pq}\n\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\n\nNoteRappel : Transpos√©e d‚Äôune matrice\n\n\n\nSi \\(A = (a_{i,j})_{1\\leq i \\leq p, 1\\leq j \\leq q}\\) est une matrice \\((p \\times q)\\), on note alors \\(A^t\\) sa transpos√©e, la matrice \\((q \\times p)\\) d√©finie par\n\\[A^t = \\begin{bmatrix}\na_{11} & a_{21} & \\ldots & a_{p1}\\\\\na_{12} & a_{22} & \\ldots & a_{p2}\\\\\n\\vdots & \\vdots & & \\vdots \\\\\na_{1q} & a_{2q} & \\ldots & a_{pq}\n\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteRappel : Matrice sym√©trique\n\n\n\n\\(A\\) est une matrice sym√©trique si :\n\n\\(A\\) est une matrice carr√© (\\(p=q\\))\n\\(A^t = A\\)\n\n\n\n\n\n\n\n\n\n\nNoteRappel : Transpos√©e du produit\n\n\n\nSoit \\(A\\) et \\(B\\) deux matrices. On a\n\\[ (A  B)^t  = B^t A^t\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#rappels-dalg√®bre-vecteur",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#rappels-dalg√®bre-vecteur",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.3 Rappels d‚Äôalg√®bre : Vecteur",
    "text": "2.3 Rappels d‚Äôalg√®bre : Vecteur\n\n\n\n\n\n\nNoteRappel : Vecteurs\n\n\n\n\nOn note V un vecteur √† \\(p\\) √©l√©ments par\n\n\\[V = \\begin{bmatrix} v_{1} \\\\ v_{2}\\\\ \\vdots \\\\ v_{p} \\end{bmatrix}= \\left[{v_1, v_2, \\ldots, v_p}\\right]^t \\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#rappels-dalg√®bre-vecteur-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#rappels-dalg√®bre-vecteur-1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.4 Rappels d‚Äôalg√®bre : Vecteur",
    "text": "2.4 Rappels d‚Äôalg√®bre : Vecteur\n\n\n\n\n\n\nNoteRappel : Produit matrice-vecteur\n\n\n\nSi \\(V\\) est un vecteur √† \\(q\\) √©l√©ments et \\(A\\) une matrice \\((p \\times q)\\) alors, \\(U=AV\\) est un vecteur √† \\(p\\) √©l√©ments\n\\[ \\begin{bmatrix} u_{1} \\\\ u_{2}\\\\ \\vdots \\\\ u_{p} \\end{bmatrix} = AV =\n\\begin{bmatrix}\na_{11} & a_{12} & \\ldots & a_{1q}\\\\\na_{21} & a_{22} & \\ldots & a_{2q}\\\\\n\\vdots & \\vdots & & \\vdots \\\\\na_{p1} & a_{p2} & \\ldots & a_{pq}\n\\end{bmatrix}\\begin{bmatrix} v_{1} \\\\ v_{2}\\\\ \\vdots \\\\ v_{p} \\end{bmatrix} = \\begin{bmatrix}  \\sum_{j=1}^{q} a_{1j} v_j \\\\ \\sum_{j=1}^{q} a_{2j} v_j\\\\ \\vdots \\\\\n\\sum_{j=1}^{q} a_{pj} \\end{bmatrix}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#rappels-dalg√®bre-identit√©-et-inverse",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#rappels-dalg√®bre-identit√©-et-inverse",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.5 Rappels d‚Äôalg√®bre : Identit√© et inverse",
    "text": "2.5 Rappels d‚Äôalg√®bre : Identit√© et inverse\n\n\n\n\n\n\n\nNoteRappel : matrice identit√©\n\n\n\nLa matrice identit√© \\(I_n\\) est la matrice carr√© √† \\(n\\) lignes et \\(n\\) colonnes, dont les coefficients diagonaux valent \\(1\\) et les autres valent \\(0\\).\n\\[I_n =  \\begin{bmatrix}\n1 & 0 & \\ldots & 0\\\\\n0 & 1 & \\ldots & 0\\\\\n\\vdots & \\vdots & & \\vdots \\\\\n0 & 0 & \\ldots & 1\n\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\n\n\nNoteRappel : Inverse d‚Äôune matrice\n\n\n\nSi \\(A = (a_{i,j})_{1\\leq i \\leq p, 1\\leq j \\leq p}\\) est une matrice carr√©e \\((p \\times p)\\) inversible, alors on note son inverse \\(A^{-1}\\) la matrice \\((p \\times p)\\) telle que\n\\[A\\,A^{-1} = A^{-1}\\,A = I_p \\]\n\n\n\n\n\n\n\n\n\nNoteRappel : Transpos√©e de l‚Äôinverse\n\n\n\nSi \\(A\\) est une matrice inversible, alors\n\\[(A^{-1})^t=(A^t)^{-1}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#vecteurs-al√©atoires",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#vecteurs-al√©atoires",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.6 Vecteurs al√©atoires",
    "text": "2.6 Vecteurs al√©atoires\n\n\n\n\n\n\n\nNoteRappel : Vecteurs al√©atoires\n\n\n\nSoient \\(V_1,V_2,\\dots,V_n\\), \\(n\\) variables al√©atoires r√©elles, alors\n\\[V = \\begin{bmatrix} V_1 \\\\ V_2 \\\\ \\vdots \\\\ V_n \\end{bmatrix} \\]\n\n\n\n\n\n\n\n\n\n\nNoteRappel : Esp√©rance d‚Äôun vecteur al√©atoire\n\n\n\n\\(V\\) a pour esp√©rance\n\\[\\mathbb{E}[V] =  \\begin{bmatrix} \\mathbb{E}[V_1] \\\\ \\mathbb{E}[V_2] \\\\ \\vdots \\\\ \\mathbb{E}[V_n] \\end{bmatrix}\\]\n\n\n\n\n\n\n\n\n\nNoteRappel : Matrice de variance-covariance\n\n\n\n\\(V\\) a pour matrice de variance-covariance (sym√©trique)\n\\[\\mathbb{V}[V] = \\mathbb{E}\\left[\\left(V- \\mathbb{E}[V] \\right)\\left(V- \\mathbb{E}[V] \\right)^t \\right] =\\]\n\n\\[\\begin{bmatrix} \\mathbb{V}[V_1] & cov(V_1,V_2) & \\dots& Cov(V_1,V_n) \\\\\ncov(V_2,V_1) & \\mathbb{V}[V_2] & \\dots& Cov(V_2,V_n) \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n  cov(V_n,V_1) & cov(V_n,V_2) & \\dots&  \\mathbb{V}[V_n]\\end{bmatrix}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#propri√©t√©s",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#propri√©t√©s",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.7 Propri√©t√©s",
    "text": "2.7 Propri√©t√©s\n\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\nSoient \\(\\color{blue}{A}\\) et \\(\\color{blue}{B}\\) des matrices √† coefficients non al√©atoires et soit \\(\\color{red}{V}\\) un vecteur al√©atoire, alors\n\\[\\begin{align}\n\\mathbb{E}[\\color{blue}{A}\\color{red}{V}\\color{blue}{B}] &= \\color{blue}{A} \\mathbb{E}[\\color{red}{V}]\\color{blue}{B}\\\\\n\\mathbb{V}[\\color{blue}{A}\\color{red}{V}] & = \\color{blue}{A} \\mathbb{V}[\\color{red}{V}] \\color{blue}{A^t}\n\\end{align}\\]\n\n\n\n\n\n\n\n\nNoteRappel : Vecteurs gaussiens\n\n\n\nSi \\(V_1, V_2, \\ldots, V_n\\) sont gaussiennes et ind√©pendantes, alors \\(V = [V_1, \\ldots, V_n]^t\\) est un vecteur gaussien.\nSi \\(V_1, V_2, \\ldots, V_n \\overset{i.i.d}\\sim \\mathcal{N}(0,\\sigma ^2)\\), alors\n\\[V \\sim \\mathcal{N}\\left(\\vec{0}_n,\\,\\sigma^2 I_n\\right)\\] o√π \\(I_n\\) est la matrice identit√© d‚Äôordre \\(n\\).",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#√©criture-matricielle-du-mod√®le-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#√©criture-matricielle-du-mod√®le-1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.8 √âcriture matricielle du mod√®le",
    "text": "2.8 √âcriture matricielle du mod√®le\n\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\n\\[\\left\\{\\begin{matrix}\nY_1  =  \\beta\\ +\\ \\alpha_1\\,x_{1,1}\\ +\\ \\alpha_2\\,x_{2,1}\\ +\\\n\\ldots\\ +\\ \\alpha_{p}\\,x_{p, 1}\\ +\\ E_1\\\\\nY_2  =  \\beta\\ +\\ \\alpha_1\\,x_{1, 2}\\ +\\ \\alpha_2\\,x_{2,2}\\ +\\\n\\ldots\\ +\\ \\alpha_{p}\\,x_{p, 2}\\ +\\ E_2\\\\\n\\vdots   \\\\\nY_n  =  \\beta\\ +\\ \\alpha_1\\,x_{1,n}\\ +\\ \\alpha_2\\,x_{2, n}\\ +\\\n\\ldots\\ +\\ \\alpha_{p}\\,x_{p,n}\\ +\\ E_n \\end{matrix} \\right.\\]\npeut se r√©√©crire sous la forme\n\\[ Y = X \\theta + E \\]\navec\n\\[Y =\\begin{bmatrix} Y_1\\\\ Y_2\\\\ \\vdots \\\\ Y_n\\end{bmatrix},\\quad  X = \\begin{bmatrix}\n1 & x_{1,1} & \\ldots & x_{p, 1}\\\\\n1 & x_{1, 2} & \\ldots & x_{p, 2}\\\\\n\\vdots & \\vdots & & \\vdots \\\\\n1 & x_{1, n} & \\ldots & x_{p, n}\n\\end{bmatrix},\\quad \\theta = \\begin{bmatrix} \\beta\\\\ \\alpha_1\\\\\n\\alpha_2\\\\ \\vdots \\\\ \\alpha_{p}\\end{bmatrix},\\quad E = \\begin{bmatrix}E_1\\\\\nE_2\\\\ \\vdots \\\\ E_n\\end{bmatrix}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#√©criture-matricielle-du-mod√®le-2",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#√©criture-matricielle-du-mod√®le-2",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.9 √âcriture matricielle du mod√®le",
    "text": "2.9 √âcriture matricielle du mod√®le\n\n\n\n\n\n\n\nTipPropri√©t√©\n\n\n\n\n\\(X\\) est de taille \\(n\\times (p+1)\\)\n\\(\\theta\\) est de dimension \\((p+1)\\times 1\\) : vecteur des param√®tres d‚Äôesp√©rance\n\\(E\\) est de dimension \\((n\\times 1)\\) : est un vecteur Gaussien tel que\n\n\\[E \\sim \\mathcal{N}\\left(\\vec{0}_n,\\,\\sigma^2 I_n\\right) \\]\n\n\\(Y\\) est de dimension \\((n\\times 1)\\) : est un vecteur Gaussien tel que\n\n\\[ Y \\sim \\mathcal{N}\\left(X\\theta,\\,\\sigma^2 I_n\\right)\\]\n\n\n\n\n\n\n\n\nCautionRemarques\n\n\n\nSi les vecteurs colonnes de \\(X\\) sont lin√©airement ind√©pendants, \\(X\\) est de rang \\(p+1\\) et \\(X^t X\\) est inversible.",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#exercice-√©crire-le-mod√®le-lin√©aire-univari√©-sous-forme-matricielle",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#exercice-√©crire-le-mod√®le-lin√©aire-univari√©-sous-forme-matricielle",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.10 Exercice : √©crire le mod√®le lin√©aire univari√© sous forme matricielle",
    "text": "2.10 Exercice : √©crire le mod√®le lin√©aire univari√© sous forme matricielle",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#correction",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#correction",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.11 Correction",
    "text": "2.11 Correction\nLe mod√®le de r√©gression simple \\[Y_i=\\alpha x_i+\\beta+E_i\\] s‚Äô√©crit matriciellement \\(Y=X\\theta+E\\) avec \\[Y = \\begin{bmatrix} Y_1\\\\ Y_2\\\\ \\vdots \\\\ Y_n\\end{bmatrix},\\quad\nX =  \\begin{bmatrix}\n1 & x_{1} \\\\\n1 & x_{2} \\\\\n\\vdots & \\\\\n1 & x_{n} \\\\\n\\end{bmatrix},\\quad\n\\theta\\ =\\  \\begin{bmatrix}\\beta\\\\ \\alpha\\end{bmatrix},\\quad\nE\\ =\\  \\begin{bmatrix} E_1\\\\\nE_2\\\\ \\vdots \\\\ E_n\\end{bmatrix}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#√©criture-du-mod√®le-lin√©aire-simple",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#√©criture-du-mod√®le-lin√©aire-simple",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.12 √âcriture du mod√®le lin√©aire simple",
    "text": "2.12 √âcriture du mod√®le lin√©aire simple\n\n\n\n\n\n\n\nTipPropri√©t√©\n\n\n\n\n\\(X\\) est de taille \\((n\\times 2)\\)\n\\(\\theta\\) est de dimension \\((2 \\times 1)\\) : vecteur des param√®tres d‚Äôesp√©rance\n\\(E\\) est de dimension \\((n\\times 1)\\) : est un vecteur Gaussien tel que\n\n\\[E \\sim \\mathcal{N}\\left(\\vec{0}_n,\\,\\sigma^2 I_n\\right) \\]\n\n\\(Y\\) est de dimension \\((n\\times 1)\\) : est un vecteur Gaussien tel que\n\n\\[ Y \\sim \\mathcal{N}\\left(X\\theta,\\,\\sigma^2 I_n\\right)\\]\n\n\n\n\n\n\n\n\nCautionRemarques\n\n\n\nSi les \\(x_i\\) ne sont pas tous √©gaux, les deux vecteurs colonnes de \\(X\\) sont lin√©airement ind√©pendants et \\(X\\) est de rang \\(p = 2\\).",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#exemple-sur-les-poissons",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#exemple-sur-les-poissons",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.13 Exemple sur les poissons",
    "text": "2.13 Exemple sur les poissons\n\n2.13.0.1 Notations\n\nOn a \\(n = 20\\) observations. On note, pour \\(1 \\leq i \\leq 20\\)\n\n\\(x_{1,i}\\) la mesure de la longueur du poisson \\(i\\).\n\\(x_{2,i}\\) la mesure de la largeure du poisson \\(i\\).\n\\(x_{3,i}\\) la mesure de l‚Äôepaisseur du poisson \\(i\\).\n\\(y_i\\) la mesure du poids du poisson \\(i\\).\n\n\n\n\n\n\n\nNoteD√©finition : Mod√®le de r√©gression lin√©aire multiple\n\n\n\nOn suppose que \\(y_i\\) est la r√©alisation d‚Äôune variable al√©atoire \\(Y_i\\) telle que: \\[Y_i = \\alpha_1 x_{1,i} + \\alpha_2 x_{2,i} + \\alpha_3 x_{3,i} + \\beta  + E_i,\\quad 1 \\leq i \\leq n\\]\n\n\\(\\alpha_1\\) (resp \\(\\alpha_2\\) , \\(\\alpha_3\\) ) est un param√®tre inconnu, l‚Äôeffet de la longueur (resp largeur, √©paisseur) sur le poids;\n\\(\\beta\\) est un param√®tre inconnu;\n\\(E_i\\) une variable al√©atoire, \\(E_i \\overset{i.i.d.}\\sim \\mathcal{N}(0, \\sigma^2)\\)\nLes \\(x_i\\) sont lin√©airement ind√©pendants",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#comment-√©crire-le-mod√®le",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#comment-√©crire-le-mod√®le",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.14 Comment √©crire le mod√®le :",
    "text": "2.14 Comment √©crire le mod√®le :\n\\[\\left\\{\\begin{matrix}\nY_1  =  \\beta\\ +\\ \\alpha_1\\,x_{1,1}\\ +\\ \\alpha_2\\,x_{2,1}\\\n+\\ \\alpha_{3}\\,x_{3, 1}\\ +\\ E_1\\\\\nY_2  =  \\beta\\ +\\ \\alpha_1\\,x_{1, 2}\\ +\\ \\alpha_2\\,x_{2,2}\\ +\\\n\\alpha_{3}\\,x_{3, 2}\\ +\\ E_2\\\\\n\\vdots   \\\\\nY_n  =  \\beta\\ +\\ \\alpha_1\\,x_{1,n}\\ +\\ \\alpha_2\\,x_{2, n}\\ +\\\n\\alpha_{3}\\,x_{3,n}\\ +\\ E_n \\end{matrix} \\right.\\]\npeut se r√©√©crire sous la forme\n\\[ Y = X \\theta + E \\]\navec\n\\[Y =\\begin{bmatrix} Y_1\\\\ Y_2\\\\ \\vdots \\\\ Y_n\\end{bmatrix},\\quad  X = \\begin{bmatrix}\n1 & x_{1,1} & x_{2,1} & x_{3, 1}\\\\\n1 & x_{1, 2} & x_{2,1} & x_{3, 2}\\\\\n\\vdots & \\vdots & & \\vdots \\\\\n1 & x_{1, n} & x_{2,1} & x_{3, n}\n\\end{bmatrix},\\quad \\theta = \\begin{bmatrix} \\beta\\\\ \\alpha_1\\\\\n\\alpha_2\\\\ \\alpha_{3}\\end{bmatrix},\\quad E = \\begin{bmatrix}E_1\\\\\nE_2\\\\ \\vdots \\\\ E_n\\end{bmatrix}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#avec-les-donn√©es",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#avec-les-donn√©es",
    "title": "Mod√®le lin√©aire multiple",
    "section": "2.15 Avec les donn√©es :",
    "text": "2.15 Avec les donn√©es :\n\\[X = \\]\n\n\n\nIntercept\nLength1\nHeight\nWidth\n\n\n\n\n1\n23.2\n11.5200\n4.0200\n\n\n1\n24.0\n12.4800\n4.3056\n\n\n1\n23.9\n12.3778\n4.6961\n\n\n1\n26.3\n12.7300\n4.4555\n\n\n1\n26.5\n12.4440\n5.1340\n\n\n1\n26.8\n13.6024\n4.9274\n\n\n1\n26.8\n14.1795\n5.2785\n\n\n1\n27.6\n12.6700\n4.6900\n\n\n1\n27.6\n14.0049\n4.8438\n\n\n1\n28.5\n14.2266\n4.9594",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#estimateurs-des-moindres-carr√©s",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#estimateurs-des-moindres-carr√©s",
    "title": "Mod√®le lin√©aire multiple",
    "section": "3.1 Estimateurs des moindres carr√©s",
    "text": "3.1 Estimateurs des moindres carr√©s\n\n\n\n\n\n\nWarningObjectif\n\n\n\nOn note \\(\\theta= [\\beta,\\alpha_1,...,\\alpha_p]^t\\).\nComme dans la regression lin√©aire simple on cherche √† minimiser :\n\\[J(\\theta) = \\sum_{i = 1}^n \\left( y_i -(\\beta +  \\sum_{j=1}^p \\alpha _j x_{j,i}) \\right)^2\\] √âcriture matricielle ?",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#rappels-dalg√®bre-norme",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#rappels-dalg√®bre-norme",
    "title": "Mod√®le lin√©aire multiple",
    "section": "3.2 Rappels d‚Äôalg√®bre : norme",
    "text": "3.2 Rappels d‚Äôalg√®bre : norme\n\n\n\n\n\n\n\nNoteRappel : norme\n\n\n\nSoit \\[V\\ =\\ \\begin{bmatrix} v_{1} \\\\ v_{2}\\\\ \\vdots \\\\ v_{n}\\end{bmatrix}\n\\ =\\ [v_1, \\ldots, v_n]^t\\] un vecteur de \\(\\mathbb{R}^n\\). On appelle norme de \\(V\\) le r√©el\n\\[\\displaystyle V^t V \\ =\\ \\sum_{i=1}^{n} v_i^2\\ =\\ ||V||^2 \\]\n\n\n\n\n\n\n\n\nCautionRemarque\n\n\n\n\\[V^t V \\neq V V^t\\]\n\\[V V^t = \\begin{bmatrix} v_1^2 & v_1\\,v_2 & \\ldots & v_1\\,v_n\\\\\nv_2\\,v_1 & v_2^2 & \\ldots & v_2\\,v_n\\\\\n\\vdots & \\vdots & & \\vdots \\\\\nv_n\\,v_1 & v_n\\,v_2 & \\ldots & v_n^2 \\end{bmatrix}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#estimateurs-des-moindres-carr√©s-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#estimateurs-des-moindres-carr√©s-1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "3.3 Estimateurs des moindres carr√©s",
    "text": "3.3 Estimateurs des moindres carr√©s\n\n\n\n\n\n\n\nWarningObjectif\n\n\n\nOn souhaite trouver \\(\\theta= (\\beta,\\alpha_1,...\\alpha_p)^t\\) qui minimise\n\\[J(\\theta)=\\sum_{i = 1}^n \\left( y_i -(\\beta +  \\sum_{j=1}^p \\alpha _j x_{j,i}) \\right)^2 = (Y-X\\theta)^t(Y-X\\theta) = ||Y-X\\theta||^2\\]\n\n\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\nLe \\(\\theta\\) optimal est la solution du syst√®me de \\(p+1\\) √©quations √† \\(p+1\\) inconnues\n\\[\n\\left\\{\\begin{array}{ccc}\n\\frac{\\partial \\sum_{i = 1}^n \\left( y_i -(\\beta +  \\sum_{j=1}^p \\alpha _j x_{j,i}) \\right)^2 }{\\partial \\beta} & = & 0 \\\\\n%\n\\frac{\\partial \\sum_{i = 1}^n \\left( y_i -(\\beta +  \\sum_{j=1}^p \\alpha _j x_{j,i}) \\right)^2 }{\\partial \\alpha_1} & = & 0\\\\\n\\vdots & & \\\\\n\\frac{\\partial \\sum_{i = 1}^n \\left( y_i -(\\beta +  \\sum_{j=1}^p \\alpha _j x_{j,i}) \\right)^2 }{\\partial \\alpha_p} & = & 0\n\\end{array}\\right.\n\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#√†-la-recherche-de-widehattheta",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#√†-la-recherche-de-widehattheta",
    "title": "Mod√®le lin√©aire multiple",
    "section": "3.4 √Ä la recherche de \\(\\widehat{\\theta}\\)",
    "text": "3.4 √Ä la recherche de \\(\\widehat{\\theta}\\)\n\\[\\widehat{\\theta} = \\underset{\\theta\\in\\mathbb{R}^{p+1}}{argmin} (Y-X\\theta)^t(Y-X\\theta) =\\underset{\\theta\\in\\mathbb{R}^{p+1}}{argmin} ||Y-X\\theta||^2\\]\n\\(\\widehat{\\theta} = [B,A_1, \\dots, A_p]^t\\) o√π \\(B\\) est l‚Äôestimateur de \\(\\beta\\) et \\(A_j\\) l‚Äôestimateur de \\(\\alpha_j\\)\n\\[\\begin{align}\n(Y-X\\theta)^t(Y-X\\theta) &= (Y^t-\\theta^tX^t)(Y-X\\theta)\\\\\n&= Y^tY - Y^tX\\theta  -\\theta^tX^t Y -\\theta^tX^tX\\theta \\\\\n&= Y^tY - 2 Y^tX\\theta -\\theta^tX^tX\\theta\n\\end{align}\\]\nEn d√©rivant par rapport √† \\(\\theta\\) on obtient : \\[-2Y^tX + 2\\theta^tX^tX \\] Le syst√®me \\(-2Y^tX + 2\\theta^tX^tX=0\\) est bien le m√™me que les \\(p+1\\) equations de la slide pr√©c√©dente",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#√†-la-recherche-de-widehattheta-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#√†-la-recherche-de-widehattheta-1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "3.5 √Ä la recherche de \\(\\widehat{\\theta}\\)",
    "text": "3.5 √Ä la recherche de \\(\\widehat{\\theta}\\)\n\\[\\begin{align}\n-2Y^tX + 2\\widehat{\\theta}^tX^tX = 0 &\\iff \\widehat{\\theta}^tX^tX  =  Y^tX  \\\\\n\\iff X^tX  \\widehat{\\theta}   =  X^tY   & \\iff \\widehat{\\theta} = (X^tX)^{-1}  X^tY\n\\end{align}\\]\n\n\n\n\n\n\nCautionRemarques\n\n\n\n\\(X\\) est de rang \\(p+1\\) donc \\(X^tX\\) est inversible.\n\n\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\n\\[\\widehat{\\theta} =\\underset{\\theta\\in\\mathbb{R}^{p+1}}{argmin} ||Y-X\\theta||^2\\] a pour solution\n\\[\\widehat{\\theta} = (X^tX)^{-1}  X^tY\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#estimateurs-des-param√®tres-desp√©rance",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#estimateurs-des-param√®tres-desp√©rance",
    "title": "Mod√®le lin√©aire multiple",
    "section": "3.6 Estimateurs des param√®tres d‚Äôesp√©rance",
    "text": "3.6 Estimateurs des param√®tres d‚Äôesp√©rance\n\n\n\n\n\n\n\nWarningObjectif : Estimateur des moindres carr√©s de \\(\\theta\\)\n\n\n\n\\[\\widehat{\\theta}  =\\underset{\\theta\\in\\mathbb{R}^{p+1}}{argmin} ||Y-X\\theta||^2\\]\n\n\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\n\nSi \\(\\hat{\\theta}= [B, A_1, \\ldots, A_{p}]^t\\) est solution du syst√®me et que \\((X^t\\,X)\\) est inversible, alors\n\n\\[\\hat{\\theta}=(X^t\\,X)^{-1}\\,X^t\\,Y\\]\n\n\n\n\n\n\n\n\nParam√®tres\nEstimateurs\nEstimations\n\n\n\n\n\\([\\beta,\\alpha_1,...\\alpha_p]\\)\n\\([B, A_1, \\ldots, A_{p}]\\)\n\\([b,a_1,\\cdots,a_p]\\)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#les-4-graphiques",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#les-4-graphiques",
    "title": "Mod√®le lin√©aire multiple",
    "section": "4.1 Les 4 graphiques",
    "text": "4.1 Les 4 graphiques\n\nfish &lt;- read.table(file = \"Fish.csv\",\n                   sep =\",\", header = TRUE) %&gt;% filter(Species == \"Bream\") \n\n\nmod &lt;- lm(Weight ~Length1 + Height + Width , data =  fish)\npar(mfrow=c(2,2))\nplot(mod)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#multicolin√©arit√©-des-x_i",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#multicolin√©arit√©-des-x_i",
    "title": "Mod√®le lin√©aire multiple",
    "section": "4.2 Multicolin√©arit√© des \\(x_i\\)",
    "text": "4.2 Multicolin√©arit√© des \\(x_i\\)\nOn v√©rifie la corr√©lation entre les \\(x_i\\)\n\nlibrary(corrplot)\n\ncorrplot 0.95 loaded\n\nM = cor(fish[c(\"Length1\",\"Height\",\"Width\",\"Weight\")])\ncorrplot.mixed(M)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#v√©rification-avec-le-vif",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#v√©rification-avec-le-vif",
    "title": "Mod√®le lin√©aire multiple",
    "section": "4.3 V√©rification avec le VIF",
    "text": "4.3 V√©rification avec le VIF\n\n\n\n\n\n\nNoteD√©finition : VIF\n\n\n\n\\[\n  VIF(x_i) = \\frac{1}{1-R^2(x_i)}\n\\] o√π \\(R^2(x_i)\\) est le \\(R^2\\) du mod√®le lin√©aire dans lequel on explique \\(x_i\\) par toutes les autres covariables (\\(x_j\\))",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#exemple-du-vif-sur-les-poissons",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#exemple-du-vif-sur-les-poissons",
    "title": "Mod√®le lin√©aire multiple",
    "section": "4.4 Exemple du VIF sur les poissons :",
    "text": "4.4 Exemple du VIF sur les poissons :\nCalcul ‚Äò√† la main‚Äô\n\nmod_length&lt;- lm(Length1 ~ Height + Width , data =  fish)\nvif_length &lt;- 1/ ( 1-summary(mod_length)$r.squared)\n\nAvec la fonction VIF :\n\nlibrary(car)\n\nLe chargement a n√©cessit√© le package : carData\n\n\n\nAttachement du package : 'car'\n\n\nL'objet suivant est masqu√© depuis 'package:dplyr':\n\n    recode\n\n\nL'objet suivant est masqu√© depuis 'package:purrr':\n\n    some\n\nvif(mod)\n\n  Length1    Height     Width \n 8.952978 12.123683  7.451746 \n\n\nEn pratique : on retire les covariales qui ont un VIF sup√©rieur √† 10 (ou 5 si on veut √™tre plus strict)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#estimations-des-param√®tres-sur-notre-exemple",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#estimations-des-param√®tres-sur-notre-exemple",
    "title": "Mod√®le lin√©aire multiple",
    "section": "4.5 Estimations des param√®tres sur notre exemple :",
    "text": "4.5 Estimations des param√®tres sur notre exemple :\n\nfish &lt;- read.table(file = \"Fish.csv\",\n                   sep =\",\", header = TRUE) %&gt;% filter(Species == \"Bream\") %&gt;% \n  slice(1:20)\n\n\nmod &lt;- lm(Weight ~Length1 + Height + Width , data =  fish)\nsummary(mod)\n\n\nCall:\nlm(formula = Weight ~ Length1 + Height + Width, data = fish)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-183.872  -17.044   -0.495   24.591  101.032 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1048.57     187.86  -5.582 4.13e-05 ***\nLength1        18.96      13.26   1.430    0.172    \nHeight         48.50      28.31   1.713    0.106    \nWidth          66.72      51.73   1.290    0.215    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 63.03 on 16 degrees of freedom\nMultiple R-squared:  0.808, Adjusted R-squared:  0.772 \nF-statistic: 22.44 on 3 and 16 DF,  p-value: 5.624e-06",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#sur-notre-exemple-sans-la-fonction-lm",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#sur-notre-exemple-sans-la-fonction-lm",
    "title": "Mod√®le lin√©aire multiple",
    "section": "4.6 Sur notre exemple (sans la fonction lm)",
    "text": "4.6 Sur notre exemple (sans la fonction lm)\n\nOn r√©cup√®re les matrices X et Y :\n\n\nX1 &lt;- fish[, c(\"Length1\",  \"Height\",  \"Width\")] %&gt;% \n  as.matrix() \nX &lt;- cbind(Intercept = 1,X1)\nY &lt;- fish[,\"Weight\"] %&gt;% \n  as.matrix()",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#sur-notre-exemple-sans-la-fonction-lm-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#sur-notre-exemple-sans-la-fonction-lm-1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "4.7 Sur notre exemple (sans la fonction lm)",
    "text": "4.7 Sur notre exemple (sans la fonction lm)\n\nOn cherche maintenant \\(\\widehat{\\theta}=(X^t\\,X)^{-1}\\,X^t\\,Y\\).\n\nLe produit matriciel \\(AB\\) s‚Äôobtient en faisant A %*% B, La transpos√©e d‚Äôune matrice A s‚Äôobtient avec la fonction t(A) et son inverse avec la fonction solve(A).\n\n\\(X^t\\,X\\) s‚Äôobtient avec :\n\n\nt(X) %*% X\n\n\n\\((X^t\\,X)^{-1}\\) s‚Äôobtient avec :\n\n\nsolve(t(X) %*% X)\n\nOn a finalement \\(\\widehat{\\theta}\\) :\n\nsolve(t(X) %*% X)%*% t(X)%*% Y",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#on-retrouve-bien-les-m√™mes-valeurs",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#on-retrouve-bien-les-m√™mes-valeurs",
    "title": "Mod√®le lin√©aire multiple",
    "section": "4.8 On retrouve bien les m√™mes valeurs",
    "text": "4.8 On retrouve bien les m√™mes valeurs\n\ncoefficients(mod)\n\n(Intercept)     Length1      Height       Width \n-1048.57013    18.95867    48.49646    66.71559 \n\n\n\nsolve(t(X) %*% X)%*% t(X)%*% Y\n\n                 [,1]\nIntercept -1048.57013\nLength1      18.95867\nHeight       48.49646\nWidth        66.71559",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#dans-le-mod√®le-lin√©aire-simple",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#dans-le-mod√®le-lin√©aire-simple",
    "title": "Mod√®le lin√©aire multiple",
    "section": "5.1 Dans le mod√®le lin√©aire simple",
    "text": "5.1 Dans le mod√®le lin√©aire simple\n\n\n\n\n\n\nNoteRappel\n\n\n\nDans le mod√®le \\(M_2\\) : \\(\\forall i \\in \\{1, \\dots, n\\} \\;\\;\\) \\[ Y_i =\\beta + \\alpha x_i  + E_i,\\quad  E_i \\overset{i.i.d.}{\\sim}\\mathcal{N}(0, \\sigma^2)\\]\nL‚Äôestimateur de la variance r√©siduelle √©tait :\n\\[\nS^2 = \\frac{1}{n-2}\\sum_{i=1}^n(Y_i-\\widehat{Y_i})^2=\\frac{1}{n-2}\\sum_{i=1}^n(Y_i-Ax_i-B)^2= \\frac{SCR(M_2)}{n-2},\n\\]\no√π \\(\\widehat{Y_i}=Ax_i+B\\), la pr√©vision (al√©atoire) par le mod√®le de r√©gression lin√©aire associ√©e √† \\(x_i\\).",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#le-param√®tre-de-variance-r√©siduelle",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#le-param√®tre-de-variance-r√©siduelle",
    "title": "Mod√®le lin√©aire multiple",
    "section": "5.2 Le param√®tre de variance r√©siduelle",
    "text": "5.2 Le param√®tre de variance r√©siduelle\n\n\n\n\n\n\nWarningObjectif\n\n\n\nDans le mod√®le \\(M_{p+1}\\):\n\\(\\forall i \\in \\{1, \\dots, n\\} \\;\\;\\) \\[ Y_i =\\beta +  \\sum_{j=1}^p\\alpha_j x_{j,i}   + E_i,  \\quad E_i \\overset{i.i.d.}{\\sim}\\mathcal{N}(0, \\sigma^2)\\]\nil y‚Äôa un param√®tre de variance \\(\\sigma ^2\\) : la variance residuelle.\nQuel est son estimateur ?",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#estimation-de-la-variance-residuelle-du-mod√®le",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#estimation-de-la-variance-residuelle-du-mod√®le",
    "title": "Mod√®le lin√©aire multiple",
    "section": "5.3 Estimation de la variance residuelle du mod√®le",
    "text": "5.3 Estimation de la variance residuelle du mod√®le\n\n\n\n\n\n\n\n\nNoteD√©finition : Pr√©vision al√©atoire par le mod√®le \\(M_{p+1}\\)\n\n\n\n\\[\\widehat{Y_i}=B+A_1x_{i,1}+\\cdots+A_px_{i,p}=B+\\sum_{j=1}^p A_jx_{i,j}\\]\n\n\n\n\n\n\n\n\nNoteD√©finition : R√©sidus al√©atoires du mod√®le \\(M_{p+1}\\)\n\n\n\n\\[E_i=Y_i-\\widehat{Y_i}\\]\n\n\n\n\n\n\n\n\nNoteD√©finition : Somme des carr√©s r√©siduels\n\n\n\n\\[SCR(M_{p+1})=\\sum_{i=1}^n E_i^2=\\sum_{i=1}^n\\left(Y_i-(B+A_1x_{i,1}+\\cdots+A_px_{i,p})\\right)^2\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#dun-point-de-vue-matriciel",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#dun-point-de-vue-matriciel",
    "title": "Mod√®le lin√©aire multiple",
    "section": "5.4 D‚Äôun point de vue matriciel",
    "text": "5.4 D‚Äôun point de vue matriciel\n\n\n\n\n\n\n\nNoteD√©finition : Vecteur (al√©atoire) des pr√©visions\n\n\n\n\\[\\widehat{Y}\\ =\\ \\begin{bmatrix} \\widehat{Y_1}\\\\\n\\widehat{Y_2}\\\\ \\vdots \\\\ \\widehat{Y_n}\\end{bmatrix}=\\ \\begin{bmatrix} B+\\sum_{j=1}^p A_jx_{1,j}\\\\\nB+\\sum_{j=1}^p A_jx_{2,j}\\\\ \\vdots \\\\ B+\\sum_{j=1}^p A_jx_{n,j}\\end{bmatrix}=X\\hat{\\theta}\\]\n\n\n\n\n\n\n\n\nNoteD√©finition : Vecteur (al√©atoire) des r√©sidus\n\n\n\n\\[E\\ =\\ \\begin{bmatrix} E_1\\\\\nE_2\\\\ \\vdots \\\\ E_n\\end{bmatrix}=\\ \\begin{bmatrix} Y_1-\\widehat{Y_1}\\\\\nY_2-\\widehat{Y_2}\\\\ \\vdots \\\\ Y_n-\\widehat{Y_n}\\end{bmatrix}=Y-X\\hat{\\theta}\\]\n\n\n\n\n\n\n\n\nNoteD√©finition : Somme des carr√©s r√©siduels\n\n\n\n\\[SCR(M_{p+1})=\\sum_{i=1}^n E_i^2= ||E||^2=||Y-X\\hat{\\theta}||^2\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#estimateur-de-la-variance-r√©siduelle-sigma2",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#estimateur-de-la-variance-r√©siduelle-sigma2",
    "title": "Mod√®le lin√©aire multiple",
    "section": "5.5 Estimateur de la variance r√©siduelle \\(\\sigma^2\\)",
    "text": "5.5 Estimateur de la variance r√©siduelle \\(\\sigma^2\\)\n\n\n\n\n\n\n\nNoteD√©finition : Estimateur de \\(\\sigma^2\\)\n\n\n\n\\[\\begin{align}\n{S^2}_{(M_{p+1})}&=\\frac{SCR(M_{p+1})}{n-(p+1)}=\\frac{1}{n-p-1}\\sum_{i=1}^n E_i^2\\\\\n&=\\frac{1}{n-p-1}\\sum_{i=1}^n\\left(Y_i-(B+\\sum_{j=1}^p A_jx_{i,j})\\right)^2=\\frac{||Y - X\\,\\hat{\\theta}||^2}{n-p-1}\n\\end{align}\\]\n\n\n\n\n\n\n\n\nNoteD√©finition : Estimation de \\(\\sigma^2\\)\n\n\n\nR√©alisation \\(s^2\\) de \\({S^2}_{(M_{p+1})}\\) sur les donn√©es\n\\[s^2=\\frac{1}{n-p-1}\\sum_{i=1}^n e_i(M_{p+1})^2=\\sum_{i=1}^n(y_i-(b+a_1x_{i,1}+\\cdots+a_px_{i,p}))^2\\] o√π \\(e_i(M_{p+1})\\) sont les r√©sidus observ√©s dans le mod√®le \\(M_{p+1}\\)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#propri√©t√©s-et-lois-de-s2",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#propri√©t√©s-et-lois-de-s2",
    "title": "Mod√®le lin√©aire multiple",
    "section": "6.1 Propri√©t√©s et lois de \\(S^2\\)",
    "text": "6.1 Propri√©t√©s et lois de \\(S^2\\)\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\nSous les hypoth√®ses du mod√®le lin√©aire gaussien, \\({S^2}_{(M_{p+1})}\\) est un estimateur sans biais de \\(\\sigma^2\\) et on a \\[\\frac{(n-p-1){S^2}_{(M_{p+1})}}{\\sigma^2}=\\frac{\\sum_{i=1}^n(Y_i-B-\\sum_{j=1}^pA_jx_{i,j})^2}{\\sigma^2}\\sim\\chi^2(n-p-1)\\]\nDe plus \\({S^2}_{(M_{p+1})}\\) est ind√©pendant de \\(\\hat{\\theta}\\).",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#propri√©t√©s-et-loi-de-hattheta",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#propri√©t√©s-et-loi-de-hattheta",
    "title": "Mod√®le lin√©aire multiple",
    "section": "6.2 Propri√©t√©s et loi de \\(\\hat{\\theta}\\)",
    "text": "6.2 Propri√©t√©s et loi de \\(\\hat{\\theta}\\)\n\n\n\n\n\n\n\nTipTh√©or√®me\n\n\n\n\\(\\hat{\\theta}\\) est un vecteur gaussien d‚Äôesp√©rance \\(\\theta\\) et de matrice de variance-covariance \\[Var(\\hat{\\theta})=\\sigma^2(X^t\\,X)^{-1} \\quad \\mbox{estim√©e par} \\quad\nS^2(\\hat{\\theta})={S^2}_{(M_{p+1})}(X^t\\,X)^{-1}\\] On montre que \\[\\widehat{\\theta}\\sim{\\cal N}(\\theta\\,,\\,\\sigma^2(X^t\\,X)^{-1})\\]\nEn particulier, pour tout \\(k=1,\\cdots,p+1\\), si \\(c_{kk}={(X^t\\,X)^{-1}}_{kk}\\) d√©signe le \\(k\\)-√®me √©l√©ment diagonal de \\((X^t\\,X)^{-1}\\), et \\(\\widehat{\\theta}_k\\) d√©signe le \\(k\\)-√®me √©l√©ment du vecteur \\(\\hat{\\theta}\\), on a \\[\\widehat{\\theta}_k\\sim{\\cal N}(\\theta_k\\,,\\,\\sigma^2c_{kk})\\]\nEn rempla√ßant \\(\\sigma^2\\) par son estimateur on a, \\[\\frac{(\\widehat{\\theta}_k-\\theta_k)}{\\sqrt{{S^2}_{(M_{p+1})}c_{kk}}}\\sim \\mathcal{T}{(n-p-1)}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#d√©monstrations",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#d√©monstrations",
    "title": "Mod√®le lin√©aire multiple",
    "section": "6.3 D√©monstrations",
    "text": "6.3 D√©monstrations\n\nOn rappelle que \\[\n\\hat{\\theta}=(X^t\\,X)^{-1} X^t Y\n\\]\n\\[\nE(\\hat{\\theta})=E((X^t\\,X)^{-1} X^t Y)=(X^t\\,X)^{-1} X^t E(Y)=(X^t\\,X)^{-1} X^t X\\theta=\\theta\n\\]\n\\[\\begin{align}\n{\\rm{Var}}(\\hat{\\theta})&={\\rm{Var}}((X^t\\,X)^{-1} X^t Y)\\\\\n&= (X^t\\,X)^{-1} X^t {\\rm{Var}}(Y) (X^t\\,X)^{-1} X^t)^t\\\\\n&= (X^t\\,X)^{-1} X^t \\sigma^2I_n ((X^t\\,X)^{-1} X^t)^t\\\\\n&= \\sigma^2(X^t\\,X)^{-1} X^t  (X^t\\,X)^{-1} X^t)^t\\\\\n&= \\sigma^2(X^t\\,X)^{-1} X^t ((X^t)^t) ((X^t\\,X)^{-1})^t \\\\\n&= \\sigma^2(X^t\\,X)^{-1} X^t X ((X^t\\,X)^{t})^{-1} \\\\\n&= \\sigma^2 (X^t\\,(X^{t})^t)^{-1} \\\\\n&= \\sigma^2 (X^t\\,X)^{-1} \\\\\n\\end{align}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-et-intervalle-de-confiance",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-et-intervalle-de-confiance",
    "title": "Mod√®le lin√©aire multiple",
    "section": "6.4 Test et intervalle de confiance",
    "text": "6.4 Test et intervalle de confiance\n√Ä partir du r√©sultat pour tout \\(k=1,\\cdots,p+1\\)\n\\[\\frac{(\\hat{\\theta}_k-\\theta_k)}{\\sqrt{{S^2}_{(M_{p+1})}c_{kk}}}\\sim \\mathcal{T}{(n-p-1)}\\]\n\nOn peut construire un intervalle de confiance de chaque param√®tre de r√©gression \\(\\theta_k\\), o√π \\(\\theta_k\\) d√©signe l‚Äôun des param√®tres d‚Äôesp√©rance (\\(\\beta\\), ou \\(\\alpha_1\\), ‚Ä¶, ou \\(\\alpha_p\\)).\nOn peut construire le test de Student de la nullit√© de chaque coefficient de r√©gression \\(H_0:\\theta_k=0\\) contre \\(H_1:\\theta_k\\neq 0\\) √† partir de la statistique de test \\[T_n=\\frac{\\hat{\\theta}_k}{\\sqrt{{S^2}_{(M_{p+1})}c_{kk}}}\\sim_{H_0} \\mathcal{T}{(n-p-1)}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#intervalle-de-confiance-de-theta_k",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#intervalle-de-confiance-de-theta_k",
    "title": "Mod√®le lin√©aire multiple",
    "section": "6.5 Intervalle de confiance de \\(\\theta_k\\)",
    "text": "6.5 Intervalle de confiance de \\(\\theta_k\\)\n\n\n\n\n\n\nTipTh√©or√®me : Estimateurs par intervalle de niveau de confiance \\(1-\\delta\\) des \\(\\theta_k\\)\n\n\n\n√Ä partir des lois de \\(\\theta_k\\) et \\(S^2_{(M_{p+1})}\\), on obtient:\n\\[IC_{1-\\delta}(\\theta_k) = \\begin{align}\n\\left[\\hat{\\theta}_k-t_{1-\\frac{\\delta}{2}} \\sqrt{{S^2}_{(M_{p+1})}c_{kk}};\\quad\\hat{\\theta}_k+t_{1-\\frac{\\delta}{2}} \\sqrt{{S^2}_{(M_{p+1})}c_{kk}}\\;\\right]\\\\\n\\end{align}\\]\no√π \\(t_{1-\\frac{\\delta}{2}}\\) est tel que \\(\\mathbb{P}\\left(\\mid \\mathcal{T}(n-p-1)\\mid \\leq t_{1-\\frac{\\delta}{2}}\\right)=1-\\delta\\).\n\\(t_{1-\\frac{\\delta}{2}}\\) est le quantile d‚Äôordre \\(1-\\frac{\\delta}{2}\\) de la loi \\(\\mathcal{T}(n-p-1)\\).",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#intervalle-de-confiance-de-theta_k-avec-r",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#intervalle-de-confiance-de-theta_k-avec-r",
    "title": "Mod√®le lin√©aire multiple",
    "section": "6.6 Intervalle de confiance de \\(\\theta_k\\) avec R :",
    "text": "6.6 Intervalle de confiance de \\(\\theta_k\\) avec R :\n\nconfint(mod, level = 0.95)\n\n                   2.5 %     97.5 %\n(Intercept) -1446.805131 -650.33513\nLength1        -9.153972   47.07131\nHeight        -11.528580  108.52149\nWidth         -42.941396  176.37258",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-dans-le-mod√®le-de-r√©gression-multiple",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-dans-le-mod√®le-de-r√©gression-multiple",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.1 Test dans le mod√®le de r√©gression multiple",
    "text": "7.1 Test dans le mod√®le de r√©gression multiple\n\n\n\n\n\n\nWarningObjectifs\n\n\n\n\nTester si un coefficient \\(\\theta_k\\) est significativement diff√©rent de \\(0\\).\nTester si la contribution globale des variables explicatives est significative pour expliquer \\(Y\\).\nD√©terminer la contribution effective des variables explicatives dans la mod√©lisation de \\(Y\\).\nTester si un ensemble de \\(q\\) variables explicatives (\\(q&lt;p\\)) ne suffit pas √† mod√©liser correctement \\(Y\\).",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-de-student-pour-theta_k",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-de-student-pour-theta_k",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.2 Test de Student pour \\(\\theta_k\\)",
    "text": "7.2 Test de Student pour \\(\\theta_k\\)\n\n\nStatistique de test et loi sous \\(H_0\\)\n\n\\[{T_n= \\frac{\\hat{\\theta}_k}{\\sqrt{{S^2}_{(M_{p+1})}c_{kk}}}\\sim_{H_0}\\mathcal{T}(n- p -1)}\\]\n\nZone de rejet\n\n\\[R_\\alpha = \\{T&gt; t_{1-\\frac{\\delta}{2}} \\} \\]\nOn rejette \\(H_0\\) si \\(t_{obs}&gt; t_{1-\\frac{\\delta}{2}}\\)\n\nApplication num√©rique\n\nOn calcul \\(t_{obs} = \\frac{a}{\\sqrt{{s^2}_{(M_{p+1})}c_{kk}}}\\) la r√©alisation de \\(T_n\\).\nOn compare avec \\(t_{1-\\frac{\\delta}{2}}\\) et on conclut.",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#p-valeur-du-test-de-student.",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#p-valeur-du-test-de-student.",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.3 \\(p\\)-valeur du test de Student.",
    "text": "7.3 \\(p\\)-valeur du test de Student.\n\n\n\n\n\n\nTipCalcul de la \\(p\\)-valeur\n\n\n\n\\[p_c=\\mathbb{P}_{H_0}(\\mid T_n\\mid &gt;\\mid t_n\\mid)=2(1-\\mathbb{P}(T_n\\leq |t_n|))\\] o√π \\(T_n\\sim \\mathcal{T}(n-p -1)\\)\n\n\n\n\n\n\n\n\nNoteIntepr√©tation\n\n\n\nPour un risque de 1√®re esp√®ce \\(\\delta\\) fix√© acceptable (par ex \\(\\delta=5\\%\\))\n\nsi \\(p_c &lt;\\delta\\), le test de niveau \\(\\delta\\) est significatif (liaison significative), on rejette \\(H_0\\).\nsi \\(p_c &gt;\\delta\\), le test de niveau \\(\\delta\\) n‚Äôest pas significatif (liaison non significative), on ne rejette pas \\(H_0\\).",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-de-student-avec-r",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-de-student-avec-r",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.4 Test de Student avec R",
    "text": "7.4 Test de Student avec R\n\nmod &lt;- lm(Weight ~Length1 + Height + Width , data =  fish)\nsummary(mod)\n\n\nCall:\nlm(formula = Weight ~ Length1 + Height + Width, data = fish)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-183.872  -17.044   -0.495   24.591  101.032 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1048.57     187.86  -5.582 4.13e-05 ***\nLength1        18.96      13.26   1.430    0.172    \nHeight         48.50      28.31   1.713    0.106    \nWidth          66.72      51.73   1.290    0.215    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 63.03 on 16 degrees of freedom\nMultiple R-squared:  0.808, Adjusted R-squared:  0.772 \nF-statistic: 22.44 on 3 and 16 DF,  p-value: 5.624e-06",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-de-la-contribution-globale-des-variables-explicatives",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-de-la-contribution-globale-des-variables-explicatives",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.5 Test de la contribution globale des variables explicatives",
    "text": "7.5 Test de la contribution globale des variables explicatives\n\n\n\n\n\n\n\nNoteG√©n√©ralisation du test de Fisher √† \\(p\\) variables explicatives\n\n\n\n\\(H_0\\) : aucune des \\(p\\) variables explicatives n‚Äôa d‚Äôinfluence sur \\(Y\\).\n\\(H_1\\) : au moins une des variables explicatives contribue √† expliquer \\(Y\\).\nAutre formulation :\nTest du mod√®le constant \\[H_0\\ :\\ \\text{mod√®le}\\ M_1:Y_i=\\beta+E_i,\\quad E_i\\ \\overset{i.i.d.}{\\sim}\\ {\\cal N}(0,\\sigma^2)\\] contre le mod√®le complet\n\\[H_1\\ :\\ \\text{mod√®le}\\ M_{p+1}:Y_i=\\beta+\\sum_{j=1}^p\\alpha_j x_{i,j}+E_i,\\quad E_i\\ \\overset{i.i.d.}{\\sim} {\\cal N}(0,\\sigma^2)\\]\nAutre formulation :\nTest de \\(H_0:\\ \\forall j=1,\\cdots,p,\\ \\alpha_j=0\\quad\\) contre \\(\\quad H_1:\\exists j\\ \\alpha_j\\neq 0\\)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-de-fisher-de-la-contribution-globale-des-variables-explicatives",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-de-fisher-de-la-contribution-globale-des-variables-explicatives",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.6 Test de Fisher de la contribution globale des variables explicatives",
    "text": "7.6 Test de Fisher de la contribution globale des variables explicatives\n\n\n\n\n\n\n\n\n\nNoteD√©finition : \\(SCT\\)\n\n\n\nLa variabilit√© de \\(Y\\) sans tenir compte du mod√®le.\n\\[\\color{purple}{SCT =\\displaystyle\\sum_{i = 1}^n( Y_i - \\bar{Y})^2}\\]\n\n\n\n\n\n\n\n\n\nNoteD√©finition : \\(SCM(M_{p+1})\\)\n\n\n\nPartie de la variabilit√© de \\(Y\\) expliqu√©e par le mod√®le \\(M_{p+1}\\).\n\\[\\color{blue}{SCM(M_{p+1}) = \\displaystyle\\sum_{i=1}^n(\\widehat{Y_i}(M_{p+1})-\\bar{Y})^2}\\]\n\n\n\n\n\n\n\n\n\nNoteD√©finition : \\(SCR(M_{p+1})\\)\n\n\n\nPartie de la variabilit√© de \\(Y\\) qui n‚Äôest pas expliqu√©e par le mod√®le \\(M_{p+1}\\).\n\\[\\color{red}{\\begin{align}SCR(M_{p+1}) &= \\displaystyle\\sum_{i=1}^n(Y_i-\\widehat{Y_i}(M_{p+1}))^2\\\\&=\\displaystyle\\sum_{i=1}^n E_i(M_{p+1}) ^2\\end{align}}\\]\n\n\n\n\n\n\n\n\n\n\nTipTh√©or√®me de d√©composition de la variance du mod√®le \\(M_{p+1}\\)\n\n\n\n\\[\\color{purple}{SCT}=\\color{blue}{SCM(M_{p+1})}+ \\color{red}{SCR(M_{p+1})}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-de-fisher-de-la-contribution-globale-des-variables-explicatives-suite",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-de-fisher-de-la-contribution-globale-des-variables-explicatives-suite",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.7 Test de Fisher de la contribution globale des variables explicatives (suite)",
    "text": "7.7 Test de Fisher de la contribution globale des variables explicatives (suite)\n\n\n\n\n\n\nCautionRemarques\n\n\n\nDans le mod√®le \\(M_1\\), \\(\\beta\\) est estim√©e par \\(\\bar{Y}\\) et \\(\\widehat{Y_i}(M_{1})=\\bar{Y}\\) donc \\[SCR(M_1)=\\sum_{i=1}^n(Y_i-\\widehat{Y_i}(M_{1}))^2=\\sum_{i=1}^n(Y_i-\\bar{Y})^2=SCT\\]\nOn a donc \\(SCM(M_{p+1})=SCR(M_1)-SCR(M_{p+1})\\) qui repr√©sente la r√©duction d‚Äôerreur quand on passe du mod√®le \\(M_1\\) au mod√®le \\(M_{p+1}\\).\n\n\n\n\n\n\n\n\nTipR√©√©criture de la d√©composition de la variance du mod√®le \\(M_{p+1}\\)\n\n\n\n\\[SCR(M_1)=(SCR(M_1)-SCR(M_{p+1}))+SCR(M_{p+1})\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-de-h_0-mbox-mod√®le-m_1-contre-h_1-mod√®le-m_p1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-de-h_0-mbox-mod√®le-m_1-contre-h_1-mod√®le-m_p1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.8 Test de \\(H_0 : \\mbox{ mod√®le } M_1\\) contre \\(H_1\\) : mod√®le \\(M_{p+1}\\)",
    "text": "7.8 Test de \\(H_0 : \\mbox{ mod√®le } M_1\\) contre \\(H_1\\) : mod√®le \\(M_{p+1}\\)\nStatistique de test \\[T_n=\\frac{SCM(M_{p+1})/p}{SCR(M_{p+1})/(n-p-1)}\\sim_{H_0} \\mathcal{F}(p,n-p-1)\\]\nqui s‚Äô√©crit donc aussi\n\\[T_n=\\frac{(SCR(M_1)-SCR(M_{p+1}))/p}{SCR(M_{p+1})/(n-p-1)}\\sim_{H_0} \\mathcal{F}(p,n-p-1)\\]\nZone de rejet\n\\[R_\\delta = \\{T_n &gt; f_{1-\\delta} \\}\\]\n\\(f_{1-\\delta}\\) est le quantile \\(1 - \\delta\\) de la loi de Fisher \\(\\mathcal{F}(p,n-p-1)\\).\nSi \\(t_{obs} &gt; f_{1-\\delta}\\), on rejette \\(H_0\\) au risque \\(\\delta\\).",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-de-h_0-mbox-mod√®le-m_1-contre-h_1-mod√®le-m_p1-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-de-h_0-mbox-mod√®le-m_1-contre-h_1-mod√®le-m_p1-1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.9 Test de \\(H_0 : \\mbox{ mod√®le } M_1\\) contre \\(H_1\\) : mod√®le \\(M_{p+1}\\)",
    "text": "7.9 Test de \\(H_0 : \\mbox{ mod√®le } M_1\\) contre \\(H_1\\) : mod√®le \\(M_{p+1}\\)\nMise en oeuvre et conclusion :\n\nSi \\(t_{obs} &gt; f_{1-\\delta}\\), on conserve le mod√®le complet \\(M_{p+1}\\) et la contribution globale des \\(p\\) variables explicatives est significative : au moins une des variables explicatives contribue √† expliquer la variabilit√© de \\(Y\\).\nSi \\(t_{obs} &lt; f_{1-\\delta}\\), on ne rejette pas \\(H_0\\) : le mod√®le \\(M_1\\) suffit et les variables explicatives ne contribuent pas √† expliquer de mani√®re significative \\(Y\\).\n\n\\(p\\)-valeur :\n\\[p_c=\\mathbb{P}_{H_0}(T_n &gt; t_{obs})\\] que l‚Äôon compare √† un risque, par exemple \\(\\delta=5\\%\\)\nOn rejette \\(H_0\\) si \\(p_c&lt;\\delta\\).",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-avec-r",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-avec-r",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.10 Test avec R",
    "text": "7.10 Test avec R\n\nmod &lt;- lm(Weight ~Length1 + Height + Width , data =  fish)\nsummary(mod)\n\n\nCall:\nlm(formula = Weight ~ Length1 + Height + Width, data = fish)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-183.872  -17.044   -0.495   24.591  101.032 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1048.57     187.86  -5.582 4.13e-05 ***\nLength1        18.96      13.26   1.430    0.172    \nHeight         48.50      28.31   1.713    0.106    \nWidth          66.72      51.73   1.290    0.215    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 63.03 on 16 degrees of freedom\nMultiple R-squared:  0.808, Adjusted R-squared:  0.772 \nF-statistic: 22.44 on 3 and 16 DF,  p-value: 5.624e-06",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#table-de-lanalyse-de-la-variance-de-la-r√©gression",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#table-de-lanalyse-de-la-variance-de-la-r√©gression",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.11 Table de l‚Äôanalyse de la variance de la r√©gression",
    "text": "7.11 Table de l‚Äôanalyse de la variance de la r√©gression\n\\[M_1:\\quad Y_i=\\beta+ E_i, \\quad E_i \\overset{i.i.d.}{\\sim} {\\cal N}(0\\,,\\,\\sigma^2)\\]\n\nm1 &lt;- lm(Weight ~1, data = fish)\nanova(m1, mod)\n\nAnalysis of Variance Table\n\nModel 1: Weight ~ 1\nModel 2: Weight ~ Length1 + Height + Width\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1     19 331013                                  \n2     16  63568  3    267445 22.439 5.624e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#apr√®s-le-test",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#apr√®s-le-test",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.12 Apr√®s le test",
    "text": "7.12 Apr√®s le test\n\nComme le test global \\(H_0\\) : \\(M_1\\) contre \\(H_1\\) : \\(M_{p+1}\\) est significatif, au moins une des variables explicatives contribue √† expliquer \\(Y\\).\nDans ce cas on peut mod√©liser nos donn√©es par un mod√®le de r√©gression lin√©aire multiple (sous r√©serve de validation des hypoth√®ses).\nPrendre en compte toutes les variables peut s‚Äôav√©rer tr√®s couteux (voir exemples en TP).",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-du-mod√®le-m_q1-contre-le-mod√®le-m_p1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-du-mod√®le-m_q1-contre-le-mod√®le-m_p1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.13 Test du mod√®le \\(M_{q+1}\\) contre le mod√®le \\(M_{p+1}\\)",
    "text": "7.13 Test du mod√®le \\(M_{q+1}\\) contre le mod√®le \\(M_{p+1}\\)\n\n\n\n\n\n\n\nWarningObjectif\n\n\n\n\nTester si un ensemble de \\(q\\) variables explicatives ne suffit pas √† expliquer \\(Y\\), avec \\(q&lt;p\\).\nAutre formulation :\n\n\\[H_0\\ :\\ \\text{mod√®le}\\ M_{q+1}\\ :Y_i=\\beta+\\sum_{j=1}^q\\alpha_j x_{i,j}+E_i,\\quad E_i\\overset{iid}{\\sim}{\\cal N}(0,\\sigma^2)\\] contre l‚Äôalternative \\[H_1\\ :\\ \\text{mod√®le}\\ M_{p+1}:Y_i=\\beta+\\sum_{j=1}^p\\alpha_j x_{i,j}+E_i,\\quad E_i\\ \\overset{i.i.d.}{\\sim} {\\cal N}(0,\\sigma^2)\\]\n\nAutre formulation :\n\nTest de \\(H_0:\\ \\forall j=q+1,\\cdots,p,\\ \\alpha_j=0 \\quad\\) contre \\(\\quad H_1:\\exists j=q+1,\\cdots,p\\ \\alpha_j\\neq 0\\)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#description-des-deux-mod√®les-m_q1-et-m_p1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#description-des-deux-mod√®les-m_q1-et-m_p1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.14 Description des deux mod√®les \\(M_{q+1}\\) et \\(M_{p+1}\\)",
    "text": "7.14 Description des deux mod√®les \\(M_{q+1}\\) et \\(M_{p+1}\\)\n\nMod√®le √† \\(p\\) variables explicatives \\(M_{p+1}\\)\n\\[ Y_i  =  \\beta\\ +\\ \\sum_{j=1}^p\\alpha_j\\,x_{i,j}+ E_i,\\quad E_i\\ \\overset{i.i.d.}{\\sim}\\ {\\cal N}(0,\\sigma^2).\\]\nSous la forme matricielle :\n\\[(M_{p+1})\\,:  Y  =  X^{(p)}\\theta^{(p)}\\ +\\  E, \\quad\nE \\sim {\\cal N}(0, \\sigma^2 I_n) \\]\navec\n\\[\nX^{(p)} = \\begin{bmatrix}\n1 & x_{1,1} & \\ldots & x_{1,p}\\\\\n1 & x_{2,1} & \\ldots & x_{2,p}\\\\\n\\vdots & \\vdots & & \\vdots \\\\\n1 & x_{n,1} & \\ldots & x_{n,p}\n\\end{bmatrix} \\mbox{ et } \\theta^{(p)}=[\\beta,\\alpha_1,\\cdots,\\alpha_p]^t\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#description-des-deux-mod√®les-m_q1-et-m_p1-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#description-des-deux-mod√®les-m_q1-et-m_p1-1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.15 Description des deux mod√®les \\(M_{q+1}\\) et \\(M_{p+1}\\)",
    "text": "7.15 Description des deux mod√®les \\(M_{q+1}\\) et \\(M_{p+1}\\)\n\nMod√®le √† \\(q\\) variables explicatives \\(M_{q+1}\\)\n\\[ Y_i  =  \\beta\\ +\\ \\sum_{j=1}^q\\alpha_j\\,x_{i,j}+ E_i,\\quad E_i\\ \\overset{i.i.d.}{\\sim}\\ {\\cal N}(0,\\sigma^2).\\]\nSous la forme matricielle :\n\\[(M_{p+1})\\,:  Y  =  X^{(q)}\\theta^{(q)}\\ +\\  E, \\quad\nE \\sim {\\cal N}(0, \\sigma^2 I_n) \\]\navec\n\\[\nX^{(q)} = \\begin{bmatrix}\n1 & x_{1,1} & \\ldots & x_{1,q}\\\\\n1 & x_{2,1} & \\ldots & x_{2,q}\\\\\n\\vdots & \\vdots & & \\vdots \\\\\n1 & x_{n,1} & \\ldots & x_{n,q}\n\\end{bmatrix} \\mbox{ et } \\theta^{(q)}=[\\beta,\\alpha_1,\\cdots,\\alpha_q]^t\\]\nLe mod√®le √† \\(q\\) variables explicatives \\(M_{q+1}\\) est embo√Æt√© dans le mod√®le √† \\(p\\) variables explicatives \\(M_{p+1}\\) : les \\(q\\) variables explicatives forment un sous-ensemble des \\(p\\) variables explicatives.",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#estimateur-des-param√®tres-dans-m_p1-et-dans-m_q1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#estimateur-des-param√®tres-dans-m_p1-et-dans-m_q1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.16 Estimateur des param√®tres dans \\(M_{p+1}\\) et dans \\(M_{q+1}\\)",
    "text": "7.16 Estimateur des param√®tres dans \\(M_{p+1}\\) et dans \\(M_{q+1}\\)\nParam√®tres d‚Äôesp√©rances\n\\[\\begin{array}{ccc}\n\\hat{\\theta}^{(p)} &=& (B^{(p)},A_1^{(p)},\\dots,A_{p}^{(p)})^t = \\left((X^{(p)})^t\\,X^{(p)}\\right)^{-1}\\,\\!(X^{(p)})^t\\,Y\\\\\n\\hat{\\theta}^{(q)}  & = & (B^{(q)},A_1^{(q)},\\dots,A_{q}^{(q)})^t=\\left((X^{(q)})^t\\,X^{(q)}\\right)^{-1}\\,\\!(X^{(q)})^t\\,Y\\\n\\end{array}\\]\n\n\n\n\n\n\nCautionRemarques\n\n\n\n\\(B^{(p)}\\neq B^{(q)}, A_1^{(p)}\\neq A_1^{(q)},\\cdots\\)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#pr√©vision-et-r√©sidu-dans-m_p1-et-dans-m_q1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#pr√©vision-et-r√©sidu-dans-m_p1-et-dans-m_q1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.17 Pr√©vision et r√©sidu dans \\(M_{p+1}\\) et dans \\(M_{q+1}\\)",
    "text": "7.17 Pr√©vision et r√©sidu dans \\(M_{p+1}\\) et dans \\(M_{q+1}\\)\n\n\n\n\n\n\n\nNotePr√©vision dans \\(M_{p+1}\\) et dans \\(M_{q+1}\\)\n\n\n\n\\[\\begin{align}\\widehat{Y_i}(M_{p+1})&=B^{(p)}+\\sum_{j=1}^p A^{(p)}_jx_{i,j}\\\\\n\\widehat{Y_i}(M_{q+1})&=B^{(q)}+\\sum_{j=1}^q A^{(q)}_jx_{i,j}\n\\end{align}\\]\n\n\n\n\n\n\n\n\nNoteR√©sidu dans \\(M_{p+1}\\) et dans \\(M_{q+1}\\)\n\n\n\n\\[\\begin{align}E_i(M_{p+1})&=Y_i-\\widehat{Y_i}(M_{p+1})=Y_i-(B^{(p)}+\\sum_{j=1}^p A^{(p)}_jx_{i,j})\\\\\nE_i(M_{q+1})&=Y_i-\\widehat{Y_i}(M_{q+1})=Y_i-(B^{(q)}+\\sum_{j=1}^q A^{(q)}_jx_{i,j})\n\\end{align}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#scr-dans-m_p1-et-dans-m_q1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#scr-dans-m_p1-et-dans-m_q1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.18 SCR dans \\(M_{p+1}\\) et dans \\(M_{q+1}\\)",
    "text": "7.18 SCR dans \\(M_{p+1}\\) et dans \\(M_{q+1}\\)\n\n\n\n\n\n\n\nNoteSCR dans \\(M_{p+1}\\) et dans \\(M_{q+1}\\)\n\n\n\n\\[SCR(M_{p+1}) = \\sum_{i=1}^{n}\\left(Y_i-B^{(p)}-\\sum_{j=1}^{p}A^{(p)}_j\\,x_{i,j}\\right)^2\\ =\\ ||Y - X^{(p)}\\hat{\\theta}^{(p)}||^2\\]\n\\[SCR(M_{q+1}) = \\sum_{i=1}^{n}\\left(Y_i-B^{(q)}-\\sum_{j=1}^{q}A^{(q)}_j\\,x_{i,j}\\right)^2\\ =\\ ||Y - X^{(q)}\\hat{\\theta}^{(q)}||^2\\]\n\n\n\n\n\n\n\n\nNoteEstimation de \\(\\sigma^2\\) dans \\(M_{p+1}\\) et dans \\(M_{q+1}\\)\n\n\n\n\\[S^2_{(M_{p+1})}=\\frac{SCR(M_{p+1})}{n-p-1}\\\\\nS^2_{(M_{q+1})}=\\frac{SCR(M_{q+1})}{n-q-1}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#r√©sultat-important",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#r√©sultat-important",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.19 R√©sultat important",
    "text": "7.19 R√©sultat important\n\n\n\n\n\n\n\nTipTh√©or√®me important du cours\n\n\n\nSous les hypoth√®ses du mod√®le lin√©aire Gaussien multiple, et si on d√©finit \\(SCE=SCR(M_{q+1})-SCR(M_{p+1})\\) alors\n\n\\(\\frac{SCR(M_{p+1})}{\\sigma^2}\\, \\sim\\,\\chi^2_{n-p-1}\\)\nSous le mod√®le \\(M_{q+1}\\), c‚Äôest √† dire sous \\(H_0\\) :\n\n\\[\\frac{SCR(M_{q+1})}{\\sigma^2} \\underset{H_0}{\\sim}\\,\\chi^2_{n-q-1}\\quad;\\quad \\frac{SCE}{\\sigma^2} \\underset{H_0}{\\sim}\\,\\chi^2_{p-q}\\\\\\]\net \\(SCE\\) et \\(SCR(M_{p+1})\\) sont ind√©pendants ce qui permet de d√©duire que\n\\[\\frac{\\left(SCR(M_{q+1}) - SCR(M_{p+1})\\right)\\Bigl/(p-q)}{SCR(M_{p+1})\\Bigl/~(n-p-1)} \\sim_{H_0}^{}~\\mathcal{F}(p-q\\,,\\,n-p-1)\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-de-h_0-mod√®le-m_q1-contre-h_1-mod√®le-m_p1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-de-h_0-mod√®le-m_q1-contre-h_1-mod√®le-m_p1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.20 Test de \\(H_0\\) : mod√®le \\(M_{q+1}\\) contre \\(H_1\\) : mod√®le \\(M_{p+1}\\)",
    "text": "7.20 Test de \\(H_0\\) : mod√®le \\(M_{q+1}\\) contre \\(H_1\\) : mod√®le \\(M_{p+1}\\)\n\n\n\n\n\n\nTipStatistique de test\n\n\n\n\\[\n{T_n=\\frac{(SCR(M_{q+1})-SCR(M_{p+1}))/(p-q)}{SCR(M_{p+1})/(n-p-1)}\\sim_{H_0} \\mathcal{F}(p-q,n-p-1)}\n\\] - \\(SCR(M_{q+1})-SCR(M_{p+1})\\) repr√©sente la r√©duction d‚Äôerreur quand on passe de \\(M_{q+1}\\) √† \\(M_{p+1}\\).\n\n\n\n\n\n\n\n\nTipZone de rejet\n\n\n\n\\[R_\\delta = \\{T_n &gt; f_{1-\\delta} \\} \\] o√π \\(f_\\delta\\) est le quantile d‚Äôordre \\(1-\\delta\\) de la \\(\\mathcal{F}(p-q,n-p-1)\\).\nOn rejette \\(H_0\\) si \\(t_{n}&gt; f_{1-\\delta}\\)",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-de-h_0-mod√®le-m_q1-contre-h_1-mod√®le-m_p1-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#test-de-h_0-mod√®le-m_q1-contre-h_1-mod√®le-m_p1-1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.21 Test de \\(H_0\\) : mod√®le \\(M_{q+1}\\) contre \\(H_1\\) : mod√®le \\(M_{p+1}\\)",
    "text": "7.21 Test de \\(H_0\\) : mod√®le \\(M_{q+1}\\) contre \\(H_1\\) : mod√®le \\(M_{p+1}\\)\n\n\n\n\n\n\nTipInterpr√©tation\n\n\n\nSi \\(t_n &gt; f_{1-\\delta}\\), on conserve le mod√®le complet \\(M_{p+1}\\), on consid√®re que le passage de \\(M_{q+1}\\) √† \\(M_{p+1}\\) est significatif : au moins une variable explicative parmi \\(x_{q+1},\\cdots,x_p\\) a une influence significative sur \\(Y\\) (en plus de \\(x_1,\\cdots,x_q\\)).\nSi \\(t_n \\leq f_{1-\\delta}\\), on ne rejette pas \\(H_0\\), on consid√®re que le passage de \\(M_{q+1}\\) √† \\(M_{p+1}\\) n‚Äôest pas significatif : l‚Äôinfluence des variables explicatives \\(x_{q+1},\\cdots,x_p\\) n‚Äôest pas significative pour expliquer \\(Y\\).\n\n\n\n\n\n\n\n\nTipCalcul de la \\(p\\)-valeur\n\n\n\n\\[p_c=\\mathbb{P}_{H_0}(T_n &gt; t_n)=\\mathbb{P}(\\mathcal{F}(p-q,n-p-1)&gt;t_n)\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#table-de-lanalyse-de-la-variance-de-la-r√©gression-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#table-de-lanalyse-de-la-variance-de-la-r√©gression-1",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.22 Table de l‚Äôanalyse de la variance de la r√©gression",
    "text": "7.22 Table de l‚Äôanalyse de la variance de la r√©gression\nAvec R, commande anova\n\n\\[\\begin{array}{|c|c|c|c|c|c|c|}\n\\hline Source & ddl & SCR& ddl & SCE\\quad expliqu√©e& Statistique & p-value\\\\\n& r√©siduelle&  &&  par\\quad M_{p+1}  & de\\quad test & \\\\\n\\hline \\text{Mod√®le}  & n-q-1 & SCR(M_{q+1}) &  &&&\\\\\nM_{q+1} &&&&&&\\\\\n\\hline \\text{Mod√®le} & n-p-1 & SCR(M_{p+1}) & p-q & SCE=SCR(M_{q+1}) & t_n=&\\mathbb{P}(\\mathcal{F}(p-q,n-p-1)&gt;t_n)\\\\\nM_{p+1} &&&& - SCR(M_{p+1}) &\\frac{SCE/(p-q)}{SCR(M_{p+1})/(n-p-1)} &\\\\\n\\hline\n\\end{array}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#retour-√†-lexemple",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#retour-√†-lexemple",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.23 Retour √† l‚Äôexemple",
    "text": "7.23 Retour √† l‚Äôexemple\nOn va tester\n\\[\\begin{align} &M_4 : Y_i=\\beta+ \\alpha_1x_{i,1}+\\alpha_2x_{i,2}+\\alpha_3x_{i,3}+ E_i \\\\\n&M_3 : Y_i=\\beta+ \\alpha_1x_{i,1}+\\alpha_2x_{i,2}  +E_i \\end{align}\\]\nOn va d√©finir le mod√®le \\(M_3\\)\n\nm3 &lt;- lm(Weight ~ Length1 + Width, data = fish)\nsummary(m3)\n\n\nCall:\nlm(formula = Weight ~ Length1 + Width, data = fish)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-211.090  -14.742    2.901   25.347  104.568 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -998.742    195.859  -5.099 8.91e-05 ***\nLength1       35.713      9.449   3.779   0.0015 ** \nWidth         97.835     51.111   1.914   0.0726 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 66.52 on 17 degrees of freedom\nMultiple R-squared:  0.7728,    Adjusted R-squared:  0.746 \nF-statistic:  28.9 on 2 and 17 DF,  p-value: 3.391e-06",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#sorties-r",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#sorties-r",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.24 Sorties R",
    "text": "7.24 Sorties R\n\nanova(m3,  mod)\n\nAnalysis of Variance Table\n\nModel 1: Weight ~ Length1 + Width\nModel 2: Weight ~ Length1 + Height + Width\n  Res.Df   RSS Df Sum of Sq      F Pr(&gt;F)\n1     17 75223                           \n2     16 63568  1     11655 2.9335 0.1061\n\n\n\nanova(m1,  m3)\n\nAnalysis of Variance Table\n\nModel 1: Weight ~ 1\nModel 2: Weight ~ Length1 + Width\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1     19 331013                                  \n2     17  75223  2    255790 28.904 3.391e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#remarques-sur-les-mod√®les-emboit√©s",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours2/cours2.html#remarques-sur-les-mod√®les-emboit√©s",
    "title": "Mod√®le lin√©aire multiple",
    "section": "7.25 Remarques sur les mod√®les emboit√©s",
    "text": "7.25 Remarques sur les mod√®les emboit√©s\n\n\n\n\n\n\nCautionRemarques\n\n\n\n\nOn peut toujours comparer des mod√®les emboit√©s l‚Äôun dans l‚Äôautre.\nOn peut donc comparer tous les mod√®les au mod√®le complet (structure la plus riche).\nOn peut de m√™me comparer tous les mod√®les au mod√®le constant (structure la moins riche).\nOn ne peut pas comparer des mod√®les non embo√Æt√©s √† l‚Äôaide de ce test :",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires.",
      "Mod√®le lin√©aire multiple"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#√©tude-de-la-variance",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#√©tude-de-la-variance",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.16 √âtude de la variance",
    "text": "6.16 √âtude de la variance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteD√©finition : Somme des Carr√©s Totale\n\n\n\nLa variabilit√© de \\(Y\\) sans tenir compte du mod√®le.\n\\[\\color{purple}{SCT =\\displaystyle\\sum_{i = 1}^n( Y_i - \\bar{Y})^2}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  },
  {
    "objectID": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#√©tude-de-la-variance-1",
    "href": "Cours/EMS/Mod√®le lin√©aire/Cours1/cours1.html#√©tude-de-la-variance-1",
    "title": "Introduction aux mod√®les lin√©aires",
    "section": "6.17 √âtude de la variance",
    "text": "6.17 √âtude de la variance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteD√©finition : Somme des Carr√©s du Mod√®le\n\n\n\nPartie de la variabilit√© de \\(Y\\) expliqu√©e par le mod√®le.\n\\[\\color{blue}{SCM = \\displaystyle\\sum_{i=1}^n(\\widehat{Y_i}-\\bar{Y})^2}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteD√©finition : Somme des Carr√©s R√©siduelles\n\n\n\nPartie de la variabilit√© de \\(Y\\) qui n‚Äôest pas expliqu√©e par le mod√®le.\n\\[\\color{red}{\\begin{align}SCR = \\displaystyle\\sum_{i=1}^n(Y_i-\\widehat{Y_i})^2=\\displaystyle\\sum_{i=1}^n E_i ^2\\end{align}}\\]",
    "crumbs": [
      "Cours",
      "Mod√®les lin√©aires",
      "Introduction aux mod√®les lin√©aires"
    ]
  }
]